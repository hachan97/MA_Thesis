{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":180724,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":154008,"modelId":176490}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# Pip Install\n\n!pip install langchain_experimental langchain_openai langchain_huggingface faiss-cpu peft bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:45:18.660055Z","iopub.execute_input":"2024-11-28T12:45:18.660814Z","iopub.status.idle":"2024-11-28T12:45:40.737600Z","shell.execute_reply.started":"2024-11-28T12:45:18.660780Z","shell.execute_reply":"2024-11-28T12:45:40.736768Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting langchain_experimental\n  Downloading langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\nCollecting langchain_openai\n  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\nCollecting langchain_huggingface\n  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting peft\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nCollecting langchain-community<0.4.0,>=0.3.0 (from langchain_experimental)\n  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\nCollecting langchain-core<0.4.0,>=0.3.15 (from langchain_experimental)\n  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\nCollecting openai<2.0.0,>=1.54.0 (from langchain_openai)\n  Downloading openai-1.55.2-py3-none-any.whl.metadata (24 kB)\nCollecting tiktoken<1,>=0.7 (from langchain_openai)\n  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.25.1)\nCollecting sentence-transformers>=2.6.0 (from langchain_huggingface)\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.20.0)\nRequirement already satisfied: transformers>=4.39.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (4.45.1)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\nRequirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\nCollecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain<0.4.0,>=0.3.8 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\nCollecting langsmith<0.2.0,>=0.1.125 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (8.3.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (1.33)\nCollecting packaging (from faiss-cpu)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (2.9.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.27.0)\nCollecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.54.0->langchain_openai)\n  Downloading jiter-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (10.3.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.0.3)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.22.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (2.4)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.8->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.4)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (2.23.4)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (1.26.18)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\nDownloading langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_openai-0.2.10-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\nDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.55.2-py3-none-any.whl (389 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.5/389.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading jiter-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\nDownloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\nDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, jiter, httpx-sse, tiktoken, requests-toolbelt, faiss-cpu, pydantic-settings, openai, langsmith, bitsandbytes, langchain-core, sentence-transformers, peft, langchain-text-splitters, langchain_openai, langchain_huggingface, langchain, langchain-community, langchain_experimental\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: requests-toolbelt\n    Found existing installation: requests-toolbelt 0.10.1\n    Uninstalling requests-toolbelt-0.10.1:\n      Successfully uninstalled requests-toolbelt-0.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.44.1 faiss-cpu-1.9.0.post1 httpx-sse-0.4.0 jiter-0.8.0 langchain-0.3.9 langchain-community-0.3.8 langchain-core-0.3.21 langchain-text-splitters-0.3.2 langchain_experimental-0.3.3 langchain_huggingface-0.1.2 langchain_openai-0.2.10 langsmith-0.1.147 openai-1.55.2 packaging-24.2 peft-0.13.2 pydantic-settings-2.6.1 requests-toolbelt-1.0.0 sentence-transformers-3.3.1 tiktoken-0.8.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Standard library imports\n\nfrom datetime import datetime, timedelta\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\nimport re\nimport random\nfrom collections import OrderedDict\nimport functools\nimport math\nimport json\nimport os\nimport torch\n\n# Third-party imports\nimport tenacity\nimport faiss\n#from termcolor import colored\n\n# LangChain imports\nfrom langchain.utils import mock_now\nfrom langchain.docstore import InMemoryDocstore\nfrom langchain.retrievers import TimeWeightedVectorStoreRetriever\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.chains import LLMChain\nfrom langchain_core.language_models import BaseLanguageModel\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain.output_parsers import RegexParser\nfrom langchain.prompts import PromptTemplate\nfrom langchain.schema import HumanMessage, SystemMessage, BaseMemory, Document\n#from langchain_experimental.generative_agents import GenerativeAgent, GenerativeAgentMemory\n\n# Pydantic imports\nfrom pydantic import BaseModel, ConfigDict, Field\n\n# Hugging Face\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\nfrom peft import PeftModel, PeftConfig\nfrom langchain_huggingface import HuggingFacePipeline\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\n# API Loggins\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:45:42.628915Z","iopub.execute_input":"2024-11-28T12:45:42.629750Z","iopub.status.idle":"2024-11-28T12:46:01.515735Z","shell.execute_reply.started":"2024-11-28T12:45:42.629696Z","shell.execute_reply":"2024-11-28T12:46:01.515045Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Login to Hugging Face\nuser_secrets = UserSecretsClient()\nHugging_Face_token = user_secrets.get_secret(\"Hugging_Face_token\")\n\nfrom huggingface_hub import login\nlogin(Hugging_Face_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:23:25.349156Z","iopub.execute_input":"2024-11-28T13:23:25.350389Z","iopub.status.idle":"2024-11-28T13:23:25.720485Z","shell.execute_reply.started":"2024-11-28T13:23:25.350352Z","shell.execute_reply":"2024-11-28T13:23:25.719628Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Load GPT","metadata":{}},{"cell_type":"code","source":"LLM = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=1500) ","metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Load Llama 2","metadata":{}},{"cell_type":"code","source":"model_name = \"meta-llama/Llama-2-7b-hf\"  # Replace with the desired model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",  # Automatically allocate to CPU/GPU\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T10:02:01.593430Z","iopub.execute_input":"2024-11-28T10:02:01.593760Z","iopub.status.idle":"2024-11-28T10:03:36.583529Z","shell.execute_reply.started":"2024-11-28T10:02:01.593732Z","shell.execute_reply":"2024-11-28T10:03:36.582571Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbea53a1ba4346769dbf6b34134d903b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"781e75fac3264ddcb0999230ff2d03b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c5e47632aca460f928aa87992f653fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b0b7104687342ec8ec28ee9f99277c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ea8a051a3384a139e1e08fbbf795bea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65a774177c3741dfb54693c6e427e747"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37b22cf580da417e8d01be2dd597e560"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f769d25213451ca14ff35a86784737"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad8d36a09aea4295a3a194d23bcb8156"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b9bf51f1390415b863676999e7f11c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68d353d69c184d829230b4f0a411693c"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Set up the Hugging Face pipeline\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_length=200,\n    temperature=0.7,\n    top_p=0.95,\n)\n\n# Use the pipeline in LangChain\nllm = HuggingFacePipeline(pipeline=pipe)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T10:12:12.119954Z","iopub.execute_input":"2024-11-28T10:12:12.120729Z","iopub.status.idle":"2024-11-28T10:12:12.125718Z","shell.execute_reply.started":"2024-11-28T10:12:12.120694Z","shell.execute_reply":"2024-11-28T10:12:12.124878Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Load Tuned-Llama","metadata":{}},{"cell_type":"code","source":"# base_model_name = \"meta-llama/Llama-3.2-3B\"\nPEFT_MODEL = \"/kaggle/input/llama_boris/pytorch/default/1\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,                      # Load model in 4bit, to redeuce memory and computational requirements\n    bnb_4bit_use_double_quant=True,         # Double quantization, further compress the model weights\n    bnb_4bit_quant_type=\"nf4\",              # Quantization type = nf4\n    bnb_4bit_compute_dtype=torch.bfloat16,  # Compute in 16bit format, to speed up computation\n    load_in_8bit_fp32_cpu_offload=True\n)\n\n\nconfig = PeftConfig.from_pretrained(PEFT_MODEL)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    return_dict=True,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\ntokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = PeftModel.from_pretrained(model, PEFT_MODEL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:23:41.122262Z","iopub.execute_input":"2024-11-28T13:23:41.123097Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Unused kwargs: ['load_in_8bit_fp32_cpu_offload']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adc548554e064ee49f8665f68eb34c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba4d9c741e74c928843125994a8e51c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0201cd08fcc40819cc60264691c3c81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"293344670c7d45fd80024403bec1bf6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a42107d94a1477a9a313045025e2606"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Test the Fine-tuned model\nprompt = \"Should the UK rejoin the European Union?\"\n\n# Tokenize the input prompt\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Generate a response\noutput = model.generate(\n    input_ids=inputs[\"input_ids\"],\n    max_length=300,              # Maximum length of the generated response\n    temperature=0.7,             # Sampling temperature for more creative responses\n    top_p=0.9,                   # Nucleus sampling for generating diverse text\n    repetition_penalty=1.2,      # Penalize repetition in the response\n    do_sample=True,              # Enable sampling for non-deterministic output\n    pad_token_id=tokenizer.eos_token_id,      # Explicitly set the pad token ID\n)\n\n# Decode and print the response\nresponse = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(response)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generative AI Setup\n\n\n\nThe [codes](https://python.langchain.com/api_reference/experimental/generative_agents.html) for the classes `GenerativeAgentMemory` and `GenerativeAgent` was entirely reused from the **[LangChain Experimental](https://pypi.org/project/langchain-experimental/)** project in the LangChain Python API reference - intended for research and experimental uses, with a few minor tweaks and proper configuration of the prompts.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Generative Agent Memory","metadata":{}},{"cell_type":"code","source":"class GenerativeAgentMemory(BaseMemory):\n\n    \"\"\"Memory for the generative agent.\"\"\"\n\n\n\n    llm: BaseLanguageModel\n\n    \"\"\"The core language model.\"\"\"\n\n    memory_retriever: TimeWeightedVectorStoreRetriever\n\n    \"\"\"The retriever to fetch related memories.\"\"\"\n\n    verbose: bool = False\n\n    reflection_threshold: Optional[float] = None\n\n    \"\"\"When aggregate_importance exceeds reflection_threshold, stop to reflect.\"\"\"\n\n    current_plan: List[str] = []\n\n    \"\"\"The current plan of the agent.\"\"\"\n\n    # A weight of 0.15 makes this less important than it\n\n    # would be otherwise, relative to salience and time\n\n    importance_weight: float = 0.15\n\n    \"\"\"How much weight to assign the memory importance.\"\"\"\n\n    aggregate_importance: float = 0.0  # : :meta private:\n\n    \"\"\"Track the sum of the 'importance' of recent memories.\n\n\n\n    Triggers reflection when it reaches reflection_threshold.\"\"\"\n\n\n\n    max_tokens_limit: int = 1200  # : :meta private:\n\n    # input keys\n\n    queries_key: str = \"queries\"\n\n    most_recent_memories_token_key: str = \"recent_memories_token\"\n\n    add_memory_key: str = \"add_memory\"\n\n    # output keys\n\n    relevant_memories_key: str = \"relevant_memories\"\n\n    relevant_memories_simple_key: str = \"relevant_memories_simple\"\n\n    most_recent_memories_key: str = \"most_recent_memories\"\n\n    now_key: str = \"now\"\n\n    reflecting: bool = False\n\n\n\n\n\n\n\n    def chain(self, prompt: PromptTemplate) -> LLMChain:\n\n        return LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n\n\n\n\n\n\n\n    @staticmethod\n\n    def _parse_list(text: str) -> List[str]:\n\n        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n\n        lines = re.split(r\"\\n\", text.strip())\n\n        lines = [line for line in lines if line.strip()]  # remove empty lines\n\n        return [re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", line).strip() for line in lines]\n\n\n\n    def _get_topics_of_reflection(self, last_k: int = 50) -> List[str]:\n\n        \"\"\"Return the 3 most salient high-level questions about recent observations.\"\"\"\n\n        prompt = PromptTemplate.from_template(\n\n            \"{observations}\\n\\n\"\n\n            \"Given only the information above, what are the 3 most salient \"\n\n            \"high-level questions we can answer about the subjects in the statements?\\n\"\n\n            \"Provide each question on a new line.\"\n\n        )\n\n        observations = self.memory_retriever.memory_stream[-last_k:]\n\n        observation_str = \"\\n\".join(\n\n            [self._format_memory_detail(o) for o in observations]\n\n        )\n\n        result = self.chain(prompt).run(observations=observation_str)\n\n        return self._parse_list(result)\n\n\n\n    def _get_insights_on_topic(\n\n        self, topic: str, now: Optional[datetime] = None\n\n    ) -> List[str]:\n\n        \"\"\"Generate 'insights' on a topic of reflection, based on pertinent memories.\"\"\"\n\n        prompt = PromptTemplate.from_template(\n\n            \"Statements relevant to: '{topic}'\\n\"\n\n            \"---\\n\"\n\n            \"{related_statements}\\n\"\n\n            \"---\\n\"\n\n            \"What 5 high-level novel insights can you infer from the above statements \"\n\n            \"that are relevant for answering the following question?\\n\"\n\n            \"Do not include any insights that are not relevant to the question.\\n\"\n\n            \"Do not repeat any insights that have already been made.\\n\\n\"\n\n            \"Question: {topic}\\n\\n\"\n\n            \"(example format: insight (because of 1, 5, 3))\\n\"\n\n        )\n\n\n\n        related_memories = self.fetch_memories(topic, now=now)\n\n        related_statements = \"\\n\".join(\n\n            [\n\n                self._format_memory_detail(memory, prefix=f\"{i+1}. \")\n\n                for i, memory in enumerate(related_memories)\n\n            ]\n\n        )\n\n        result = self.chain(prompt).run(\n\n            topic=topic, related_statements=related_statements\n\n        )\n\n        # TODO: Parse the connections between memories and insights\n\n        return self._parse_list(result)\n\n\n\n\n\n\n\n    def pause_to_reflect(self, now: Optional[datetime] = None) -> List[str]:\n\n        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n\n\n\n        if self.verbose:\n\n            logger.info(\"Character is reflecting\")\n\n        new_insights = []\n\n        topics = self._get_topics_of_reflection()\n\n\n\n        for topic in topics:\n\n            insights = self._get_insights_on_topic(topic, now=now)\n\n            for insight in insights:\n\n                self.add_memory(insight, now=now)\n\n            new_insights.extend(insights)\n\n            \n\n        return new_insights\n\n\n\n\n\n\n\n    def _score_memory_importance(self, memory_content: str) -> float:\n\n        \"\"\"Score the absolute importance of the given memory.\"\"\"\n\n        prompt = PromptTemplate.from_template(\n\n            \"On the scale of 1 to 10, where 1 is purely mundane\"\n\n            + \" (e.g., brushing teeth, making bed) and 10 is\"\n\n            + \" extremely poignant (e.g., a break up, college\"\n\n            + \" acceptance), rate the likely poignancy of the\"\n\n            + \" following piece of memory. Respond with a single integer.\"\n\n            + \"\\nMemory: {memory_content}\"\n\n            + \"\\nRating: \"\n\n        )\n\n        score = self.chain(prompt).run(memory_content=memory_content).strip()\n\n        if self.verbose:\n\n            logger.info(f\"Importance score: {score}\")\n\n        match = re.search(r\"^\\D*(\\d+)\", score)\n\n        if match:\n\n            return (float(match.group(1)) / 10) * self.importance_weight\n\n        else:\n\n            return 0.0\n\n\n\n    def _score_memories_importance(self, memory_content: str) -> List[float]:\n\n        \"\"\"Score the absolute importance of the given memory.\"\"\"\n\n        prompt = PromptTemplate.from_template(\n\n            \"On the scale of 1 to 10, where 1 is purely mundane\"\n\n            + \" (e.g., brushing teeth, making bed) and 10 is\"\n\n            + \" extremely poignant (e.g., a break up, college\"\n\n            + \" acceptance), rate the likely poignancy of the\"\n\n            + \" following piece of memory. Always answer with only a list of numbers.\"\n\n            + \" If just given one memory still respond in a list.\"\n\n            + \" Memories are separated by semi colans (;)\"\n\n            + \"\\nMemories: {memory_content}\"\n\n            + \"\\nRating: \"\n\n        )\n\n        scores = self.chain(prompt).run(memory_content=memory_content).strip()\n\n\n\n        if self.verbose:\n\n            logger.info(f\"Importance scores: {scores}\")\n\n\n\n        # Split into list of strings and convert to floats\n\n        scores_list = [float(x) for x in scores.split(\";\")]\n\n\n\n        return scores_list\n\n\n\n\n\n    def add_memories(\n\n        self, memory_content: str, now: Optional[datetime] = None\n\n    ) -> List[str]:\n\n        \"\"\"Add an observations or memories to the agent's memory.\"\"\"\n\n        importance_scores = self._score_memories_importance(memory_content)\n\n\n\n        self.aggregate_importance += max(importance_scores)\n\n        memory_list = memory_content.split(\";\")\n\n        documents = []\n\n\n\n        for i in range(len(memory_list)):\n\n            documents.append(\n\n                Document(\n\n                    page_content=memory_list[i],\n\n                    metadata={\"importance\": importance_scores[i]},\n\n                )\n\n            )\n\n\n\n        result = self.memory_retriever.add_documents(documents, current_time=now)\n\n\n\n        # After an agent has processed a certain amount of memories (as measured by\n\n        # aggregate importance), it is time to reflect on recent events to add\n\n        # more synthesized memories to the agent's memory stream.\n\n        if (\n\n            self.reflection_threshold is not None\n\n            and self.aggregate_importance > self.reflection_threshold\n\n            and not self.reflecting\n\n        ):\n\n            self.reflecting = True\n\n            self.pause_to_reflect(now=now)\n\n            # Hack to clear the importance from reflection\n\n            self.aggregate_importance = 0.0\n\n            self.reflecting = False\n\n        return result\n\n\n\n    def add_memory(\n\n        self, memory_content: str, now: Optional[datetime] = None\n\n    ) -> List[str]:\n\n        \"\"\"Add an observation or memory to the agent's memory.\"\"\"\n\n        importance_score = self._score_memory_importance(memory_content)\n\n        self.aggregate_importance += importance_score\n\n        document = Document(\n\n            page_content=memory_content, metadata={\"importance\": importance_score}\n\n        )\n\n        result = self.memory_retriever.add_documents([document], current_time=now)\n\n\n\n        # After an agent has processed a certain amount of memories (as measured by\n\n        # aggregate importance), it is time to reflect on recent events to add\n\n        # more synthesized memories to the agent's memory stream.\n\n        if (\n\n            self.reflection_threshold is not None\n\n            and self.aggregate_importance > self.reflection_threshold\n\n            and not self.reflecting\n\n        ):\n\n            self.reflecting = True\n\n            self.pause_to_reflect(now=now)\n\n            # Hack to clear the importance from reflection\n\n            self.aggregate_importance = 0.0\n\n            self.reflecting = False\n\n        return result\n\n\n\n    def fetch_memories(\n\n        self, observation: str, now: Optional[datetime] = None\n\n    ) -> List[Document]:\n\n        \"\"\"Fetch related memories.\"\"\"\n\n        if now is not None:\n\n            with mock_now(now):\n\n                return self.memory_retriever.invoke(observation)\n\n        else:\n\n            return self.memory_retriever.invoke(observation)\n\n\n\n    def format_memories_detail(self, relevant_memories: List[Document]) -> str:\n\n        content = []\n\n        for mem in relevant_memories:\n\n            content.append(self._format_memory_detail(mem, prefix=\"- \"))\n\n        return \"\\n\".join([f\"{mem}\" for mem in content])\n\n\n\n    def _format_memory_detail(self, memory: Document, prefix: str = \"\") -> str:\n\n        created_time = memory.metadata[\"created_at\"].strftime(\"%B %d, %Y, %I:%M %p\")\n\n        return f\"{prefix}[{created_time}] {memory.page_content.strip()}\"\n\n\n\n    def format_memories_simple(self, relevant_memories: List[Document]) -> str:\n\n        return \"; \".join([f\"{mem.page_content}\" for mem in relevant_memories])\n\n\n\n    def _get_memories_until_limit(self, consumed_tokens: int) -> str:\n\n        \"\"\"Reduce the number of tokens in the documents.\"\"\"\n\n        result = []\n\n        for doc in self.memory_retriever.memory_stream[::-1]:\n\n            if consumed_tokens >= self.max_tokens_limit:\n\n                break\n\n            consumed_tokens += self.llm.get_num_tokens(doc.page_content)\n\n            if consumed_tokens < self.max_tokens_limit:\n\n                result.append(doc)\n\n        return self.format_memories_simple(result)\n\n\n\n    @property\n\n    def memory_variables(self) -> List[str]:\n\n        \"\"\"Input keys this memory class will load dynamically.\"\"\"\n\n        return []\n\n\n\n\n\n    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n\n        \"\"\"Return key-value pairs given the text input to the chain.\"\"\"\n\n        queries = inputs.get(self.queries_key)\n\n        now = inputs.get(self.now_key)\n\n        if queries is not None:\n\n            relevant_memories = [\n\n                mem for query in queries for mem in self.fetch_memories(query, now=now)\n\n            ]\n\n            return {\n\n                self.relevant_memories_key: self.format_memories_detail(\n\n                    relevant_memories\n\n                ),\n\n                self.relevant_memories_simple_key: self.format_memories_simple(\n\n                    relevant_memories\n\n                ),\n\n            }\n\n\n\n        most_recent_memories_token = inputs.get(self.most_recent_memories_token_key)\n\n        if most_recent_memories_token is not None:\n\n            return {\n\n                self.most_recent_memories_key: self._get_memories_until_limit(\n\n                    most_recent_memories_token\n\n                )\n\n            }\n\n        return {}\n\n\n\n\n\n    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, Any]) -> None:\n\n        \"\"\"Save the context of this model run to memory.\"\"\"\n\n        # TODO: fix the save memory key\n\n        mem = outputs.get(self.add_memory_key)\n\n        now = outputs.get(self.now_key)\n\n        if mem:\n\n            self.add_memory(mem, now=now)\n\n\n\n\n\n    def clear(self) -> None:\n\n        \"\"\"Clear memory contents.\"\"\"\n\n\n\n\n\n\n\n        # TODO","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:55:31.289546Z","iopub.execute_input":"2024-11-28T11:55:31.290088Z","iopub.status.idle":"2024-11-28T11:55:31.323867Z","shell.execute_reply.started":"2024-11-28T11:55:31.290045Z","shell.execute_reply":"2024-11-28T11:55:31.322810Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Generative Agent","metadata":{}},{"cell_type":"code","source":"class GenerativeAgent(BaseModel):\n\n    \"\"\"Agent as a character with memory and innate characteristics.\"\"\"\n\n\n\n    name: str\n\n    \"\"\"The character's name.\"\"\"\n\n    age: Optional[int] = None\n\n    \"\"\"The optional age of the character.\"\"\"\n\n    traits: str = \"N/A\"\n\n    \"\"\"Permanent traits to ascribe to the character.\"\"\"\n\n    status: str\n\n    \"\"\"The traits of the character you wish not to change.\"\"\"\n\n    memory: GenerativeAgentMemory\n\n    \"\"\"The memory object that combines relevance, recency, and 'importance'.\"\"\"\n\n    llm: BaseLanguageModel\n\n    \"\"\"The underlying language model.\"\"\"\n\n    verbose: bool = False\n\n    summary: str = \"\"  #: :meta private:\n\n    \"\"\"Stateful self-summary generated via reflection on the character's memory.\"\"\"\n\n    summary_refresh_seconds: int = 3600  #: :meta private:\n\n    \"\"\"How frequently to re-generate the summary.\"\"\"\n\n    last_refreshed: datetime = Field(default_factory=datetime.now)  # : :meta private:\n\n    \"\"\"The last time the character's summary was regenerated.\"\"\"\n\n    daily_summaries: List[str] = Field(default_factory=list)  # : :meta private:\n\n    \"\"\"Summary of the events in the plan that the agent took.\"\"\"\n\n\n\n    model_config = ConfigDict(\n\n        arbitrary_types_allowed=True,\n\n    )\n\n\n\n    # LLM-related methods\n\n    @staticmethod\n\n    def _parse_list(text: str) -> List[str]:\n\n        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n\n        lines = re.split(r\"\\n\", text.strip())\n\n        return [re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", line).strip() for line in lines]\n\n\n\n\n\n\n\n    def chain(self, prompt: PromptTemplate) -> LLMChain:\n\n        \"\"\"Create a chain with the same settings as the agent.\"\"\"\n\n\n\n        return LLMChain(\n\n            llm=self.llm, prompt=prompt, verbose=self.verbose, memory=self.memory\n\n        )\n\n\n\n\n\n\n\n    def _get_entity_from_observation(self, observation: str) -> str:\n\n        prompt = PromptTemplate.from_template(\n\n            \"What is the observed entity in the following observation? {observation}\"\n\n            + \"\\nEntity=\"\n\n        )\n\n        return self.chain(prompt).run(observation=observation).strip()\n\n\n\n    def _get_entity_action(self, observation: str, entity_name: str) -> str:\n\n        prompt = PromptTemplate.from_template(\n\n            \"What is the {entity} doing in the following observation? {observation}\"\n\n            + \"\\nThe {entity} is\"\n\n        )\n\n        return (\n\n            self.chain(prompt).run(entity=entity_name, observation=observation).strip()\n\n        )\n\n\n\n\n\n\n\n    def summarize_related_memories(self, observation: str) -> str:\n\n        \"\"\"Summarize memories that are most relevant to an observation.\"\"\"\n\n        prompt = PromptTemplate.from_template(\n\n            \"\"\"\n\n            {q1}?\n\n            Context from memory:\n\n            {relevant_memories}\n\n            Relevant context: \n\n            \"\"\"\n\n        )\n\n        entity_name = self._get_entity_from_observation(observation)\n\n        entity_action = self._get_entity_action(observation, entity_name)\n\n        q1 = f\"What is the relationship between {self.name} and {entity_name}\"\n\n        q2 = f\"{entity_name} is {entity_action}\"\n\n        return self.chain(prompt=prompt).run(q1=q1, queries=[q1, q2]).strip()\n\n\n\n\n\n## Generate Summary of the agent + reaction \n\n    def _generate_reaction(\n\n        self, observation: str, suffix: str, now: Optional[datetime] = None\n\n    ) -> str:\n\n        \"\"\"React to a given observation or dialogue act.\"\"\"\n\n        prompt = PromptTemplate.from_template(\n\n            \"{agent_summary_description}\"\n\n            + \"\\nIt is {current_time}.\"\n\n            + \"\\n{agent_name}'s status: {agent_status}\"\n\n            + \"\\nSummary of relevant context from {agent_name}'s memory:\"\n\n            + \"\\n{relevant_memories}\"\n\n            + \"\\nMost recent observations: {most_recent_memories}\"\n\n            + \"\\nObservation: {observation}\"\n\n            + \"\\n\\n\"\n\n            + suffix\n\n        )\n\n        agent_summary_description = self.get_summary(now=now)\n\n        relevant_memories_str = self.summarize_related_memories(observation)\n\n        current_time_str = (\n\n            datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n\n            if now is None\n\n            else now.strftime(\"%B %d, %Y, %I:%M %p\")\n\n        )\n\n        kwargs: Dict[str, Any] = dict(\n\n            agent_summary_description=agent_summary_description,\n\n            current_time=current_time_str,\n\n            relevant_memories=relevant_memories_str,\n\n            agent_name=self.name,\n\n            observation=observation,\n\n            agent_status=self.status,\n\n        )\n\n        consumed_tokens = self.llm.get_num_tokens(\n\n            prompt.format(most_recent_memories=\"\", **kwargs)\n\n        )\n\n        kwargs[self.memory.most_recent_memories_token_key] = consumed_tokens\n\n        return self.chain(prompt=prompt).run(**kwargs).strip()\n\n\n\n## Clean response\n\n    def _clean_response(self, text: str) -> str:\n\n        return re.sub(f\"^{self.name} \", \"\", text.strip()).strip()\n\n\n\n## Generate Reaction\n\n    def generate_reaction(\n\n        self, observation: str, now: Optional[datetime] = None\n\n    ) -> Tuple[bool, str]:\n\n        \"\"\"React to a given observation.\"\"\"\n\n\n\n        call_to_action_template = (\n\n            \"Should {agent_name} react to the observation, and if so,\"\n\n            + \" what would be an appropriate reaction? Respond in one line.\"\n\n            + ' If the action is to engage in dialogue, write:\\nSAY: \"what to say\"'\n\n            + \"\\notherwise, write:\\nREACT: {agent_name}'s reaction (if anything).\"\n\n            + \"\\nEither do nothing, react, or say something but not both.\\n\\n\"\n\n        )\n\n        full_result = self._generate_reaction(\n\n            observation, call_to_action_template, now=now\n\n        )\n\n        result = full_result.strip().split(\"\\n\")[0]\n\n        # AAA\n\n        self.memory.save_context(\n\n            {},\n\n            {\n\n                self.memory.add_memory_key: f\"{self.name} observed \"\n\n                f\"{observation} and reacted by {result}\",\n\n                self.memory.now_key: now,\n\n            },\n\n        )\n\n        \n\n        if \"REACT:\" in result:\n\n            reaction = self._clean_response(result.split(\"REACT:\")[-1])\n\n            return False, f\"{self.name} {reaction}\"\n\n        \n\n        if \"SAY:\" in result:\n\n            said_value = self._clean_response(result.split(\"SAY:\")[-1])\n\n            return True, f\"{self.name} said {said_value}\"\n\n        \n\n        else:\n\n            return False, result\n\n\n\n## Generate Dialogue response\n\n    def generate_dialogue_response(\n\n        self, observation: str, now: Optional[datetime] = None\n\n    ) -> Tuple[bool, str]:\n\n        \"\"\"React to a given observation.\"\"\"\n\n\n\n        call_to_action_template = (\n\n        \"What would {agent_name} say in response to the observation provided?\\n\"\n\n        \"Respond directly with what {agent_name} would say next.\\n\\n\"\n\n        )\n\n\n\n        # Generating response with updated prompt\n\n        full_result = self._generate_reaction(observation, call_to_action_template, now=now)\n\n        result = re.findall(r'\"(.*?)\"', full_result)[0]\n\n        \n\n        response_text = self._clean_response(result.strip())\n\n        self.memory.save_context(\n\n            {},\n\n            {\n\n                self.memory.add_memory_key: f\"{self.name} observed \"\n\n                f\"{observation} and said {response_text}\",\n\n                self.memory.now_key: now,\n\n            },\n\n        )\n\n\n\n        return True, f\"{self.name} said {response_text}\"\n\n\n\n## Decide if the agent wants to respond to the observation\n\n    def decide_to_respond(self, observation: str, now: Optional[datetime] = None) -> bool:\n\n        \"\"\"Decide whether the agent wants to respond to the observation.\"\"\"\n\n\n\n        call_to_action_template = (\n\n            \"Decide if {agent_name} should respond to the statement made, and if so, \"\n\n            + \"Answer 'yes' if the agent should respond, otherwise answer 'no'.\"\n\n            + \"\\n\\nConsider the following:\"\n\n            + \"\\n- Answer 'yes' if the statement contains a question directed at {agent_name}.\"\n\n            + \"\\n- Answer 'yes' if the statement directly relates to {agent_name}'s interests, role, or is otherwise important.\"\n\n            + \"\\n- Answer 'no' if the statement is not important or not relevant to {agent_name}.\"\n\n            + \"\\n\\nRespond with only 'yes' or 'no'.\"\n\n            )\n\n\n\n        full_result = self._generate_reaction(observation, call_to_action_template, now=now)\n\n        result = full_result.strip().lower()  # Normalize result to lowercase for consistent comparison\n\n\n\n        # Save the decision context to memory\n\n        self.memory.save_context(\n\n            {},\n\n            {\n\n                self.memory.add_memory_key: f\"{self.name} observed \"\n\n                f\"{observation} and reacted by {result}\",\n\n                self.memory.now_key: now,\n\n            },\n\n        )\n\n        \n\n        # Check if the model returned \"yes\" or \"no\"\n\n        if result == \"no\":\n\n            return False\n\n        elif result == \"yes\":\n\n            return True\n\n        else:\n\n            print(f\"Unexpected response: {result}\")  # For debugging purposes\n\n            return False\n\n\n\n\n\n    ######################################################\n\n    # Agent stateful' summary methods.                   #\n\n    # Each dialog or response prompt includes a header   #\n\n    # summarizing the agent's self-description. This is  #\n\n    # updated periodically through probing its memories  #\n\n    ######################################################\n\n    def _compute_agent_summary(self) -> str:\n\n        \"\"\"\"\"\"\n\n        prompt = PromptTemplate.from_template(\n\n            \"How would you summarize {name}'s core characteristics given the\"\n\n            + \" following statements:\\n\"\n\n            + \"{relevant_memories}\"\n\n            + \"Do not embellish.\"\n\n            + \"\\n\\nSummary: \"\n\n        )\n\n        # The agent seeks to think about their core characteristics.\n\n        return (\n\n            self.chain(prompt)\n\n            .run(name=self.name, queries=[f\"{self.name}'s core characteristics\"])\n\n            .strip()\n\n        )\n\n\n\n\n\n\n\n    def get_summary(\n\n        self, force_refresh: bool = False, now: Optional[datetime] = None\n\n    ) -> str:\n\n        \"\"\"Return a descriptive summary of the agent.\"\"\"\n\n        current_time = datetime.now() if now is None else now\n\n        since_refresh = (current_time - self.last_refreshed).seconds\n\n        if (\n\n            not self.summary\n\n            or since_refresh >= self.summary_refresh_seconds\n\n            or force_refresh\n\n        ):\n\n            self.summary = self._compute_agent_summary()\n\n            self.last_refreshed = current_time\n\n        age = self.age if self.age is not None else \"N/A\"\n\n        return (\n\n            f\"Name: {self.name} (age: {age})\"\n\n            + f\"\\nInnate traits: {self.traits}\"\n\n            + f\"\\n{self.summary}\"\n\n        )\n\n\n\n\n\n\n\n\n\n\n\n    def get_full_header(\n\n        self, force_refresh: bool = False, now: Optional[datetime] = None\n\n    ) -> str:\n\n        \"\"\"Return a full header of the agent's status, summary, and current time.\"\"\"\n\n        now = datetime.now() if now is None else now\n\n        summary = self.get_summary(force_refresh=force_refresh, now=now)\n\n        current_time_str = now.strftime(\"%B %d, %Y, %I:%M %p\")\n\n        return (\n\n            f\"{summary}\\nIt is {current_time_str}.\\n{self.name}'s status: {self.status}\"\n\n        )\n\n\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:55:35.928604Z","iopub.execute_input":"2024-11-28T11:55:35.929172Z","iopub.status.idle":"2024-11-28T11:55:35.961803Z","shell.execute_reply.started":"2024-11-28T11:55:35.929135Z","shell.execute_reply":"2024-11-28T11:55:35.960866Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Create Agent\n\n\n\n- [GenerativeAgentMemory](https://python.langchain.com/api_reference/experimental/generative_agents/langchain_experimental.generative_agents.memory.GenerativeAgentMemory.html): **Memory** for the generative agent \n\n   - `llm`\n\n   - `memory_retriever` = create_new_memory_retriever()\n\n   - `current_plan`\n\n   - `reflection_threshold`\n\n   - `add_memory` add observation/memory\n\n\n\n- [GenerativeAgent](https://python.langchain.com/api_reference/experimental/generative_agents.html): Agent as a character with **memory** and innate **characteristics**,  \n\n   - basics like `name`, `age` and `llm`\n\n   - `memory` object that combines relevance, recency, and ‘importance’\n\n   - `summary` and `summary_refresh_seconds` to set how frequently to re-generate the summary\n\n   - `summarize_related_memories`: Summarize memories that are most relevant to an observation\n\n   - `status` fix-objectives / traits of the character you wish not to change\n\n   - `traits` set Permanent traits to ascribe to the character \n\n   - `generate_dialogue_response`","metadata":{}},{"cell_type":"code","source":"# Relevance Score function - relevance_score_fn()\n\ndef relevance_score_fn(score: float) -> float:\n\n    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n\n    return 1.0 - score / math.sqrt(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:55:39.917051Z","iopub.execute_input":"2024-11-28T11:55:39.917728Z","iopub.status.idle":"2024-11-28T11:55:39.922199Z","shell.execute_reply.started":"2024-11-28T11:55:39.917694Z","shell.execute_reply":"2024-11-28T11:55:39.921168Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Memory Retriever function - create_new_memory_retriever()\n\ndef create_new_memory_retriever():\n\n    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n\n    embeddings_model = OpenAIEmbeddings()     \n\n    # Initialize the vectorstore as empty\n\n    embedding_size = 1536  # embedding dimension\n\n    index = faiss.IndexFlatL2(embedding_size)\n\n    vectorstore = FAISS(\n\n        embeddings_model.embed_query,\n\n        index,\n\n        InMemoryDocstore({}),  # empty Memory docstore\n\n        {},  # index-to-document store ID mapping\n\n        relevance_score_fn=relevance_score_fn,\n\n    )\n\n\n\n    # Time-weighted scoring mechanism\n\n    return TimeWeightedVectorStoreRetriever(\n\n        vectorstore=vectorstore,\n\n        other_score_keys=[\"importance\"],\n\n        k=15  # retrieve up to 15 relevant memories\n\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T10:18:29.511858Z","iopub.execute_input":"2024-11-28T10:18:29.512577Z","iopub.status.idle":"2024-11-28T10:18:29.517819Z","shell.execute_reply.started":"2024-11-28T10:18:29.512543Z","shell.execute_reply":"2024-11-28T10:18:29.516833Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Agent Creation function - create_debate_agent()\n\ndef create_debate_agent(name, age, traits, status, \n\n                        #reflection_threshold, \n\n                        llm):\n\n    \n\n    memory = GenerativeAgentMemory(\n\n        llm=llm,\n\n        memory_retriever=create_new_memory_retriever(),\n\n        verbose=False,\n\n        #reflection_threshold=reflection_threshold,  # adjust as needed for reflection frequency\n\n    )\n\n\n\n    agent = GenerativeAgent(\n\n        name=name,\n\n        age=age,\n\n        traits=traits,\n\n        status=status,\n\n        memory_retriever=create_new_memory_retriever(),\n\n        llm=llm,\n\n        memory=memory,\n\n    )\n\n    return agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T10:13:09.463948Z","iopub.execute_input":"2024-11-28T10:13:09.464242Z","iopub.status.idle":"2024-11-28T10:13:09.469184Z","shell.execute_reply.started":"2024-11-28T10:13:09.464217Z","shell.execute_reply":"2024-11-28T10:13:09.468272Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Create debate agents (MPs) with their respective characteristics\n\n\n\nTrott = create_debate_agent(name=\"Laura Trott\", age=38, llm = llm,\n\n                            traits= \"highly disciplined, sharp, and pragmatic. Strategic, focus on “quiet competence” rather than loud rhetoric, detail-oriented and a stickler for facts\",\n\n                            status=\"Conservative MP\")\n\n\n\nJohnson = create_debate_agent(name=\"Boris Johnson\", age=57, llm = llm,\n\n                            traits=\"charismatic, chaotic, opportunistic, larger-than-life personality, thrives on spectacle and Blitz-spirit optimism, mixes humor with charm and a dash of bluster, unpredictable yet captivating, a showman who values headlines over substance\",\n\n                            status=\"Conservative MP\")\n\n\n\nFarage = create_debate_agent(name=\"Nigel Farage\", age=60, llm = llm,\n\n                             traits=\"unapologetically bold, confrontational, divisive, a provocateur, skilled at stirring public opinion with blunt populist rhetoric, political brawle, highly skilled at galvanizing crowds\",\n\n                             status=\"Former UKIP leader, Brexit Party leader, and political commentator\")\n\n\n\nSunak = create_debate_agent(name=\"Rishi Sunak\", age=44, llm = llm,\n\n                            traits=\"technocratic, astute, polished, financially extremely wealthy, meticulous, highly analytical, known as the Fiscal-Guardian, out of touch with the middle-class\",\n\n                            status=\"Conservative MP, Former Prime Minister\")\n\n\n\nStarmer = create_debate_agent(name=\"Sir Keir Starmer\", age=61, llm = llm,\n\n                              traits=\"methodical, earnest, intense focus on justice and reform, calm demeanor, seeks accountability, values facts over flair, deliver points with precision rather than emotion\",\n\n                              status=\"Leader of the Labour Party\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T10:18:33.836082Z","iopub.execute_input":"2024-11-28T10:18:33.836431Z","iopub.status.idle":"2024-11-28T10:19:20.937017Z","shell.execute_reply.started":"2024-11-28T10:18:33.836397Z","shell.execute_reply":"2024-11-28T10:19:20.935091Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3009616454.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embeddings_model = HuggingFaceEmbeddings(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bf66949469b43e2b888d2bd8edf1258"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create debate agents (MPs) with their respective characteristics\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m Trott \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_debate_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLaura Trott\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m38\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtraits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhighly disciplined, sharp, and pragmatic. Strategic, focus on “quiet competence” rather than loud rhetoric, detail-oriented and a stickler for facts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mstatus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConservative MP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m Johnson \u001b[38;5;241m=\u001b[39m create_debate_agent(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoris Johnson\u001b[39m\u001b[38;5;124m\"\u001b[39m, age\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m57\u001b[39m, llm \u001b[38;5;241m=\u001b[39m llm,\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m                             traits\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharismatic, chaotic, opportunistic, larger-than-life personality, thrives on spectacle and Blitz-spirit optimism, mixes humor with charm and a dash of bluster, unpredictable yet captivating, a showman who values headlines over substance\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m                             status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConservative MP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m Farage \u001b[38;5;241m=\u001b[39m create_debate_agent(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNigel Farage\u001b[39m\u001b[38;5;124m\"\u001b[39m, age\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, llm \u001b[38;5;241m=\u001b[39m llm,\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m                              traits\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munapologetically bold, confrontational, divisive, a provocateur, skilled at stirring public opinion with blunt populist rhetoric, political brawle, highly skilled at galvanizing crowds\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m                              status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormer UKIP leader, Brexit Party leader, and political commentator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[23], line 15\u001b[0m, in \u001b[0;36mcreate_debate_agent\u001b[0;34m(name, age, traits, status, llm)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_debate_agent\u001b[39m(name, age, traits, status, \n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m                         \u001b[38;5;66;03m#reflection_threshold, \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m                         llm):\n\u001b[1;32m     11\u001b[0m     memory \u001b[38;5;241m=\u001b[39m GenerativeAgentMemory(\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m         llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     14\u001b[0m \n\u001b[0;32m---> 15\u001b[0m         memory_retriever\u001b[38;5;241m=\u001b[39m\u001b[43mcreate_new_memory_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m#reflection_threshold=reflection_threshold,  # adjust as needed for reflection frequency\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     agent \u001b[38;5;241m=\u001b[39m GenerativeAgent(\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent\n","Cell \u001b[0;32mIn[29], line 7\u001b[0m, in \u001b[0;36mcreate_new_memory_retriever\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_new_memory_retriever\u001b[39m():\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new vector store retriever unique to the agent.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     embeddings_model \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-2-7b-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Replace with your model\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Initialize the vectorstore as empty\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     embedding_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1536\u001b[39m  \u001b[38;5;66;03m# embedding dimension\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     emit_warning()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py:92\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43msentence_transformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:347\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (3 times)]\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 30.12 MiB is free. Process 2825 has 14.71 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 30.12 MiB is free. Process 2825 has 14.71 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":30},{"cell_type":"code","source":"# Creat Memory objects for each agent\n\nTrott_memory = Trott.memory\n\nJohnson_memory = Johnson.memory\n\nFarage_memory = Farage.memory   \n\nSunak_memory = Sunak.memory\n\nStarmer_memory = Starmer.memory","metadata":{},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# Base Observations \n\nTrott_observations = [\n\n    \"Trott attended Oxted School, studied history and economics at Oxford University\",\n\n    \"Trott is preparing for a debate on the economy\",\n\n    \"Trott advocates for responsible budgeting and cautious government spending\",\n\n    \"Trott emphasize business growth and pragmatic economic solutions\",\n\n    \"Trott generally conservative but supports progressive stances on education and family policies\",\n\n    \"Trott focuses on pragmatic rather than ideological approaches\",\n\n]\n\n\n\nJohnson_observations = [\n\n    \"Johnson attended Eton College, studied Classics Oxford University\",\n\n    \"Johnson is Pro-Brexit and economically nationalist\",\n\n    \"Johnson advocates for deregulation, minimal government intervention, and strong support for British businesses\",\n\n    \"Johnson is a populist, often aligning with traditional conservative values, though flexible when politically advantageous\",\n\n    \"Johnson is support strong national identity and sovereignty\",\n\n]\n\n\n\nFarage_observations = [\n\n    \"Farage attended Dulwich College but did not attend university\",\n\n    \"Farage is strongly Eurosceptic, advocates for British sovereignty, deregulation, and cutting ties with EU economic policies\",\n\n    \"Farage prioritizes domestic industry and independence from European influence\",\n\n    \"Farage is a Nationalist, anti-globalist, and socially conservative\",\n\n    \"Farage advocates for strict immigration controls and promotes traditional British values\"\n\n]\n\n\n\nSunak_observations = [\n\n    \"Sunak studied Philosophy, Politics, and Economics at Oxford University and later earned an MBA from Stanford University\",\n\n    \"Sunak is fiscal conservative with a focus on budget balancing\",\n\n    \"Sunak advocates for responsible spending and a cautious approach to government intervention\",\n\n    \"Sunak prioritizes stability over drastic reforms\",\n\n    \"Sunak focus on pragmatism over ideology, holds relatively conservative views on social issues, often supporting traditional family values\",\n\n]\n\n\n\nStarmer_observations = [\n\n    \"Starmer attended Reigate Grammar School, studied law at the University of Leeds and completed studies at Oxford University\",\n\n    \"Starmer focuses on investment in public services, especially the NHS, and progressive taxation\",\n\n    \"Starmer prioritizes worker rights and social equality, advocating for a balanced but progressive approach\",\n\n    \"Starmer supports expanded public services, social justice, and inclusivity\",\n\n    \"Starmer Focuses on social reform and government accountability\",\n\n]","metadata":{},"outputs":[],"execution_count":87},{"cell_type":"code","source":"# Loop through the observations and add to memory\n\n# Add the observations to the memory using the 'add_memory()' function\n\n\n\nfor observation in Trott_observations:\n\n    Trott_memory.add_memory(observation)\n\n\n\nfor observation in Johnson_observations:    \n\n    Johnson_memory.add_memory(observation)\n\n\n\nfor observation in Farage_observations:\n\n    Farage_memory.add_memory(observation)\n\n\n\nfor observation in Sunak_observations:\n\n    Sunak_memory.add_memory(observation)\n\n\n\nfor observation in Starmer_observations:\n\n    Starmer.memory.add_memory(observation)","metadata":{},"outputs":[],"execution_count":88},{"cell_type":"markdown","source":"# Create Simulation","metadata":{}},{"cell_type":"code","source":"# List of agents in the debate\n\nagents = [Trott, Johnson, Farage, Sunak, Starmer]\n\n\n\n# Define the initial debate topic\n\ninitial_observation = \"Should the UK rejoin the European Union?\"","metadata":{},"outputs":[],"execution_count":89},{"cell_type":"markdown","source":"## Framework X\n\nArchived frameworks that DOES NOT work.\n\n\n\n`run_HoC_debate_framework_X1`:\n\n- Use the generate_reaction() function to decide \"what would be an appropriate reaction?\", and if it chooses to say something, call up the generate_dialogue_response() function to generate a response text.\n\n- Results: agents does not respond, agent doesn not engage in dialogue, because the prompt is \"*what would be an appropriate reaction*?\"\n","metadata":{}},{"cell_type":"code","source":"def run_HoC_debate_framework_X1 (agents: List[GenerativeAgent],\n\ninitial_observation: str) -> None:\n\n    \"\"\"Runs a conversation where each agent strictly chooses to either react or say a response.\"\"\"\n\n    \n\n    observation = initial_observation  # Initial observation passed into the conversation loop\n\n    turns = 0  # Counter to limit turns or control flow as needed\n\n    \n\n    # Loop through rounds of conversation\n\n    while turns < 3:  # Set a suitable limit for the number of rounds\n\n        for agent in agents:\n\n            # Generate a reaction or response to the current observation\n\n            continue_dialogue, reaction_or_response = agent.generate_reaction(observation)\n\n            \n\n            if continue_dialogue == False:\n\n                # Agent chooses to react - print reaction, but do not change observation\n\n                print(reaction_or_response)\n\n                \n\n            elif continue_dialogue == True:\n\n                # Agent chooses to say something - print and update observation for next agent\n\n                stay_in_dialogue, response_text = agent.generate_dialogue_response(observation)\n\n                print(response_text)\n\n\n\n            else:\n\n                # Skip any output that is not a strict \"REACT\" or \"SAY\"\n\n                print(f\"{agent.name} output ignored as it did not conform to 'REACT' or 'SAY'\")\n\n        \n\n        turns += 1  # Increment the turn count","metadata":{},"outputs":[],"execution_count":130},{"cell_type":"code","source":"# Run the debate\n\nrun_HoC_debate_framework_X1 (agents, initial_observation)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Laura Trott would likely maintain a pragmatic approach and carefully assess the potential benefits and drawbacks of rejoining the European Union before making any decisions.\n","Boris Johnson Boris Johnson's reaction would likely be to strongly oppose the idea of the UK rejoining the European Union, given his pro-Brexit stance and emphasis on British independence and sovereignty.\n","Nigel Farage would likely strongly oppose the UK rejoining the European Union, citing his beliefs in British sovereignty, nationalism, and independence from European influence.\n","Rishi Sunak would likely approach the question of rejoining the European Union cautiously, emphasizing the need for a thorough analysis of the potential economic and social implications before making any decision.\n","Sir Keir Starmer would likely support the idea of the UK rejoining the European Union, as it aligns with his values of inclusivity, social justice, and cooperation.\n","Laura Trott would likely maintain a pragmatic approach and carefully assess the potential benefits and drawbacks of rejoining the European Union before making any decisions.\n","Boris Johnson Boris Johnson's reaction would likely be to strongly oppose the idea of the UK rejoining the European Union, given his pro-Brexit stance and emphasis on British independence and sovereignty.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[131], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the debate\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mrun_HoC_debate_framework_0\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_observation\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[130], line 12\u001b[0m, in \u001b[0;36mrun_HoC_debate_framework_0\u001b[1;34m(agents, initial_observation)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m turns \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:  \u001b[38;5;66;03m# Set a suitable limit for the number of rounds\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m agents:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# Generate a reaction or response to the current observation\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m         continue_dialogue, reaction_or_response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reaction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m continue_dialogue \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;66;03m# Agent chooses to react - print reaction, but do not change observation\u001b[39;00m\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;28mprint\u001b[39m(reaction_or_response)\n","Cell \u001b[1;32mIn[116], line 137\u001b[0m, in \u001b[0;36mGenerativeAgent.generate_reaction\u001b[1;34m(self, observation, now)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"React to a given observation.\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m call_to_action_template \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould \u001b[39m\u001b[38;5;132;01m{agent_name}\u001b[39;00m\u001b[38;5;124m react to the observation, and if so,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m what would be an appropriate reaction? Respond in one line.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEither do nothing, react, or say something but not both.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m )\n\u001b[1;32m--> 137\u001b[0m full_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_reaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_to_action_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnow\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m result \u001b[38;5;241m=\u001b[39m full_result\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# AAA\u001b[39;00m\n","Cell \u001b[1;32mIn[116], line 100\u001b[0m, in \u001b[0;36mGenerativeAgent._generate_reaction\u001b[1;34m(self, observation, suffix, now)\u001b[0m\n\u001b[0;32m     88\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{agent_summary_description}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIt is \u001b[39m\u001b[38;5;132;01m{current_time}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m     99\u001b[0m agent_summary_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_summary(now\u001b[38;5;241m=\u001b[39mnow)\n\u001b[1;32m--> 100\u001b[0m relevant_memories_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize_related_memories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m current_time_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    102\u001b[0m     datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mB \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mI:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m now \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m now\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mB \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY, \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mI:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    106\u001b[0m kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    107\u001b[0m     agent_summary_description\u001b[38;5;241m=\u001b[39magent_summary_description,\n\u001b[0;32m    108\u001b[0m     current_time\u001b[38;5;241m=\u001b[39mcurrent_time_str,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m     agent_status\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    113\u001b[0m )\n","Cell \u001b[1;32mIn[116], line 77\u001b[0m, in \u001b[0;36mGenerativeAgent.summarize_related_memories\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m     68\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    {q1}?\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m )\n\u001b[0;32m     76\u001b[0m entity_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_entity_from_observation(observation)\n\u001b[1;32m---> 77\u001b[0m entity_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_entity_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m q1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the relationship between \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentity_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m q2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentity_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentity_action\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n","Cell \u001b[1;32mIn[116], line 61\u001b[0m, in \u001b[0;36mGenerativeAgent._get_entity_action\u001b[1;34m(self, observation, entity_name)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_entity_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: \u001b[38;5;28mstr\u001b[39m, entity_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     56\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the \u001b[39m\u001b[38;5;132;01m{entity}\u001b[39;00m\u001b[38;5;124m doing in the following observation? \u001b[39m\u001b[38;5;132;01m{observation}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{entity}\u001b[39;00m\u001b[38;5;124m is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m     )\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m---> 61\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentity_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     62\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:611\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    147\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_openai\\chat_models\\base.py:707\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    705\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\resources\\chat\\completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1277\u001b[0m     )\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:991\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 991\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    997\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:1263\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n","File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:1136\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":131},{"cell_type":"markdown","source":"## Framework 1\n\n\n\nAgents reply in fixed-order, with a set-limit of 'turns'","metadata":{}},{"cell_type":"code","source":"def run_HoC_debate_framework_1 (agents: List[GenerativeAgent],             # get a list of agents\n\n                     initial_observation: str) -> None:         # get the 1st observation\n\n    \"\"\"Runs a conversation between agents.\"\"\"\n\n\n\n    _, observation = agents[4].generate_reaction(initial_observation)   # generate a reaction to observation\n\n    print(observation)\n\n\n\n    max_turns = 2\n\n    turns = 0\n\n\n\n    # Enters a loop where agents take turns generating responses\n\n    while turns < max_turns:\n\n        for agent in agents:\n\n            # Each agent generates a response to the latest observation\n\n            spoken_response, observation = agent.generate_dialogue_response(observation)\n\n            print(observation)\n\n\n\n            if not spoken_response:\n\n                print(f\"{agent.name} chose not to respond.\")\n\n        \n\n        # Increment the turn count after each full round of responses\n\n        turns += 1","metadata":{},"outputs":[],"execution_count":138},{"cell_type":"code","source":"# Run the debate\n\nrun_HoC_debate_framework_1 (agents, initial_observation)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sir Keir Starmer would likely support the idea of the UK rejoining the European Union, as it aligns with his values of inclusivity, social justice, and cooperation.\n","Laura Trott said \"Thank you for sharing your perspective, Sir Keir Starmer. As we continue this debate on whether the UK should rejoin the European Union, I believe it is crucial to carefully assess the potential benefits and drawbacks of such a decision. We must prioritize the economic well-being of our country and ensure that any decisions made are in the best interest of all our citizens. Let's delve deeper into the details and facts to inform our discussion further.\"\n","Boris Johnson said \"Thank you, Laura Trott, for your thoughtful input. It's important to carefully consider all aspects of the debate on whether the UK should rejoin the European Union. As we delve into the details and facts, let's ensure that we prioritize the economic well-being and sovereignty of our country. Let's continue this discussion to make informed decisions that benefit all our citizens.\"\n","Nigel Farage said \"Thank you, Boris Johnson, for your input. While I appreciate the need for careful consideration of all aspects of the debate, I firmly believe that rejoining the EU would be a detrimental move for the UK's sovereignty and economic well-being. Let's prioritize our country's independence and make decisions that truly benefit our citizens. Let's continue this discussion to ensure that the voices of the British people are heard and respected.\"\n","Rishi Sunak said \"I appreciate both perspectives in this debate. As a former Prime Minister, I understand the importance of carefully weighing the implications of rejoining the EU. Let's continue this discussion to ensure that the best interests of the British people are at the forefront of our decision-making process.\"\n","Sir Keir Starmer said \"I appreciate the thoughtful consideration from Rishi Sunak. However, I firmly believe that rejoining the European Union is in the best interests of the British people in terms of economic stability, social cooperation, and international relationships. Let's continue this discussion to ensure a comprehensive and informed decision-making process.\"\n","Laura Trott said \"Thank you, Sir Keir Starmer, for sharing your perspective on rejoining the European Union. It is clear that both economic stability and international relationships are crucial factors to consider in this decision. As we delve deeper into this debate, I believe it is important for us to thoroughly assess the potential benefits and drawbacks of rejoining the EU to ensure that we make the best decision for the British people. Let's continue this discussion with a focus on facts and pragmatic solutions.\"\n","Boris Johnson said \"Thank you, Laura Trott, for your thoughtful input. It's crucial to consider all aspects of the debate on whether the UK should rejoin the European Union. As we analyze the potential benefits and drawbacks, let's prioritize the economic well-being and sovereignty of our country. Let's continue this discussion with a focus on facts and pragmatic solutions. What to say next?\"\n","Nigel Farage said \"Thank you, Boris Johnson, for your input. While I appreciate the need for a thorough analysis of the potential benefits and drawbacks of rejoining the EU, I firmly believe that prioritizing our country's sovereignty and independence should be our top priority. Let's continue this discussion with a focus on upholding British values and making decisions that truly benefit our citizens. What to say next?\"\n","Rishi Sunak said \"Thank you, Nigel Farage, for your perspective on this important issue. I agree that the well-being of our country and its citizens should be our top priority. Let's continue this discussion with a focus on upholding British values and ensuring that any decision made is in the best interest of our nation. What are your thoughts on how we can achieve this balance between sovereignty and economic stability?\"\n","Sir Keir Starmer said \"Thank you, Rishi Sunak, for your perspective and for acknowledging the importance of upholding British values while considering the well-being of our nation. I believe that a balanced approach that prioritizes both sovereignty and economic stability is crucial. We must ensure that any decision made is in the best interest of our country and its citizens. Let's continue this discussion with a focus on collaboration, inclusivity, and a comprehensive analysis of the implications involved. What are your thoughts on how we can achieve this balance effectively?\"\n"]}],"execution_count":136},{"cell_type":"markdown","source":"## Framework 2\n\n\n\nEach agent gets `X`-number of speaking slots allocated randomly","metadata":{}},{"cell_type":"code","source":"def run_HoC_debate_framework_2 (agents: List[GenerativeAgent],\n\n                              initial_observation: str) -> None:\n\n    \"\"\"Runs a conversation between agents, each getting X-number of speaking slots allocated randomly.\"\"\"\n\n\n\n    # Initialize the count of speaking slots for each agent\n\n    max_slot_each = 2\n\n    \n\n    speaking_slots = {agent.name: 0 for agent in agents}\n\n    max_speaking_slots = max_slot_each * len(agents)\n\n    turns = 0\n\n\n\n    # Start the debate with an initial observation\n\n    observation = initial_observation\n\n    print(observation)\n\n\n\n    # Continue the conversation until each agent has spoken twice\n\n    while sum(speaking_slots.values()) < max_speaking_slots:\n\n        # Randomly select an agent who hasn't spoken twice yet\n\n        agent = random.choice([agent for agent in agents if speaking_slots[agent.name] < max_slot_each])\n\n        \n\n        # Each agent generates a response to the latest observation\n\n        stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n\n        print(observation)\n\n\n\n        # Increment the speaking slot count for the agent\n\n        speaking_slots[agent.name] += 1\n\n\n\n        # Increment the turn count\n\n        turns += 1","metadata":{},"outputs":[],"execution_count":143},{"cell_type":"code","source":"# Run the debate\n\nrun_HoC_debate_framework_2 (agents, initial_observation)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Should the UK rejoin the European Union?\n","Boris Johnson said \"Thank you for bringing up this important topic. As we consider the possibility of rejoining the European Union, it is crucial to prioritize the economic well-being and sovereignty of our country. Let us delve deeper into the details and facts to inform our decision-making process. What are the potential benefits and drawbacks we need to consider in this debate?\"\n","Rishi Sunak said \"Thank you, Boris Johnson, for highlighting the importance of considering the economic well-being and sovereignty of our country in the debate on rejoining the European Union. I believe that a thorough analysis of the potential benefits and drawbacks is essential before making any decision. Let's continue this discussion with a focus on upholding British values and ensuring that any decision made truly benefits our citizens. What are your thoughts on how we can achieve this balance effectively?\"\n","Sir Keir Starmer said \"Thank you, Rishi Sunak, for your perspective on the importance of considering economic well-being and sovereignty in the discussion on rejoining the European Union. I agree that a comprehensive analysis of the potential benefits and drawbacks is crucial before making any decision. Let's continue this conversation with a focus on upholding British values and ensuring that any decision made truly benefits our citizens. What are your thoughts on how we can achieve this balance effectively?\"\n","Laura Trott said \"Thank you, Sir Keir Starmer, for your thoughtful response. I agree that a comprehensive analysis of the potential benefits and drawbacks is essential in making a decision of this magnitude. As we continue this debate, let's ensure that we prioritize the economic well-being and sovereignty of our country while also considering the values and interests of our citizens. How do you propose we strike this balance effectively in our decision-making process?\"\n","Rishi Sunak said \"Thank you, Laura Trott, for your insightful input. I agree that striking a balance between economic well-being, sovereignty, and the values of our citizens is crucial in this decision-making process. As we delve deeper into this debate, let's continue to prioritize the best interests of our country and its people. What specific strategies do you propose to achieve this balance effectively?\"\n","Laura Trott said \"Thank you, Rishi Sunak, for your acknowledgment of the importance of balancing economic well-being, sovereignty, and the values of our citizens in this decision-making process. I believe that a thorough analysis of the potential benefits and drawbacks is essential to ensure that we make the best decision for our country. Moving forward, I propose that we focus on pragmatic economic solutions and responsible budgeting to prioritize the economic well-being of our nation while also considering the values and interests of our citizens. How do you suggest we implement these strategies effectively in our decision-making process?\"\n","Nigel Farage said \"Thank you, Laura Trott, for your thoughtful input. While I agree that balancing economic well-being, sovereignty, and the values of our citizens is crucial, I believe that prioritizing British sovereignty and independence should be our top priority. I suggest that we focus on policies that promote domestic industry, strict immigration controls, and traditional British values to truly benefit our nation. How do you propose we implement these strategies effectively in our decision-making process?\"\n","Boris Johnson said \"Thank you, Nigel Farage, for sharing your perspective. I agree that prioritizing British sovereignty and independence is crucial in our decision-making process. To implement these strategies effectively, we must focus on policies that support domestic industry, uphold strict immigration controls, and preserve traditional British values. By working together, we can ensure that our nation's best interests are at the forefront of our decisions. Let's continue this discussion to explore practical solutions that benefit all our citizens.\"\n","Nigel Farage said \"Thank you, Boris Johnson, for acknowledging the importance of prioritizing British sovereignty and independence in our decision-making process. I believe that focusing on policies that support domestic industry, strict immigration controls, and traditional British values is crucial for the well-being of our nation. Let's work together to ensure that our decisions truly benefit all our citizens. What practical solutions do you suggest we explore further in our discussion?\"\n","Sir Keir Starmer said \"Thank you, Nigel Farage, for sharing your perspective on prioritizing British sovereignty and independence. I believe that a balance between sovereignty and economic stability is crucial for the well-being of our nation. Let's continue this discussion with a focus on upholding British values, ensuring fairness for all citizens, and exploring practical solutions that benefit our country as a whole. What specific policies do you suggest we consider to achieve this balance effectively?\"\n"]}],"execution_count":144},{"cell_type":"markdown","source":"## Framework 3\n\n\n\n1. Each agent add new-observation into memory. \n\n2. Each agent does a quick reflection on this new-observation, to whether to \"respond or not respond\" - depending on personal saliency (a custom function within the class `GenerativeAgent`). Output `decide_to_respond` as either True or False\n\n3. Randomly select one agent from the list of agents that decide to respond to the observation.\n\n4. Print this selected generate_dialogue_response as the new observation.","metadata":{}},{"cell_type":"code","source":"# Testing the `decide_to_respond()` function for each agent\n\n\n\nrandom_observation = \"Should the official UK national dish be changed??\"\n\n\n\n# Who would respond to the observation? Trott, Johnson, Farage, Sunak, Starmer\n\nprint(Trott.decide_to_respond(random_observation))\n\nprint(Johnson.decide_to_respond(random_observation))\n\nprint(Farage.decide_to_respond(random_observation))\n\nprint(Sunak.decide_to_respond(random_observation))\n\nprint(Starmer.decide_to_respond(random_observation))","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n","True\n","False\n","True\n","True\n"]}],"execution_count":42},{"cell_type":"code","source":"# Testing the `generate_dialogue_response()` function for each agent\n\nTrott.generate_dialogue_response(initial_observation)","metadata":{},"outputs":[{"data":{"text/plain":["(True,\n"," 'Laura Trott said As a Conservative MP, I believe that the decision for the UK to leave the European Union was made by the British people in a democratic referendum. While there are certainly benefits to being part of the EU, I also understand and respect the reasons for Brexit. As we move forward, it is important for us to focus on building strong relationships with our European neighbors while also maintaining our sovereignty and independence as a nation.')"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"execution_count":80},{"cell_type":"code","source":"def run_HoC_debate_framework_3 (agents: List[GenerativeAgent],             # get a list of agents\n\n                     initial_observation: str) -> None:         # get the 1st observation\n\n    \"\"\"Runs a conversation between agents, until a maximum number of turns is reached.\"\"\"\n\n    \n\n    max_turns = 10\n\n    turns = 0\n\n\n\n    # Start the debate with an initial observation\n\n    observation = initial_observation\n\n    print(observation)\n\n\n\n    # Enters a loop where agents take turns generating responses\n\n    while turns < max_turns:\n\n        # Step 1: Each agent adds the new observation into memory\n\n        for agent in agents:\n\n            agent.memory.add_memory(observation)\n\n\n\n        # Step 2: Randomly select one agent from the list of agents that decide to respond to the observation\n\n        responding_agents = [agent for agent in agents if agent.decide_to_respond(observation)]\n\n        if responding_agents:\n\n            agent = random.choice(responding_agents)\n\n            \n\n            # The selected agent generates a response to the latest observation\n\n            stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n\n            print(observation)\n\n        \n\n        # Increment the turn count after each full round of responses\n\n        turns += 1","metadata":{"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"run_HoC_debate_framework_3(agents, initial_observation)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Should the UK rejoin the European Union?\n","Rishi Sunak said Yes, I believe that exploring closer ties with the European Union could be beneficial for the UK. It's important to approach this issue pragmatically and consider the potential benefits for our economy and stability. While I value our independence, I also recognize the advantages of cooperation with our European neighbors.\n","Boris Johnson said Well, Rishi, I appreciate your perspective on exploring closer ties with the EU. However, I believe that maintaining our independence and sovereignty is crucial for the future of our country. While cooperation with our European neighbors is important, we must prioritize British interests and businesses above all else. Let's continue to work together to find the best path forward for the UK.\n","Boris Johnson said I understand the importance of considering all perspectives when it comes to our relationship with the EU. However, we must ensure that any decisions we make prioritize the best interests of the British people and our economy. Let's work together to find a solution that maintains our sovereignty while also fostering beneficial cooperation with our European partners.\n","Laura Trott said I appreciate the sentiment of considering all perspectives. However, I believe that exploring closer ties with the EU could bring potential benefits for our economy and stability. It's important to approach this issue pragmatically and prioritize the best interests of the British people. Let's continue to analyze the situation and find a solution that balances our sovereignty with beneficial cooperation with our European partners.\n","Rishi Sunak said I agree with your perspective, Laura. It's crucial to carefully consider all angles when it comes to our relationship with the EU. Finding a solution that benefits our economy and stability while maintaining our sovereignty is key. Let's continue to analyze the situation and work towards a balanced approach that serves the best interests of the British people.\n","Rishi Sunak said I appreciate your input, Laura. It's important to weigh all perspectives and find a solution that truly serves the best interests of the British people. Let's continue to analyze the situation and work towards a balanced approach that considers both our economy and sovereignty.\n","Laura Trott said Thank you, Rishi. I agree that finding a balanced approach that considers both our economy and sovereignty is crucial. Let's continue our collaborative efforts to analyze the situation and work towards a solution that prioritizes the best interests of the British people.\n","Laura Trott said I appreciate your input, Rishi. It's important to weigh all perspectives and find a solution that truly serves the best interests of the British people. Let's continue to analyze the situation and work towards a balanced approach that considers both our economy and sovereignty.\n","Sir Keir Starmer said I agree with Laura and Rishi's approach. It's essential to consider all perspectives and work towards a balanced solution that serves the best interests of the British people. Let's continue to analyze the situation carefully and prioritize the well-being of our economy and sovereignty.\n","Rishi Sunak said I appreciate your agreement, Sir Keir. It's crucial that we continue to carefully analyze the situation and prioritize the well-being of our economy and sovereignty. Let's work together to find a balanced solution that truly serves the best interests of the British people.\n"]}],"execution_count":91},{"cell_type":"code","source":"\n\n# Save Conversation into a text file\n\nimport sys\n\nsys.stdout = open(\"HoC_debate_framework_3_output.txt\", \"w\")\n\nrun_HoC_debate_framework_3 (agents, initial_observation)\n\nsys.stdout.close()","metadata":{},"outputs":[],"execution_count":null}]}