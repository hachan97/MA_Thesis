{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":214523019,"sourceType":"kernelVersion"},{"sourceId":224133583,"sourceType":"kernelVersion"},{"sourceId":224219749,"sourceType":"kernelVersion"},{"sourceId":225018323,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# Standard library imports\nimport pandas as pd\nimport os\nimport re\nimport math\nimport json\nimport random\n\n# Third-party imports\nimport torch\nimport tenacity\nimport openai\n\n# Hugging Face & Langchain imports\nimport transformers\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema import SystemMessage, HumanMessage\n#from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig, pipeline, AutoModel\n#from peft import PeftModel, PeftConfig\n#from langchain_huggingface import HuggingFacePipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T00:27:56.195002Z","iopub.execute_input":"2025-02-28T00:27:56.195544Z","iopub.status.idle":"2025-02-28T00:28:01.302814Z","shell.execute_reply.started":"2025-02-28T00:27:56.195489Z","shell.execute_reply":"2025-02-28T00:28:01.302038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set API Keys\nfrom kaggle_secrets import UserSecretsClient # API Loggins\nuser_secrets = UserSecretsClient()\n\n## Hugging Face\nHugging_Face_token = user_secrets.get_secret(\"Hugging_Face_token\")\nfrom huggingface_hub import login\nlogin(Hugging_Face_token)\n\n## Openai\nOPENAI_API_KEY = user_secrets.get_secret(\"OPENAI_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T00:28:04.21576Z","iopub.execute_input":"2025-02-28T00:28:04.216324Z","iopub.status.idle":"2025-02-28T00:28:04.658846Z","shell.execute_reply.started":"2025-02-28T00:28:04.21629Z","shell.execute_reply":"2025-02-28T00:28:04.657866Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"df_pairs_TheresaMay = pd.read_csv('/kaggle/input/parlspeech-eda-ipynb/df_pairs_TheresaMay.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T00:28:06.736103Z","iopub.execute_input":"2025-02-28T00:28:06.736485Z","iopub.status.idle":"2025-02-28T00:28:07.0912Z","shell.execute_reply.started":"2025-02-28T00:28:06.736453Z","shell.execute_reply":"2025-02-28T00:28:07.090165Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"LLM_gpt = ChatOpenAI(model=\"gpt-3.5-turbo\", \n                 max_tokens=1500, \n                 api_key = OPENAI_API_KEY) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T15:14:05.754108Z","iopub.execute_input":"2025-02-27T15:14:05.754534Z","iopub.status.idle":"2025-02-27T15:14:05.794205Z","shell.execute_reply.started":"2025-02-27T15:14:05.754496Z","shell.execute_reply":"2025-02-27T15:14:05.792667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run Inferencing\nSYSTEM_PROMPT = \"\"\"You are David Cameron, a politician in the UK's House of Commons.\nYou are responding to statements in the House of Commons.\nRespond exactly as David Cameron would speak, staying fully in character and address the observation directly.\n\"\"\"\n\ndef build_chat_prompt(observation: str):\n    return [SystemMessage(content=SYSTEM_PROMPT),\n            HumanMessage(content=observation) ]\n\ndf_pairs_TheresaMay[\"model_response\"] = df_pairs_TheresaMay[\"prompt\"].apply(\n    lambda obs: LLM_gpt(build_chat_prompt(obs)).content  # Extract the text content\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T15:19:08.89238Z","iopub.execute_input":"2025-02-27T15:19:08.892718Z","iopub.status.idle":"2025-02-27T15:19:14.701686Z","shell.execute_reply.started":"2025-02-27T15:19:08.892694Z","shell.execute_reply":"2025-02-27T15:19:14.699899Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_pairs_TheresaMay.to_csv('/kaggle/working/df_pairs_TheresaMay_simulated_Gpt3.5.csv', index=False)\n# df_pairs_TheresaMay.to_csv('/kaggle/working/df_pairs_TheresaMay_simulated_Gpt3.5.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T21:30:12.898803Z","iopub.status.idle":"2025-02-26T21:30:12.899251Z","shell.execute_reply.started":"2025-02-26T21:30:12.89902Z","shell.execute_reply":"2025-02-26T21:30:12.899042Z"}},"outputs":[],"execution_count":null}]}