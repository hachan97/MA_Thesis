{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10280888,"sourceType":"datasetVersion","datasetId":6361952},{"sourceId":180724,"sourceType":"modelInstanceVersion","modelInstanceId":154008,"modelId":176490}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# Standard library imports\nimport pandas as pd\nimport os\nimport re\nimport math\nimport json\nimport random\nimport functools\nfrom datetime import datetime, timedelta\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\nfrom collections import OrderedDict\n\n# Third-party imports\nimport torch\nimport openai\nimport faiss\nimport tenacity\n\n# LangChain imports\nfrom langchain.utils import mock_now\nfrom langchain.docstore import InMemoryDocstore\nfrom langchain.retrievers import TimeWeightedVectorStoreRetriever\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.chains import LLMChain\nfrom langchain_core.language_models import BaseLanguageModel\nfrom langchain.prompts import PromptTemplate\nfrom langchain.schema import HumanMessage, SystemMessage, BaseMemory, Document\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.output_parsers import RegexParser\n\n# Pydantic imports\nfrom pydantic import BaseModel, Field, ConfigDict\n\n# Hugging Face imports\nimport transformers\nfrom transformers import (AutoModelForCausalLM, AutoTokenizer, AutoConfig, pipeline, AutoModel)\nfrom peft import PeftModel, PeftConfig\nfrom langchain_huggingface import HuggingFacePipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T00:57:48.140840Z","iopub.execute_input":"2025-01-11T00:57:48.141169Z","iopub.status.idle":"2025-01-11T00:57:48.147362Z","shell.execute_reply.started":"2025-01-11T00:57:48.141138Z","shell.execute_reply":"2025-01-11T00:57:48.146582Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Set API Keys\nfrom kaggle_secrets import UserSecretsClient # API Loggins\nuser_secrets = UserSecretsClient()\n\n## Hugging Face\nHugging_Face_token = user_secrets.get_secret(\"Hugging_Face_token\")\n\n## Openai\nOPENAI_API_KEY = user_secrets.get_secret(\"OPENAI_API_KEY\")\n\n#from dotenv import load_dotenv # Get OPENAI_API_KEY from .env file\n#load_dotenv()\n#openai.api_key = os.getenv(\"OPENAI_API_KEY\") # Set API Key\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T00:57:47.840969Z","iopub.execute_input":"2025-01-11T00:57:47.841485Z","iopub.status.idle":"2025-01-11T00:57:48.139138Z","shell.execute_reply.started":"2025-01-11T00:57:47.841456Z","shell.execute_reply":"2025-01-11T00:57:48.138260Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Login to Hugging Face\nfrom huggingface_hub import login\n\nlogin(Hugging_Face_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T00:57:48.148309Z","iopub.execute_input":"2025-01-11T00:57:48.148648Z","iopub.status.idle":"2025-01-11T00:57:48.271426Z","shell.execute_reply.started":"2025-01-11T00:57:48.148601Z","shell.execute_reply":"2025-01-11T00:57:48.270742Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"df_HoC_2000s_raw = pd.read_csv('/kaggle/input/parlspeech/df_HoC_2000s.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T00:57:48.272223Z","iopub.execute_input":"2025-01-11T00:57:48.272460Z","iopub.status.idle":"2025-01-11T00:58:23.273564Z","shell.execute_reply.started":"2025-01-11T00:57:48.272437Z","shell.execute_reply":"2025-01-11T00:58:23.272845Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df_HoC_2000s = df_HoC_2000s_raw[['date', 'agenda', 'speechnumber', 'speaker', 'party','text']]\ndf_HoC_2000s.columns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T00:58:23.274446Z","iopub.execute_input":"2025-01-11T00:58:23.274731Z","iopub.status.idle":"2025-01-11T00:58:23.352106Z","shell.execute_reply.started":"2025-01-11T00:58:23.274702Z","shell.execute_reply":"2025-01-11T00:58:23.351222Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Index(['date', 'agenda', 'speechnumber', 'speaker', 'party', 'text'], dtype='object')"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"count_unique_agenda = df_HoC_2000s[df_HoC_2000s['speaker'] == 'Boris Johnson']['agenda'].nunique()\nprint(count_unique_agenda)\n\ntotal_unique_agenda = df_HoC_2000s['agenda'].nunique()\nprint(total_unique_agenda)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T00:58:23.353134Z","iopub.execute_input":"2025-01-11T00:58:23.353436Z","iopub.status.idle":"2025-01-11T00:58:23.492006Z","shell.execute_reply.started":"2025-01-11T00:58:23.353378Z","shell.execute_reply":"2025-01-11T00:58:23.491278Z"}},"outputs":[{"name":"stdout","text":"207\n37114\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"df_HoC_2015 = df_HoC_2000s[df_HoC_2000s['date'].str.contains('2015', na=False)]\ndf_HoC_2015_Johnson = df_HoC_2015[df_HoC_2015['speaker'].str.contains('Boris Johnson', na=False)]\ndf_HoC_2015\ndf_HoC_2015_Johnson","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T00:58:51.378562Z","iopub.execute_input":"2025-01-11T00:58:51.378890Z","iopub.status.idle":"2025-01-11T00:58:51.736568Z","shell.execute_reply.started":"2025-01-11T00:58:51.378864Z","shell.execute_reply":"2025-01-11T00:58:51.735637Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"               date                                         agenda  \\\n974170   2015-05-27                          Debate on the Address   \n974190   2015-05-27                          Debate on the Address   \n974639   2015-06-01                           Britain in the World   \n974667   2015-06-01                           Britain in the World   \n974757   2015-06-01                           Britain in the World   \n974759   2015-06-01                           Britain in the World   \n974761   2015-06-01                           Britain in the World   \n978214   2015-06-11  Mental Health (Higher Education Institutions)   \n982141   2015-06-24             Sport and the 2012 Olympics Legacy   \n982144   2015-06-24             Sport and the 2012 Olympics Legacy   \n982153   2015-06-24             Sport and the 2012 Olympics Legacy   \n982221   2015-06-24             Sport and the 2012 Olympics Legacy   \n982223   2015-06-24             Sport and the 2012 Olympics Legacy   \n982225   2015-06-24             Sport and the 2012 Olympics Legacy   \n982239   2015-06-24             Sport and the 2012 Olympics Legacy   \n987827   2015-07-13      Budget Resolutions and Economic Situation   \n987829   2015-07-13      Budget Resolutions and Economic Situation   \n987852   2015-07-13      Budget Resolutions and Economic Situation   \n988767   2015-07-15                                   Water Cannon   \n988795   2015-07-15                                   Water Cannon   \n991387   2015-09-07          Syria: Refugees and Counter-terrorism   \n993818   2015-09-14                               Trade Union Bill   \n993820   2015-09-14                               Trade Union Bill   \n993824   2015-09-14                               Trade Union Bill   \n993984   2015-09-14                               Trade Union Bill   \n993985   2015-09-14                               Trade Union Bill   \n993986   2015-09-14                               Trade Union Bill   \n993988   2015-09-14                               Trade Union Bill   \n993990   2015-09-14                               Trade Union Bill   \n993992   2015-09-14                               Trade Union Bill   \n1003684  2015-11-02                      Housing and Planning Bill   \n1003809  2015-11-02                      Housing and Planning Bill   \n1012232  2015-11-26              Airports Commission: Final Report   \n1012234  2015-11-26              Airports Commission: Final Report   \n1012236  2015-11-26              Airports Commission: Final Report   \n1012248  2015-11-26              Airports Commission: Final Report   \n1012289  2015-11-26              Airports Commission: Final Report   \n1017858  2015-12-15                                        Housing   \n1017907  2015-12-15                                        Housing   \n1018724  2015-12-16                    West London Coroner's Court   \n\n         speechnumber        speaker party  \\\n974170             97  Boris Johnson   Con   \n974190            117  Boris Johnson   Con   \n974639             90  Boris Johnson   Con   \n974667            118  Boris Johnson   Con   \n974757            208  Boris Johnson   Con   \n974759            210  Boris Johnson   Con   \n974761            212  Boris Johnson   Con   \n978214            531  Boris Johnson   Con   \n982141            362  Boris Johnson   Con   \n982144            365  Boris Johnson   Con   \n982153            374  Boris Johnson   Con   \n982221            442  Boris Johnson   Con   \n982223            444  Boris Johnson   Con   \n982225            446  Boris Johnson   Con   \n982239            460  Boris Johnson   Con   \n987827            199  Boris Johnson   Con   \n987829            201  Boris Johnson   Con   \n987852            224  Boris Johnson   Con   \n988767            231  Boris Johnson   Con   \n988795            259  Boris Johnson   Con   \n991387            214  Boris Johnson   Con   \n993818            332  Boris Johnson   Con   \n993820            334  Boris Johnson   Con   \n993824            338  Boris Johnson   Con   \n993984            498  Boris Johnson   Con   \n993985            499  Boris Johnson   Con   \n993986            500  Boris Johnson   Con   \n993988            502  Boris Johnson   Con   \n993990            504  Boris Johnson   Con   \n993992            506  Boris Johnson   Con   \n1003684           209  Boris Johnson   Con   \n1003809           334  Boris Johnson   Con   \n1012232           491  Boris Johnson   Con   \n1012234           493  Boris Johnson   Con   \n1012236           495  Boris Johnson   Con   \n1012248           507  Boris Johnson   Con   \n1012289           548  Boris Johnson   Con   \n1017858           369  Boris Johnson   Con   \n1017907           418  Boris Johnson   Con   \n1018724           602  Boris Johnson   Con   \n\n                                                      text  \n974170   Does my right hon. Friend agree that her const...  \n974190   I wish the right hon. Gentleman every good for...  \n974639   My right hon. Friend is speaking very well abo...  \n974667   I may have missed something. Could the right h...  \n974757   I congratulate the hon. Member for St Helens N...  \n974759   I am delighted that my hon. Friend reminds me ...  \n974761   I am obliged, because it is absolutely right t...  \n978214   I thank my hon. Friend and brother for giving ...  \n982141   Will the hon. Gentleman give way? He is talkin...  \n982144   If the sporting legacy from the Olympic games ...  \n982153   I will agree with the hon. Gentleman on that. ...  \n982221   The debate has improved steadily as it has gon...  \n982223   I wholeheartedly agree that €squandering” is t...  \n982225   Absolutely-I acknowledge that completely. I ac...  \n982239   The hon. Gentleman is saying some sensible thi...  \n987827               Will the Secretary of State give way?  \n987829   I just want to thank the Secretary of State an...  \n987852   The reality is, as I am sure the hon. Lady wou...  \n988767   I thank the Home Secretary very much for her s...  \n988795                     I am most grateful, Mr Speaker.  \n991387   Having seen at first hand the work of DFID off...  \n993818   I am happy to inform the House that the previo...  \n993820   I tell the right hon. Gentleman that not only ...  \n993824   Does the right hon. Gentleman accept that plen...  \n993984   You are very kind, Mr Speaker. What the Bill i...  \n993985   If the hon. Gentleman will forgive me, I will ...  \n993986              I will give way to the hon. Gentleman.  \n993988   I am grateful to the hon. Gentleman for the ex...  \n993990   Only 24% of London bus drivers decided to vote...  \n993992   The hon. Gentleman will be familiar with the c...  \n1003684  I congratulate my right hon. Friend on the arg...  \n1003809  Labour is making many mistakes in opposing thi...  \n1012232  Funnily enough, I think that there are some go...  \n1012234  My hon. Friend makes a very good point. As he ...  \n1012236  That is a fair question. The answer is that th...  \n1012248  Further to the previous intervention, I remind...  \n1012289  I hesitate to remind my hon. Friend of what ha...  \n1017858  I ask the right hon. Gentleman to clear up one...  \n1017907  I congratulate my hon. Friend on his remarks, ...  \n1018724  I congratulate my hon. Friend on securing this...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>agenda</th>\n      <th>speechnumber</th>\n      <th>speaker</th>\n      <th>party</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>974170</th>\n      <td>2015-05-27</td>\n      <td>Debate on the Address</td>\n      <td>97</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Does my right hon. Friend agree that her const...</td>\n    </tr>\n    <tr>\n      <th>974190</th>\n      <td>2015-05-27</td>\n      <td>Debate on the Address</td>\n      <td>117</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I wish the right hon. Gentleman every good for...</td>\n    </tr>\n    <tr>\n      <th>974639</th>\n      <td>2015-06-01</td>\n      <td>Britain in the World</td>\n      <td>90</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>My right hon. Friend is speaking very well abo...</td>\n    </tr>\n    <tr>\n      <th>974667</th>\n      <td>2015-06-01</td>\n      <td>Britain in the World</td>\n      <td>118</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I may have missed something. Could the right h...</td>\n    </tr>\n    <tr>\n      <th>974757</th>\n      <td>2015-06-01</td>\n      <td>Britain in the World</td>\n      <td>208</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I congratulate the hon. Member for St Helens N...</td>\n    </tr>\n    <tr>\n      <th>974759</th>\n      <td>2015-06-01</td>\n      <td>Britain in the World</td>\n      <td>210</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am delighted that my hon. Friend reminds me ...</td>\n    </tr>\n    <tr>\n      <th>974761</th>\n      <td>2015-06-01</td>\n      <td>Britain in the World</td>\n      <td>212</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am obliged, because it is absolutely right t...</td>\n    </tr>\n    <tr>\n      <th>978214</th>\n      <td>2015-06-11</td>\n      <td>Mental Health (Higher Education Institutions)</td>\n      <td>531</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I thank my hon. Friend and brother for giving ...</td>\n    </tr>\n    <tr>\n      <th>982141</th>\n      <td>2015-06-24</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>362</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Will the hon. Gentleman give way? He is talkin...</td>\n    </tr>\n    <tr>\n      <th>982144</th>\n      <td>2015-06-24</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>365</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>If the sporting legacy from the Olympic games ...</td>\n    </tr>\n    <tr>\n      <th>982153</th>\n      <td>2015-06-24</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>374</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I will agree with the hon. Gentleman on that. ...</td>\n    </tr>\n    <tr>\n      <th>982221</th>\n      <td>2015-06-24</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>442</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>The debate has improved steadily as it has gon...</td>\n    </tr>\n    <tr>\n      <th>982223</th>\n      <td>2015-06-24</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>444</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I wholeheartedly agree that €squandering” is t...</td>\n    </tr>\n    <tr>\n      <th>982225</th>\n      <td>2015-06-24</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>446</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Absolutely-I acknowledge that completely. I ac...</td>\n    </tr>\n    <tr>\n      <th>982239</th>\n      <td>2015-06-24</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>460</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>The hon. Gentleman is saying some sensible thi...</td>\n    </tr>\n    <tr>\n      <th>987827</th>\n      <td>2015-07-13</td>\n      <td>Budget Resolutions and Economic Situation</td>\n      <td>199</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Will the Secretary of State give way?</td>\n    </tr>\n    <tr>\n      <th>987829</th>\n      <td>2015-07-13</td>\n      <td>Budget Resolutions and Economic Situation</td>\n      <td>201</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I just want to thank the Secretary of State an...</td>\n    </tr>\n    <tr>\n      <th>987852</th>\n      <td>2015-07-13</td>\n      <td>Budget Resolutions and Economic Situation</td>\n      <td>224</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>The reality is, as I am sure the hon. Lady wou...</td>\n    </tr>\n    <tr>\n      <th>988767</th>\n      <td>2015-07-15</td>\n      <td>Water Cannon</td>\n      <td>231</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I thank the Home Secretary very much for her s...</td>\n    </tr>\n    <tr>\n      <th>988795</th>\n      <td>2015-07-15</td>\n      <td>Water Cannon</td>\n      <td>259</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am most grateful, Mr Speaker.</td>\n    </tr>\n    <tr>\n      <th>991387</th>\n      <td>2015-09-07</td>\n      <td>Syria: Refugees and Counter-terrorism</td>\n      <td>214</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Having seen at first hand the work of DFID off...</td>\n    </tr>\n    <tr>\n      <th>993818</th>\n      <td>2015-09-14</td>\n      <td>Trade Union Bill</td>\n      <td>332</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am happy to inform the House that the previo...</td>\n    </tr>\n    <tr>\n      <th>993820</th>\n      <td>2015-09-14</td>\n      <td>Trade Union Bill</td>\n      <td>334</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I tell the right hon. Gentleman that not only ...</td>\n    </tr>\n    <tr>\n      <th>993824</th>\n      <td>2015-09-14</td>\n      <td>Trade Union Bill</td>\n      <td>338</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Does the right hon. Gentleman accept that plen...</td>\n    </tr>\n    <tr>\n      <th>993984</th>\n      <td>2015-09-14</td>\n      <td>Trade Union Bill</td>\n      <td>498</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>You are very kind, Mr Speaker. What the Bill i...</td>\n    </tr>\n    <tr>\n      <th>993985</th>\n      <td>2015-09-14</td>\n      <td>Trade Union Bill</td>\n      <td>499</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>If the hon. Gentleman will forgive me, I will ...</td>\n    </tr>\n    <tr>\n      <th>993986</th>\n      <td>2015-09-14</td>\n      <td>Trade Union Bill</td>\n      <td>500</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I will give way to the hon. Gentleman.</td>\n    </tr>\n    <tr>\n      <th>993988</th>\n      <td>2015-09-14</td>\n      <td>Trade Union Bill</td>\n      <td>502</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am grateful to the hon. Gentleman for the ex...</td>\n    </tr>\n    <tr>\n      <th>993990</th>\n      <td>2015-09-14</td>\n      <td>Trade Union Bill</td>\n      <td>504</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Only 24% of London bus drivers decided to vote...</td>\n    </tr>\n    <tr>\n      <th>993992</th>\n      <td>2015-09-14</td>\n      <td>Trade Union Bill</td>\n      <td>506</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>The hon. Gentleman will be familiar with the c...</td>\n    </tr>\n    <tr>\n      <th>1003684</th>\n      <td>2015-11-02</td>\n      <td>Housing and Planning Bill</td>\n      <td>209</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I congratulate my right hon. Friend on the arg...</td>\n    </tr>\n    <tr>\n      <th>1003809</th>\n      <td>2015-11-02</td>\n      <td>Housing and Planning Bill</td>\n      <td>334</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Labour is making many mistakes in opposing thi...</td>\n    </tr>\n    <tr>\n      <th>1012232</th>\n      <td>2015-11-26</td>\n      <td>Airports Commission: Final Report</td>\n      <td>491</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Funnily enough, I think that there are some go...</td>\n    </tr>\n    <tr>\n      <th>1012234</th>\n      <td>2015-11-26</td>\n      <td>Airports Commission: Final Report</td>\n      <td>493</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>My hon. Friend makes a very good point. As he ...</td>\n    </tr>\n    <tr>\n      <th>1012236</th>\n      <td>2015-11-26</td>\n      <td>Airports Commission: Final Report</td>\n      <td>495</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>That is a fair question. The answer is that th...</td>\n    </tr>\n    <tr>\n      <th>1012248</th>\n      <td>2015-11-26</td>\n      <td>Airports Commission: Final Report</td>\n      <td>507</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Further to the previous intervention, I remind...</td>\n    </tr>\n    <tr>\n      <th>1012289</th>\n      <td>2015-11-26</td>\n      <td>Airports Commission: Final Report</td>\n      <td>548</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I hesitate to remind my hon. Friend of what ha...</td>\n    </tr>\n    <tr>\n      <th>1017858</th>\n      <td>2015-12-15</td>\n      <td>Housing</td>\n      <td>369</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I ask the right hon. Gentleman to clear up one...</td>\n    </tr>\n    <tr>\n      <th>1017907</th>\n      <td>2015-12-15</td>\n      <td>Housing</td>\n      <td>418</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I congratulate my hon. Friend on his remarks, ...</td>\n    </tr>\n    <tr>\n      <th>1018724</th>\n      <td>2015-12-16</td>\n      <td>West London Coroner's Court</td>\n      <td>602</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I congratulate my hon. Friend on securing this...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"def process_and_preview_bounded_dialogues(df):\n    \"\"\"\n    Filters bounded dialogue chunks for Boris Johnson, includes 3 preceding and 3 succeeding speeches,\n    and returns the filtered dataset for preview.\n    \"\"\"\n    grouped = df.groupby(['date', 'agenda'])  # Group by date and agenda\n    filtered_data = []\n\n    for (date, agenda), group in grouped:\n        group = group.sort_values(by='speechnumber')  # Sort by speech order\n\n        # Filter rows where Boris Johnson is the speaker\n        bj_speeches = group[group['speaker'] == \"Boris Johnson\"]\n\n        # Skip if no Boris Johnson speeches are found\n        if bj_speeches.empty:\n            continue\n\n        # Find the first and last appearance of Boris Johnson\n        first_idx = bj_speeches.index[0]\n        last_idx = bj_speeches.index[-1]\n\n        # Get the boundaries: 3 preceding rows from the first appearance and 3 succeeding rows from the last appearance\n        start_idx = max(0, first_idx - 3)  # Ensure index doesn't go below 0\n        end_idx = min(len(group), last_idx + 4)  # Include 3 succeeding rows (hence +4)\n\n        # Extract the bounded dialogue chunk\n        bounded_chunk = group.iloc[start_idx:end_idx]\n\n        # Collect the filtered data\n        for _, row in bounded_chunk.iterrows():\n            filtered_data.append({\n                \"date\": row['date'],\n                \"agenda\": row['agenda'],\n                \"speaker\": row['speaker'],\n                \"party\": row['party'],\n                \"text\": row['text']\n            })\n\n    # Convert the collected data to a DataFrame for preview\n    filtered_df = pd.DataFrame(filtered_data)\n    return filtered_df\n\n# Example usage\nfiltered_df = process_and_preview_bounded_dialogues(df_HoC_2015)\nfiltered_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T01:01:36.019866Z","iopub.execute_input":"2025-01-11T01:01:36.020615Z","iopub.status.idle":"2025-01-11T01:01:37.248458Z","shell.execute_reply.started":"2025-01-11T01:01:36.020581Z","shell.execute_reply":"2025-01-11T01:01:37.247667Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: []\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"def process_and_add_bounded_dialogues(df, agent_memory):\n    \"\"\"\n    Add bounded dialogue chunks as memories for Boris Johnson.\n    Includes 3 preceding speeches from the first appearance and 3 succeeding speeches from the last appearance.\n    \"\"\"\n    grouped = df.groupby(['date', 'agenda'])  # Group by date and agenda\n\n    for (date, agenda), group in grouped:\n        group = group.sort_values(by='speechnumber')  # Sort by speech order\n\n        # Filter rows where Boris Johnson is the speaker\n        bj_speeches = group[group['speaker'] == \"Boris Johnson\"]\n\n        # Skip if no Boris Johnson speeches are found\n        if bj_speeches.empty:\n            continue\n\n        # Find the first and last appearance of Boris Johnson\n        first_idx = bj_speeches.index[0]\n        last_idx = bj_speeches.index[-1]\n\n        # Get the boundaries: 3 preceding rows from the first appearance and 3 succeeding rows from the last appearance\n        start_idx = max(0, first_idx - 3)  # Ensure index doesn't go below 0\n        end_idx = min(len(group), last_idx + 4)  # Include 3 succeeding rows (hence +4)\n\n        # Extract the bounded dialogue chunk\n        bounded_chunk = group.iloc[start_idx:end_idx]\n\n        # Format the bounded dialogue chunk\n        dialogue_text = \"\\n\".join(\n            f\"{r['speaker']} ({r['party']}): {r['text']}\" for _, r in bounded_chunk.iterrows()\n        )\n        observation = (\n            f\"Date: {date}\\n\"\n            f\"Agenda: {agenda}\\n\"\n            f\"Dialogue:\\n{dialogue_text}\"\n        )\n\n        # Set the memory timestamp to the date with a fixed time (e.g., 10:00 AM)\n        memory_date = datetime.strptime(date, \"%m/%d/%Y\").replace(hour=10, minute=0, second=0)\n\n        # Add the memory as a single document\n        agent_memory.add_historical_memory(memory_content=observation, memory_date=memory_date)\n\n\n# Example usage\nfiltered_df = process_and_preview_single_speeches(df_HoC_2015)\nfiltered_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:22:27.769420Z","iopub.execute_input":"2025-01-09T18:22:27.769791Z","iopub.status.idle":"2025-01-09T18:22:29.367537Z","shell.execute_reply.started":"2025-01-09T18:22:27.769756Z","shell.execute_reply":"2025-01-09T18:22:29.366648Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                  date                                         agenda  \\\n0  2015-05-27 10:00:00                          Debate on the Address   \n1  2015-05-27 10:03:00                          Debate on the Address   \n2  2015-06-01 10:00:00                           Britain in the World   \n3  2015-06-01 10:03:00                           Britain in the World   \n4  2015-06-01 10:06:00                           Britain in the World   \n5  2015-06-01 10:09:00                           Britain in the World   \n6  2015-06-01 10:12:00                           Britain in the World   \n7  2015-06-11 10:00:00  Mental Health (Higher Education Institutions)   \n8  2015-06-24 10:00:00             Sport and the 2012 Olympics Legacy   \n9  2015-06-24 10:03:00             Sport and the 2012 Olympics Legacy   \n10 2015-06-24 10:06:00             Sport and the 2012 Olympics Legacy   \n11 2015-06-24 10:09:00             Sport and the 2012 Olympics Legacy   \n12 2015-06-24 10:12:00             Sport and the 2012 Olympics Legacy   \n13 2015-06-24 10:15:00             Sport and the 2012 Olympics Legacy   \n14 2015-06-24 10:18:00             Sport and the 2012 Olympics Legacy   \n15 2015-07-13 10:00:00      Budget Resolutions and Economic Situation   \n16 2015-07-13 10:03:00      Budget Resolutions and Economic Situation   \n17 2015-07-13 10:06:00      Budget Resolutions and Economic Situation   \n18 2015-07-15 10:00:00                                   Water Cannon   \n19 2015-07-15 10:03:00                                   Water Cannon   \n20 2015-09-07 10:00:00          Syria: Refugees and Counter-terrorism   \n21 2015-09-14 10:00:00                               Trade Union Bill   \n22 2015-09-14 10:03:00                               Trade Union Bill   \n23 2015-09-14 10:06:00                               Trade Union Bill   \n24 2015-09-14 10:09:00                               Trade Union Bill   \n25 2015-09-14 10:12:00                               Trade Union Bill   \n26 2015-09-14 10:15:00                               Trade Union Bill   \n27 2015-09-14 10:18:00                               Trade Union Bill   \n28 2015-09-14 10:21:00                               Trade Union Bill   \n29 2015-09-14 10:24:00                               Trade Union Bill   \n30 2015-11-02 10:00:00                      Housing and Planning Bill   \n31 2015-11-02 10:03:00                      Housing and Planning Bill   \n32 2015-11-26 10:00:00              Airports Commission: Final Report   \n33 2015-11-26 10:03:00              Airports Commission: Final Report   \n34 2015-11-26 10:06:00              Airports Commission: Final Report   \n35 2015-11-26 10:09:00              Airports Commission: Final Report   \n36 2015-11-26 10:12:00              Airports Commission: Final Report   \n37 2015-12-15 10:00:00                                        Housing   \n38 2015-12-15 10:03:00                                        Housing   \n39 2015-12-16 10:00:00                    West London Coroner's Court   \n\n          speaker party                                               text  \\\n0   Boris Johnson   Con  Does my right hon. Friend agree that her const...   \n1   Boris Johnson   Con  I wish the right hon. Gentleman every good for...   \n2   Boris Johnson   Con  My right hon. Friend is speaking very well abo...   \n3   Boris Johnson   Con  I may have missed something. Could the right h...   \n4   Boris Johnson   Con  I congratulate the hon. Member for St Helens N...   \n5   Boris Johnson   Con  I am delighted that my hon. Friend reminds me ...   \n6   Boris Johnson   Con  I am obliged, because it is absolutely right t...   \n7   Boris Johnson   Con  I thank my hon. Friend and brother for giving ...   \n8   Boris Johnson   Con  Will the hon. Gentleman give way? He is talkin...   \n9   Boris Johnson   Con  If the sporting legacy from the Olympic games ...   \n10  Boris Johnson   Con  I will agree with the hon. Gentleman on that. ...   \n11  Boris Johnson   Con  The debate has improved steadily as it has gon...   \n12  Boris Johnson   Con  I wholeheartedly agree that €squandering” is t...   \n13  Boris Johnson   Con  Absolutely-I acknowledge that completely. I ac...   \n14  Boris Johnson   Con  The hon. Gentleman is saying some sensible thi...   \n15  Boris Johnson   Con              Will the Secretary of State give way?   \n16  Boris Johnson   Con  I just want to thank the Secretary of State an...   \n17  Boris Johnson   Con  The reality is, as I am sure the hon. Lady wou...   \n18  Boris Johnson   Con  I thank the Home Secretary very much for her s...   \n19  Boris Johnson   Con                    I am most grateful, Mr Speaker.   \n20  Boris Johnson   Con  Having seen at first hand the work of DFID off...   \n21  Boris Johnson   Con  I am happy to inform the House that the previo...   \n22  Boris Johnson   Con  I tell the right hon. Gentleman that not only ...   \n23  Boris Johnson   Con  Does the right hon. Gentleman accept that plen...   \n24  Boris Johnson   Con  You are very kind, Mr Speaker. What the Bill i...   \n25  Boris Johnson   Con  If the hon. Gentleman will forgive me, I will ...   \n26  Boris Johnson   Con             I will give way to the hon. Gentleman.   \n27  Boris Johnson   Con  I am grateful to the hon. Gentleman for the ex...   \n28  Boris Johnson   Con  Only 24% of London bus drivers decided to vote...   \n29  Boris Johnson   Con  The hon. Gentleman will be familiar with the c...   \n30  Boris Johnson   Con  I congratulate my right hon. Friend on the arg...   \n31  Boris Johnson   Con  Labour is making many mistakes in opposing thi...   \n32  Boris Johnson   Con  Funnily enough, I think that there are some go...   \n33  Boris Johnson   Con  My hon. Friend makes a very good point. As he ...   \n34  Boris Johnson   Con  That is a fair question. The answer is that th...   \n35  Boris Johnson   Con  Further to the previous intervention, I remind...   \n36  Boris Johnson   Con  I hesitate to remind my hon. Friend of what ha...   \n37  Boris Johnson   Con  I ask the right hon. Gentleman to clear up one...   \n38  Boris Johnson   Con  I congratulate my hon. Friend on his remarks, ...   \n39  Boris Johnson   Con  I congratulate my hon. Friend on securing this...   \n\n                                              context  \n0   Cheryl Gillan (Con): It is a pleasure to follo...  \n1   Graham Allen (Lab): I suggest that as well as ...  \n2   Philip Hammond (Con): My hon. Friend is absolu...  \n3   Hilary Benn (Lab): I congratulate the right ho...  \n4   Bob Stewart (Con): At the battle of Waterloo, ...  \n5   Stephen Twigg (Lab): I refer to my entries in ...  \n6   Conor McGinn (Lab): Thank you, Mr Deputy Speak...  \n7   Valerie Vaz (Lab): Congratulations, Madam Depu...  \n8   Chris Bryant (Lab): My hon. Friend makes an ex...  \n9   Lyn Brown (Lab): Does my hon. Friend agree tha...  \n10  Mark Spencer (Con): I had the privilege on Sun...  \n11  Caroline Nokes (Con): Last Friday, 2,200 child...  \n12  John Mann (Lab): It is good to see that the cr...  \n13  Seema Malhotra (Lab): I am proud to follow the...  \n14  David Rutley (Con): I, too, pay tribute to the...  \n15  Greg Clark (Con): I do not think that the hon....  \n16  Greg Clark (Con): My hon. Friend, who made a d...  \n17  Emma Reynolds (Lab): We support the local plan...  \n18  Theresa May (Con): I want to inform the House ...  \n19  Keir Starmer (Lab): I spent five years in Nort...  \n20  David Cameron (Con): In the interests of brevi...  \n21  Grahame M Morris (Lab): Is not the number of d...  \n22  Alan Johnson (Lab): I give way to my hon. Frie...  \n23  CHAIR (nan): Order. The hon. Gentleman should ...  \n24  Harry Harpham (Lab): I stand here as a proud t...  \n25  Kate Osamor (Lab): I, too, would like to decla...  \n26  Wes Streeting (Lab): On the increased threshol...  \n27  CHAIR (nan): Now that, after a short flight, t...  \n28  Boris Johnson (Con): If the hon. Gentleman wil...  \n29  Dennis Skinner (Lab): A member of the Bullingd...  \n30  Greg Clark (Con): The advantage of reaching an...  \n31  Richard Bacon (Con): I represent a rural const...  \n32  Andrew Slaughter (Lab): Old Oak Common station...  \n33  Rupa Huq (Lab): Heathrow has been in the backg...  \n34  Rupa Huq (Lab): I thank the hon. Gentleman for...  \n35  Steve Double (Con): I think I am right in sayi...  \n36  Nusrat Ghani (Con): The effect of noise disrup...  \n37  John Healey (Lab): That detail had escaped me,...  \n38  Brandon Lewis (Con): My hon. Friend makes a ve...  \n39  James Berry (Con): That experience is by no me...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>agenda</th>\n      <th>speaker</th>\n      <th>party</th>\n      <th>text</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-05-27 10:00:00</td>\n      <td>Debate on the Address</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Does my right hon. Friend agree that her const...</td>\n      <td>Cheryl Gillan (Con): It is a pleasure to follo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-05-27 10:03:00</td>\n      <td>Debate on the Address</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I wish the right hon. Gentleman every good for...</td>\n      <td>Graham Allen (Lab): I suggest that as well as ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-06-01 10:00:00</td>\n      <td>Britain in the World</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>My right hon. Friend is speaking very well abo...</td>\n      <td>Philip Hammond (Con): My hon. Friend is absolu...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-06-01 10:03:00</td>\n      <td>Britain in the World</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I may have missed something. Could the right h...</td>\n      <td>Hilary Benn (Lab): I congratulate the right ho...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-06-01 10:06:00</td>\n      <td>Britain in the World</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I congratulate the hon. Member for St Helens N...</td>\n      <td>Bob Stewart (Con): At the battle of Waterloo, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2015-06-01 10:09:00</td>\n      <td>Britain in the World</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am delighted that my hon. Friend reminds me ...</td>\n      <td>Stephen Twigg (Lab): I refer to my entries in ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2015-06-01 10:12:00</td>\n      <td>Britain in the World</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am obliged, because it is absolutely right t...</td>\n      <td>Conor McGinn (Lab): Thank you, Mr Deputy Speak...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2015-06-11 10:00:00</td>\n      <td>Mental Health (Higher Education Institutions)</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I thank my hon. Friend and brother for giving ...</td>\n      <td>Valerie Vaz (Lab): Congratulations, Madam Depu...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2015-06-24 10:00:00</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Will the hon. Gentleman give way? He is talkin...</td>\n      <td>Chris Bryant (Lab): My hon. Friend makes an ex...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2015-06-24 10:03:00</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>If the sporting legacy from the Olympic games ...</td>\n      <td>Lyn Brown (Lab): Does my hon. Friend agree tha...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2015-06-24 10:06:00</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I will agree with the hon. Gentleman on that. ...</td>\n      <td>Mark Spencer (Con): I had the privilege on Sun...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2015-06-24 10:09:00</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>The debate has improved steadily as it has gon...</td>\n      <td>Caroline Nokes (Con): Last Friday, 2,200 child...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2015-06-24 10:12:00</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I wholeheartedly agree that €squandering” is t...</td>\n      <td>John Mann (Lab): It is good to see that the cr...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2015-06-24 10:15:00</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Absolutely-I acknowledge that completely. I ac...</td>\n      <td>Seema Malhotra (Lab): I am proud to follow the...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2015-06-24 10:18:00</td>\n      <td>Sport and the 2012 Olympics Legacy</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>The hon. Gentleman is saying some sensible thi...</td>\n      <td>David Rutley (Con): I, too, pay tribute to the...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2015-07-13 10:00:00</td>\n      <td>Budget Resolutions and Economic Situation</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Will the Secretary of State give way?</td>\n      <td>Greg Clark (Con): I do not think that the hon....</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2015-07-13 10:03:00</td>\n      <td>Budget Resolutions and Economic Situation</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I just want to thank the Secretary of State an...</td>\n      <td>Greg Clark (Con): My hon. Friend, who made a d...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2015-07-13 10:06:00</td>\n      <td>Budget Resolutions and Economic Situation</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>The reality is, as I am sure the hon. Lady wou...</td>\n      <td>Emma Reynolds (Lab): We support the local plan...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2015-07-15 10:00:00</td>\n      <td>Water Cannon</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I thank the Home Secretary very much for her s...</td>\n      <td>Theresa May (Con): I want to inform the House ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2015-07-15 10:03:00</td>\n      <td>Water Cannon</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am most grateful, Mr Speaker.</td>\n      <td>Keir Starmer (Lab): I spent five years in Nort...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2015-09-07 10:00:00</td>\n      <td>Syria: Refugees and Counter-terrorism</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Having seen at first hand the work of DFID off...</td>\n      <td>David Cameron (Con): In the interests of brevi...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2015-09-14 10:00:00</td>\n      <td>Trade Union Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am happy to inform the House that the previo...</td>\n      <td>Grahame M Morris (Lab): Is not the number of d...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2015-09-14 10:03:00</td>\n      <td>Trade Union Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I tell the right hon. Gentleman that not only ...</td>\n      <td>Alan Johnson (Lab): I give way to my hon. Frie...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2015-09-14 10:06:00</td>\n      <td>Trade Union Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Does the right hon. Gentleman accept that plen...</td>\n      <td>CHAIR (nan): Order. The hon. Gentleman should ...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2015-09-14 10:09:00</td>\n      <td>Trade Union Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>You are very kind, Mr Speaker. What the Bill i...</td>\n      <td>Harry Harpham (Lab): I stand here as a proud t...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2015-09-14 10:12:00</td>\n      <td>Trade Union Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>If the hon. Gentleman will forgive me, I will ...</td>\n      <td>Kate Osamor (Lab): I, too, would like to decla...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2015-09-14 10:15:00</td>\n      <td>Trade Union Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I will give way to the hon. Gentleman.</td>\n      <td>Wes Streeting (Lab): On the increased threshol...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2015-09-14 10:18:00</td>\n      <td>Trade Union Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I am grateful to the hon. Gentleman for the ex...</td>\n      <td>CHAIR (nan): Now that, after a short flight, t...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2015-09-14 10:21:00</td>\n      <td>Trade Union Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Only 24% of London bus drivers decided to vote...</td>\n      <td>Boris Johnson (Con): If the hon. Gentleman wil...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>2015-09-14 10:24:00</td>\n      <td>Trade Union Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>The hon. Gentleman will be familiar with the c...</td>\n      <td>Dennis Skinner (Lab): A member of the Bullingd...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>2015-11-02 10:00:00</td>\n      <td>Housing and Planning Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I congratulate my right hon. Friend on the arg...</td>\n      <td>Greg Clark (Con): The advantage of reaching an...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2015-11-02 10:03:00</td>\n      <td>Housing and Planning Bill</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Labour is making many mistakes in opposing thi...</td>\n      <td>Richard Bacon (Con): I represent a rural const...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>2015-11-26 10:00:00</td>\n      <td>Airports Commission: Final Report</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Funnily enough, I think that there are some go...</td>\n      <td>Andrew Slaughter (Lab): Old Oak Common station...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>2015-11-26 10:03:00</td>\n      <td>Airports Commission: Final Report</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>My hon. Friend makes a very good point. As he ...</td>\n      <td>Rupa Huq (Lab): Heathrow has been in the backg...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2015-11-26 10:06:00</td>\n      <td>Airports Commission: Final Report</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>That is a fair question. The answer is that th...</td>\n      <td>Rupa Huq (Lab): I thank the hon. Gentleman for...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>2015-11-26 10:09:00</td>\n      <td>Airports Commission: Final Report</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>Further to the previous intervention, I remind...</td>\n      <td>Steve Double (Con): I think I am right in sayi...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>2015-11-26 10:12:00</td>\n      <td>Airports Commission: Final Report</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I hesitate to remind my hon. Friend of what ha...</td>\n      <td>Nusrat Ghani (Con): The effect of noise disrup...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>2015-12-15 10:00:00</td>\n      <td>Housing</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I ask the right hon. Gentleman to clear up one...</td>\n      <td>John Healey (Lab): That detail had escaped me,...</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>2015-12-15 10:03:00</td>\n      <td>Housing</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I congratulate my hon. Friend on his remarks, ...</td>\n      <td>Brandon Lewis (Con): My hon. Friend makes a ve...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2015-12-16 10:00:00</td>\n      <td>West London Coroner's Court</td>\n      <td>Boris Johnson</td>\n      <td>Con</td>\n      <td>I congratulate my hon. Friend on securing this...</td>\n      <td>James Berry (Con): That experience is by no me...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"markdown","source":"## Load Model: GPT","metadata":{}},{"cell_type":"code","source":"LLM = ChatOpenAI(model=\"gpt-3.5-turbo\", \n                 max_tokens=1500, \n                 api_key = OPENAI_API_KEY) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:50:07.513385Z","iopub.execute_input":"2025-01-09T17:50:07.513760Z","iopub.status.idle":"2025-01-09T17:50:07.552763Z","shell.execute_reply.started":"2025-01-09T17:50:07.513723Z","shell.execute_reply":"2025-01-09T17:50:07.551724Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"selected_embeddings_model = OpenAIEmbeddings(api_key = OPENAI_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:50:09.104590Z","iopub.execute_input":"2025-01-09T17:50:09.104984Z","iopub.status.idle":"2025-01-09T17:50:09.134145Z","shell.execute_reply.started":"2025-01-09T17:50:09.104933Z","shell.execute_reply":"2025-01-09T17:50:09.133155Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"embedding_size_selectedLLM = len(selected_embeddings_model.embed_query(\"This is a test.\"))\nprint(f\"Embedding size: {embedding_size_selectedLLM}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:50:10.102605Z","iopub.execute_input":"2025-01-09T17:50:10.103637Z","iopub.status.idle":"2025-01-09T17:50:11.270021Z","shell.execute_reply.started":"2025-01-09T17:50:10.103599Z","shell.execute_reply":"2025-01-09T17:50:11.269025Z"}},"outputs":[{"name":"stdout","text":"Embedding size: 1536\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Load Model: Llama","metadata":{}},{"cell_type":"code","source":"# Set up Tokenizer & Model & Pipeline\nmodel_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\nmodel = AutoModel.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T14:20:45.603487Z","iopub.execute_input":"2025-01-06T14:20:45.603853Z","iopub.status.idle":"2025-01-06T14:29:19.529727Z","shell.execute_reply.started":"2025-01-06T14:20:45.603822Z","shell.execute_reply":"2025-01-06T14:29:19.529005Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fda71080aa0473c9a0db32e67b81448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a77b1803ca60481b9bd6d67a5906011d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859b1042a8e84179b7018bd92ff1fcd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0edbd5451a42f9ac00a41b61e0ed49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d826d781f9d5448c9a0a33fb8f6edfff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ab2146c8d0e48a0aecba0ab33af22fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3b7539f1c9e45b7a9f0c11bb9f41e1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f914eb321ed54bb4b81e21a38bc93770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38dc61037ef44f6dab7f5eeb60ff3817"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Define LLM Pipeline\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    tokenizer=tokenizer,\n    max_new_tokens = 500,  # Maximum new tokens to generate\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    truncation=True,\n    #temperature=0.7,  # Sampling temperature\n    #top_p=0.9,        # Nucleus sampling\n    #repetition_penalty=1.2,  # Penalize repetition\n)\n\nLLM = HuggingFacePipeline(pipeline=pipeline)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T14:29:19.531010Z","iopub.execute_input":"2025-01-06T14:29:19.531274Z","iopub.status.idle":"2025-01-06T14:29:28.247597Z","shell.execute_reply.started":"2025-01-06T14:29:19.531250Z","shell.execute_reply":"2025-01-06T14:29:28.246962Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ca6a29f27742aaaa693d80bee0f2f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fc6a966a0bb45da962d2e14f287c4dc"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"[**Decoding Strategies**](https://towardsdatascience.com/decoding-strategies-that-you-need-to-know-for-response-generation-ba95ee0faadc)\n\n`do_sample=True` use Sample Decoding\n\n`do_sample=False` use Greedy decoding","metadata":{}},{"cell_type":"code","source":"# Test Model Output\ndef response(prompt):\n     sequences = pipeline(prompt,\n                          do_sample=True,   # adjust\n                          top_k=10,        # adjust vocabulary size\n                          )\n     #print('Question: ' , prompt + '\\n')\n     print('response: ', sequences[0]['generated_text'][len(prompt):] + '\\n')\n\n\ndiscussion = \"Should the UK rejoin the European Union?\"\nagent_name = \"Boris Johnson\" \nprompt = (\n    f\"Consider the following discussion:\\n\\n\"\n    f\"{discussion}\\n\\n\"\n    f\"As {agent_name}, on a scale of 1 to 10, how relevant is this discussion to you? \"\n    f\"Provide a number between 1 (not relevant at all) and 10 (extremely relevant).\"\n    f\"Output only a single number, nothing else!\"\n)\n\n\nresponse(prompt)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"When switching to any other LLaMA-based model, you need to replace the embedding model (OpenAIEmbeddings) with an embedding generation mechanism that works with your local LLaMA model. OpenAI provides embeddings as a service, but with LLaMA, **you need to generate embeddings using the model locally**.","metadata":{}},{"cell_type":"code","source":"# Custom Llama Embeddings\nclass CustomLlamaEmbeddings:   # Copilot genereated\n    def __init__(self, model, tokenizer, device=\"cuda\"):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.device = device\n        \n    def embed_documents(self, texts):\n        \"\"\"Generate embeddings for a single query string.\"\"\"\n        # Tokenize inputs\n        inputs = self.tokenizer(\n            texts, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n        \n        # Get hidden states from the model\n        with torch.no_grad():\n            outputs = self.model(**inputs, return_dict=True, output_hidden_states=True)\n            \n        # Use the mean pooling of the last hidden state as embeddings\n        embeddings = outputs.hidden_states[-1].mean(dim=1)\n        return embeddings.cpu().numpy()\n        \n    def embed_query(self, text):\n        \"\"\"Generate embeddings for a list of documents.\"\"\"\n        return self.embed_documents([text])[0]\n\nselected_embeddings_model = CustomLlamaEmbeddings(model=model, tokenizer=tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(model_id)\n# Print the embedding size\nembedding_size_selectedLLM = config.hidden_size\nprint(f\"Embedding Size (hidden size): {config.hidden_size}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load Model: Tuned Boris","metadata":{}},{"cell_type":"code","source":"# base_model_name = \"meta-llama/Llama-3.2-3B\"\nPEFT_MODEL = \"/kaggle/input/llama_boris/pytorch/default/1\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,                      # Load model in 4bit, to redeuce memory and computational requirements\n    bnb_4bit_use_double_quant=True,         # Double quantization, further compress the model weights\n    bnb_4bit_quant_type=\"nf4\",              # Quantization type = nf4\n    bnb_4bit_compute_dtype=torch.bfloat16,  # Compute in 16bit format, to speed up computation\n    load_in_8bit_fp32_cpu_offload=True\n)\nconfig = PeftConfig.from_pretrained(PEFT_MODEL)\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    return_dict=True,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\ntokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\ntokenizer.pad_token = tokenizer.eos_token\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test the Fine-tuned model\nprompt = \"Should the UK rejoin the European Union?\"\n# Tokenize the input prompt\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Generate a response\noutput = model.generate(\n    input_ids=inputs[\"input_ids\"],\n    attention_mask=inputs[\"attention_mask\"],  # Explicitly set the attention mask\n    max_length=300,              # Maximum length of the generated response\n    temperature=0.7,             # Sampling temperature for more creative responses\n    top_p=0.9,                   # Nucleus sampling for generating diverse text\n    repetition_penalty=1.2,      # Penalize repetition in the response\n    do_sample=True,              # Enable sampling for non-deterministic output\n    pad_token_id=tokenizer.eos_token_id,      # Explicitly set the pad token ID\n)\n# Decode and print the response\nresponse = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomLlamaEmbeddings:\n    def __init__(self, model, tokenizer, device=\"cuda\"):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.device = device\n        \n    def embed_documents(self, texts):\n        # Tokenize inputs\n        inputs = self.tokenizer(\n            texts, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n        \n        # Get hidden states from the model\n        with torch.no_grad():\n            outputs = self.model(**inputs, return_dict=True, output_hidden_states=True)\n            \n        # Use the mean pooling of the last hidden state as embeddings\n        embeddings = outputs.hidden_states[-1].mean(dim=1)\n        return embeddings.cpu().numpy()\n        \n    def embed_query(self, text):\n        \"\"\"Generate embeddings for a list of documents.\"\"\"\n        return self.embed_documents([text])[0]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define LLM and Embeddings\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_length=500,  # Maximum tokens in the output\n    temperature=0.7,  # Sampling temperature\n    top_p=0.9,        # Nucleus sampling\n    repetition_penalty=1.2,  # Penalize repetition\n)\nLLM = HuggingFacePipeline(pipeline=pipe)\nselected_embeddings_model = CustomLlamaEmbeddings(model, tokenizer)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embeddings = selected_embeddings_model.embed_documents([\"Sample document\"])\nprint(f\"Embedding dimension: {embeddings.shape[1]}\")  # Check the embedding size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:27:41.880366Z","iopub.execute_input":"2025-01-09T17:27:41.880606Z","iopub.status.idle":"2025-01-09T17:27:42.120858Z","shell.execute_reply.started":"2025-01-09T17:27:41.880580Z","shell.execute_reply":"2025-01-09T17:27:42.119730Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mselected_embeddings_model\u001b[49m\u001b[38;5;241m.\u001b[39membed_documents([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample document\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding dimension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Check the embedding size\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'selected_embeddings_model' is not defined"],"ename":"NameError","evalue":"name 'selected_embeddings_model' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"# Generative AI Setup\nThe [codes](https://python.langchain.com/api_reference/experimental/generative_agents.html) for the classes `GenerativeAgentMemory` and `GenerativeAgent` was entirely reused from the **[LangChain Experimental](https://pypi.org/project/langchain-experimental/)** project in the LangChain Python API reference - intended for research and experimental uses, with a few minor tweaks and proper configuration of the prompts.\n","metadata":{}},{"cell_type":"markdown","source":"## Generative Agent Memory","metadata":{}},{"cell_type":"code","source":"class GenerativeAgentMemory(BaseMemory):\n    \"\"\"Memory for the generative agent.\"\"\"\n    \n    llm: BaseLanguageModel\n    \"\"\"The core language model.\"\"\"\n    \n    memory_retriever: TimeWeightedVectorStoreRetriever\n    \"\"\"The retriever to fetch related memories.\"\"\"\n    \n    verbose: bool = False\n    reflection_threshold: Optional[float] = None\n    \"\"\"When aggregate_importance exceeds reflection_threshold, stop to reflect.\"\"\"\n    \n    current_plan: List[str] = []\n    \"\"\"The current plan of the agent.\"\"\"\n    \n    # A weight of 0.15 makes this less important than it\n    # would be otherwise, relative to salience and time\n    importance_weight: float = 0.15\n    \"\"\"How much weight to assign the memory importance.\"\"\"\n    \n    aggregate_importance: float = 0.0  # : :meta private:\n    \"\"\"Track the sum of the 'importance' of recent memories.\n    Triggers reflection when it reaches reflection_threshold.\"\"\"\n    \n    max_tokens_limit: int = 1200  # : :meta private:\n    \n    # input keys\n    queries_key: str = \"queries\"\n    most_recent_memories_token_key: str = \"recent_memories_token\"\n    add_memory_key: str = \"add_memory\"\n    \n    # output keys\n    relevant_memories_key: str = \"relevant_memories\"\n    relevant_memories_simple_key: str = \"relevant_memories_simple\"\n    most_recent_memories_key: str = \"most_recent_memories\"\n    now_key: str = \"now\"\n    reflecting: bool = False\n    \n    def chain(self, prompt: PromptTemplate) -> LLMChain:\n        return LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n    @staticmethod\n    \n    def _parse_list(text: str) -> List[str]:\n        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n        lines = re.split(r\"\\n\", text.strip())\n        lines = [line for line in lines if line.strip()]  # remove empty lines\n        return [re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", line).strip() for line in lines]\n    \n    def _get_topics_of_reflection(self, last_k: int = 50) -> List[str]:\n        \"\"\"Return the 3 most salient high-level questions about recent observations.\"\"\"\n        prompt = PromptTemplate.from_template(\n            \"{observations}\\n\\n\"\n            \"Given only the information above, what are the 3 most salient \"\n            \"high-level questions we can answer about the subjects in the statements?\\n\"\n            \"Provide each question on a new line.\"\n        )\n        observations = self.memory_retriever.memory_stream[-last_k:]\n        observation_str = \"\\n\".join(\n            [self._format_memory_detail(o) for o in observations]\n        )\n        result = self.chain(prompt).run(observations=observation_str)\n        return self._parse_list(result)\n    \n    def _get_insights_on_topic(\n        self, topic: str, now: Optional[datetime] = None\n    ) -> List[str]:\n        \"\"\"Generate 'insights' on a topic of reflection, based on pertinent memories.\"\"\"\n        prompt = PromptTemplate.from_template(\n            \"Statements relevant to: '{topic}'\\n\"\n            \"---\\n\"\n            \"{related_statements}\\n\"\n            \"---\\n\"\n            \"What 5 high-level novel insights can you infer from the above statements \"\n            \"that are relevant for answering the following question?\\n\"\n            \"Do not include any insights that are not relevant to the question.\\n\"\n            \"Do not repeat any insights that have already been made.\\n\\n\"\n            \"Question: {topic}\\n\\n\"\n            \"(example format: insight (because of 1, 5, 3))\\n\"\n        )\n        related_memories = self.fetch_memories(topic, now=now)\n        related_statements = \"\\n\".join(\n            [\n                self._format_memory_detail(memory, prefix=f\"{i+1}. \")\n                for i, memory in enumerate(related_memories)\n            ]\n        )\n        result = self.chain(prompt).run(\n            topic=topic, related_statements=related_statements\n        )\n        # TODO: Parse the connections between memories and insights\n        return self._parse_list(result)\n    \n    def pause_to_reflect(self, now: Optional[datetime] = None) -> List[str]:\n        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n        if self.verbose:\n            logger.info(\"Character is reflecting\")\n        new_insights = []\n        topics = self._get_topics_of_reflection()\n        for topic in topics:\n            insights = self._get_insights_on_topic(topic, now=now)\n            for insight in insights:\n                self.add_memory(insight, now=now)\n            new_insights.extend(insights)\n        return new_insights\n    \n    def _score_memory_importance(self, memory_content: str) -> float:\n        \"\"\"Score the absolute importance of the given memory.\"\"\"\n        prompt = PromptTemplate.from_template(\n            \"On the scale of 1 to 10, where 1 is purely mundane\"\n            + \" (e.g., brushing teeth, making bed) and 10 is\"\n            + \" extremely poignant (e.g., a break up, college\"\n            + \" acceptance), rate the likely poignancy of the\"\n            + \" following piece of memory. Respond with a single integer.\"\n            + \"\\nMemory: {memory_content}\"\n            + \"\\nRating: \"\n        )\n        score = self.chain(prompt).run(memory_content=memory_content).strip()\n        if self.verbose:\n            logger.info(f\"Importance score: {score}\")\n        match = re.search(r\"^\\D*(\\d+)\", score)\n        if match:\n            return (float(match.group(1)) / 10) * self.importance_weight\n        else:\n            return 0.0\n    \n    def _score_memories_importance(self, memory_content: str) -> List[float]:\n        \"\"\"Score the absolute importance of the given memory.\"\"\"\n        prompt = PromptTemplate.from_template(\n            \"On the scale of 1 to 10, where 1 is purely mundane\"\n            + \" (e.g., brushing teeth, making bed) and 10 is\"\n            + \" extremely poignant (e.g., a break up, college\"\n            + \" acceptance), rate the likely poignancy of the\"\n            + \" following piece of memory. Always answer with only a list of numbers.\"\n            + \" If just given one memory still respond in a list.\"\n            + \" Memories are separated by semi colans (;)\"\n            + \"\\nMemories: {memory_content}\"\n            + \"\\nRating: \"\n        )\n        scores = self.chain(prompt).run(memory_content=memory_content).strip()\n        if self.verbose:\n            logger.info(f\"Importance scores: {scores}\")\n        # Split into list of strings and convert to floats\n        scores_list = [float(x) for x in scores.split(\";\")]\n        return scores_list\n    \n    def add_memories(\n        self, memory_content: str, now: Optional[datetime] = None\n    ) -> List[str]:\n        \"\"\"Add an observations or memories to the agent's memory.\"\"\"\n        importance_scores = self._score_memories_importance(memory_content)\n        self.aggregate_importance += max(importance_scores)\n        \n        memory_list = memory_content.split(\";\")\n        documents = []\n        for i in range(len(memory_list)):\n            documents.append(\n                Document(\n                    page_content=memory_list[i],\n                    metadata={\"importance\": importance_scores[i]},\n                )\n            )\n        result = self.memory_retriever.add_documents(documents, current_time=now)\n        # After an agent has processed a certain amount of memories (as measured by\n        # aggregate importance), it is time to reflect on recent events to add\n        # more synthesized memories to the agent's memory stream.\n        if (\n            self.reflection_threshold is not None\n            and self.aggregate_importance > self.reflection_threshold\n            and not self.reflecting\n        ):\n            self.reflecting = True\n            self.pause_to_reflect(now=now)\n            # Hack to clear the importance from reflection\n            self.aggregate_importance = 0.0\n            self.reflecting = False\n        return result\n    \n    def add_memory(\n        self, memory_content: str, now: Optional[datetime] = None) -> List[str]:\n        \"\"\"Add an observation or memory to the agent's memory.\"\"\"\n        \n        importance_score = self._score_memory_importance(memory_content)\n        self.aggregate_importance += importance_score\n        \n        document = Document(\n            page_content=memory_content, \n            metadata={\"importance\": importance_score}\n        )\n        \n        result = self.memory_retriever.add_documents([document], current_time=now)\n        \n        # After an agent has processed a certain amount of memories (as measured by\n        # aggregate importance), it is time to reflect on recent events to add\n        # more synthesized memories to the agent's memory stream.\n        \n        if (\n            self.reflection_threshold is not None\n            and self.aggregate_importance > self.reflection_threshold\n            and not self.reflecting\n        ):\n            self.reflecting = True\n            self.pause_to_reflect(now=now)\n            # Hack to clear the importance from reflection\n            self.aggregate_importance = 0.0\n            self.reflecting = False\n        return result\n\n    def add_historical_memory(\n        self, memory_content: str, created_at: datetime) -> List[str]:\n        \"\"\"Add a historical observation or memory to the agent's memory with a specific creation date.\"\"\"\n        \n        importance_score = self._score_memory_importance(memory_content)\n        self.aggregate_importance += importance_score\n        \n        document = Document(\n            page_content=memory_content,\n            metadata={\n                \"importance\": importance_score,\n                \"created_at\": created_at,  # Historical creation date\n                \"last_accessed_at\": created_at  # Optional: same as created_at for historical data\n            }        )\n    \n        result = self.memory_retriever.add_documents([document], current_time=created_at)\n        \n        # Check if reflection is needed based on importance\n        if (\n            self.reflection_threshold is not None\n            and self.aggregate_importance > self.reflection_threshold\n            and not self.reflecting\n        ):\n            self.reflecting = True\n            self.pause_to_reflect(now=memory_date)\n            self.aggregate_importance = 0.0\n            self.reflecting = False\n            \n        return result\n    \n    def fetch_memories(\n        self, observation: str, now: Optional[datetime] = None\n    ) -> List[Document]:\n        \"\"\"Fetch related memories.\"\"\"\n        if now is not None:\n            with mock_now(now):\n                return self.memory_retriever.invoke(observation)\n        else:\n            return self.memory_retriever.invoke(observation)\n    \n    def format_memories_detail(self, relevant_memories: List[Document]) -> str:\n        content = []\n        for mem in relevant_memories:\n            content.append(self._format_memory_detail(mem, prefix=\"- \"))\n        return \"\\n\".join([f\"{mem}\" for mem in content])\n    \n    def _format_memory_detail(self, memory: Document, prefix: str = \"\") -> str:\n        created_time = memory.metadata[\"created_at\"].strftime(\"%B %d, %Y, %I:%M %p\")\n        return f\"{prefix}[{created_time}] {memory.page_content.strip()}\"\n    \n    def format_memories_simple(self, relevant_memories: List[Document]) -> str:\n        return \"; \".join([f\"{mem.page_content}\" for mem in relevant_memories])\n    \n    def _get_memories_until_limit(self, consumed_tokens: int) -> str:\n        \"\"\"Reduce the number of tokens in the documents.\"\"\"\n        result = []\n        for doc in self.memory_retriever.memory_stream[::-1]:\n            if consumed_tokens >= self.max_tokens_limit:\n                break\n            consumed_tokens += self.llm.get_num_tokens(doc.page_content)\n            if consumed_tokens < self.max_tokens_limit:\n                result.append(doc)\n        return self.format_memories_simple(result)\n    @property\n    \n    def memory_variables(self) -> List[str]:\n        \"\"\"Input keys this memory class will load dynamically.\"\"\"\n        return []\n   \n    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Return key-value pairs given the text input to the chain.\"\"\"\n        queries = inputs.get(self.queries_key)\n        now = inputs.get(self.now_key)\n        if queries is not None:\n            relevant_memories = [\n                mem for query in queries for mem in self.fetch_memories(query, now=now)\n            ]\n            return {\n                self.relevant_memories_key: self.format_memories_detail(\n                    relevant_memories\n                ),\n                self.relevant_memories_simple_key: self.format_memories_simple(\n                    relevant_memories\n                ),\n            }\n        most_recent_memories_token = inputs.get(self.most_recent_memories_token_key)\n        if most_recent_memories_token is not None:\n            return {\n                self.most_recent_memories_key: self._get_memories_until_limit(\n                    most_recent_memories_token\n                )\n            }\n        return {}\n    \n    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, Any]) -> None:\n        \"\"\"Save the context of this model run to memory.\"\"\"\n        # TODO: fix the save memory key\n        mem = outputs.get(self.add_memory_key)\n        now = outputs.get(self.now_key)\n        if mem:\n            self.add_memory(mem, now=now)\n    \n    def clear(self) -> None:\n        \"\"\"Clear memory contents.\"\"\"\n        # TODO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:50:20.416820Z","iopub.execute_input":"2025-01-09T17:50:20.417146Z","iopub.status.idle":"2025-01-09T17:50:20.448343Z","shell.execute_reply.started":"2025-01-09T17:50:20.417117Z","shell.execute_reply":"2025-01-09T17:50:20.447630Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Generative Agent","metadata":{}},{"cell_type":"code","source":"class GenerativeAgent(BaseModel):\n    \"\"\"Agent as a character with memory and innate characteristics.\"\"\"\n    name: str\n    \"\"\"The character's name.\"\"\"\n    age: Optional[int] = None\n    \"\"\"The optional age of the character.\"\"\"\n    traits: str = \"N/A\"\n    \"\"\"Permanent traits to ascribe to the character.\"\"\"\n    status: str\n    \"\"\"The traits of the character you wish not to change.\"\"\"\n    memory: GenerativeAgentMemory\n    \"\"\"The memory object that combines relevance, recency, and 'importance'.\"\"\"\n    llm: BaseLanguageModel\n    \"\"\"The underlying language model.\"\"\"\n    verbose: bool = False\n    summary: str = \"\"  #: :meta private:\n    \"\"\"Stateful self-summary generated via reflection on the character's memory.\"\"\"\n    summary_refresh_seconds: int = 3600  #: :meta private:\n    \"\"\"How frequently to re-generate the summary.\"\"\"\n    last_refreshed: datetime = Field(default_factory=datetime.now)  # : :meta private:\n    \"\"\"The last time the character's summary was regenerated.\"\"\"\n    daily_summaries: List[str] = Field(default_factory=list)  # : :meta private:\n    \"\"\"Summary of the events in the plan that the agent took.\"\"\"\n    model_config = ConfigDict(\n        arbitrary_types_allowed=True,\n    )\n    # LLM-related methods\n    @staticmethod\n    \n    def _parse_list(text: str) -> List[str]:\n        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n        lines = re.split(r\"\\n\", text.strip())\n        return [re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", line).strip() for line in lines]\n        \n    def chain(self, prompt: PromptTemplate) -> LLMChain:\n        \"\"\"Create a chain with the same settings as the agent.\"\"\"\n        return LLMChain(\n            llm=self.llm, prompt=prompt, verbose=self.verbose, memory=self.memory\n        )\n        \n    def _get_entity_from_observation(self, observation: str) -> str:\n        prompt = PromptTemplate.from_template(\n            \"What is the observed entity in the following observation? {observation}\"\n            + \"\\nEntity=\"\n        )\n        return self.chain(prompt).run(observation=observation).strip()\n        \n    def _get_entity_action(self, observation: str, entity_name: str) -> str:\n        prompt = PromptTemplate.from_template(\n            \"What is the {entity} doing in the following observation? {observation}\"\n            + \"\\nThe {entity} is\"\n        )\n        return (\n            self.chain(prompt).run(entity=entity_name, observation=observation).strip()\n        )\n\n## Summarize Most relevant memories\n    def summarize_related_memories(self, observation: str) -> str:\n        \"\"\"Summarize memories that are most relevant to an observation.\"\"\"\n        prompt = PromptTemplate.from_template(\n            \"\"\"\n            {q1}?\n            Context from memory:\n            {relevant_memories}\n            Relevant context: \n            \"\"\"\n        )\n        entity_name = self._get_entity_from_observation(observation)\n        entity_action = self._get_entity_action(observation, entity_name)\n        q1 = f\"What is the relationship between {self.name} and {entity_name}\"\n        q2 = f\"{entity_name} is {entity_action}\"\n        return self.chain(prompt=prompt).run(q1=q1, queries=[q1, q2]).strip()\n        \n## Generate Summary of the agent + reaction \n    def _generate_reaction(\n        self, observation: str, suffix: str, now: Optional[datetime] = None\n    ) -> str:\n        \"\"\"React to a given observation or dialogue act.\"\"\"\n        prompt = PromptTemplate.from_template(\n            \"{agent_summary_description}\"\n            + \"\\nIt is {current_time}.\"\n            + \"\\n{agent_name}'s status: {agent_status}\"\n            + \"\\nSummary of relevant context from {agent_name}'s memory:\"\n            + \"\\n{relevant_memories}\"\n            + \"\\nMost recent observations: {most_recent_memories}\"\n            + \"\\nObservation: {observation}\"\n            + \"\\n\\n\"\n            + suffix\n        )\n        agent_summary_description = self.get_summary(now=now)\n        relevant_memories_str = self.summarize_related_memories(observation)\n        current_time_str = (\n            datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n            if now is None\n            else now.strftime(\"%B %d, %Y, %I:%M %p\")\n        )\n        kwargs: Dict[str, Any] = dict(\n            agent_summary_description=agent_summary_description,\n            current_time=current_time_str,\n            relevant_memories=relevant_memories_str,\n            agent_name=self.name,\n            observation=observation,\n            agent_status=self.status,\n        )\n        consumed_tokens = self.llm.get_num_tokens(\n            prompt.format(most_recent_memories=\"\", **kwargs)\n        )\n        kwargs[self.memory.most_recent_memories_token_key] = consumed_tokens\n        return self.chain(prompt=prompt).run(**kwargs).strip()\n        \n## Clean response\n    def _clean_response(self, text: str) -> str:\n        return re.sub(f\"^{self.name} \", \"\", text.strip()).strip()\n    \n## Generate Dialogue response\n    def generate_dialogue_response(\n        self, observation: str, now: Optional[datetime] = None) -> Tuple[bool, str]:\n        \"\"\"React to a given observation.\"\"\"\n        \n        call_to_action_template = (\n            \"You are {agent_name}, responding to the Observation.\\n\"\n            + \"Respond exactly as {agent_name} would speak, staying fully in character and addressing the observation directly\"\n        )\n        \n        # Generating response with updated prompt\n        full_result = self._generate_reaction(observation, call_to_action_template, now=now)\n        #result = re.findall(r'\"(.*?)\"', full_result)[0]\n        \n        response_text = self._clean_response(full_result.strip())\n        self.memory.save_context(\n            {},\n            {\n                self.memory.add_memory_key: f\"{self.name} observed \"\n                f\"{observation} and said {response_text}\",\n                self.memory.now_key: now,\n            },\n        )\n        return True, f\"{self.name} said {response_text}\"\n\n## Decide if the agent wants to respond to the observation\n    def decide_to_respond(self, observation: str, now: Optional[datetime] = None,\n                          threshold: float = 7.0) -> bool:\n        \"\"\"Decide whether the agent wants to respond to the observation.\"\"\"\n\n        call_to_action_template = (\n            \"Consider the following discussion:\\n\\n\"\n            \"{observation}\\n\\n\"\n            \"As {agent_name}, on a scale of 1 to 10, how relevant is this discussion to you? \"\n            \"Provide a number between 1 (not relevant at all) and 10 (extremely relevant).\"\n            \"Output only a number, nothing else!\"\n            )\n        \n        full_result = self._generate_reaction(observation, call_to_action_template, now=now)\n        result = full_result.strip().lower()  # Normalize result to lowercase for consistent comparison\n        \n        try:\n            relevance_score = float(result)\n        except ValueError:\n            logging.warning(f\"Unexpected non-numeric response from agent: {result}\")\n            relevance_score = 0  # Default low relevance for unexpected responses\n\n        # Save the decision context to memory\n        self.memory.save_context(\n            {},\n            {\n                self.memory.add_memory_key: f\"{self.name} observed \"\n                f\"that the relevance of the discussion '{observation}' was scored as {result}\",\n                self.memory.now_key: now,\n            },\n        )\n         \n        # Check if the model returned \"yes\" or \"no\"\n        if relevance_score < threshold:\n            return False\n        elif relevance_score >= threshold:\n            return True\n        else:\n            print(f\"Unexpected response: {result}\")  # For debugging purposes\n            return False\n    \n    ######################################################\n    # Agent stateful' summary methods.                   #\n    # Each dialog or response prompt includes a header   #\n    # summarizing the agent's self-description. This is  #\n    # updated periodically through probing its memories  #\n    ######################################################\n    \n    def _compute_agent_summary(self) -> str:\n        \"\"\"\"\"\"\n        prompt = PromptTemplate.from_template(\n            \"How would you summarize {name}'s core characteristics given the\"\n            + \" following statements:\\n\"\n            + \"{relevant_memories}\"\n            + \"Do not embellish.\"\n            + \"\\n\\nSummary: \"\n        )\n        # The agent seeks to think about their core characteristics.\n        return (\n            self.chain(prompt)\n            .run(name=self.name, queries=[f\"{self.name}'s core characteristics\"])\n            .strip()\n        )\n    \n    def get_summary(\n        self, force_refresh: bool = False, now: Optional[datetime] = None\n    ) -> str:\n        \"\"\"Return a descriptive summary of the agent.\"\"\"\n        current_time = datetime.now() if now is None else now\n        since_refresh = (current_time - self.last_refreshed).seconds\n        if (\n            not self.summary\n            or since_refresh >= self.summary_refresh_seconds\n            or force_refresh\n        ):\n            self.summary = self._compute_agent_summary()\n            self.last_refreshed = current_time\n        age = self.age if self.age is not None else \"N/A\"\n        return (\n            f\"Name: {self.name} (age: {age})\"\n            + f\"\\nInnate traits: {self.traits}\"\n            + f\"\\n{self.summary}\"\n        )\n    \n    def get_full_header(\n        self, force_refresh: bool = False, now: Optional[datetime] = None\n    ) -> str:\n        \"\"\"Return a full header of the agent's status, summary, and current time.\"\"\"\n        now = datetime.now() if now is None else now\n        summary = self.get_summary(force_refresh=force_refresh, now=now)\n        current_time_str = now.strftime(\"%B %d, %Y, %I:%M %p\")\n        return (\n            f\"{summary}\\nIt is {current_time_str}.\\n{self.name}'s status: {self.status}\"\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:50:23.898662Z","iopub.execute_input":"2025-01-09T17:50:23.899022Z","iopub.status.idle":"2025-01-09T17:50:23.924811Z","shell.execute_reply.started":"2025-01-09T17:50:23.898992Z","shell.execute_reply":"2025-01-09T17:50:23.923975Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Create Agent\n- [GenerativeAgentMemory](https://python.langchain.com/api_reference/experimental/generative_agents/langchain_experimental.generative_agents.memory.GenerativeAgentMemory.html): **Memory** for the generative agent \n   - `llm`\n   - `memory_retriever` = create_new_memory_retriever()\n   - `current_plan`\n   - `reflection_threshold`\n   - `add_memory` add observation/memory\n- [GenerativeAgent](https://python.langchain.com/api_reference/experimental/generative_agents.html): Agent as a character with **memory** and innate **characteristics**,  \n   - basics like `name`, `age` and `llm`\n   - `memory` object that combines relevance, recency, and ‘importance’\n   - `summary` and `summary_refresh_seconds` to set how frequently to re-generate the summary\n   - `summarize_related_memories`: Summarize memories that are most relevant to an observation\n   - `status` fix-objectives / traits of the character you wish not to change\n   - `traits` set Permanent traits to ascribe to the character \n   - `generate_dialogue_response`","metadata":{}},{"cell_type":"code","source":"# Relevance Score function - relevance_score_fn()\ndef relevance_score_fn(score: float) -> float:\n    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n    return 1.0 - score / math.sqrt(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:50:28.105643Z","iopub.execute_input":"2025-01-09T17:50:28.106025Z","iopub.status.idle":"2025-01-09T17:50:28.110333Z","shell.execute_reply.started":"2025-01-09T17:50:28.105995Z","shell.execute_reply":"2025-01-09T17:50:28.109458Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Memory Retriever function - create_new_memory_retriever()\ndef create_new_memory_retriever():\n    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n    \n    embeddings_model = selected_embeddings_model  \n    \n    # Initialize the vectorstore as empty\n    embedding_size = embedding_size_selectedLLM           #use: 1536 (GPT3.5) or 3072 (Llamma)\n    \n    index = faiss.IndexFlatL2(embedding_size)\n    vectorstore = FAISS(\n        embeddings_model.embed_query,  #use: embeddings_model.embed_query OR llama_embedding_function\n        index,\n        InMemoryDocstore({}),  # empty Memory docstore\n        {},  # index-to-document store ID mapping\n        relevance_score_fn=relevance_score_fn,\n    )\n    \n    # Time-weighted scoring mechanism\n    return TimeWeightedVectorStoreRetriever(\n        vectorstore=vectorstore,\n        other_score_keys=[\"importance\"],\n        k=15  # retrieve up to 15 relevant memories\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:50:29.560019Z","iopub.execute_input":"2025-01-09T17:50:29.560359Z","iopub.status.idle":"2025-01-09T17:50:29.565752Z","shell.execute_reply.started":"2025-01-09T17:50:29.560328Z","shell.execute_reply":"2025-01-09T17:50:29.564874Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Agent Creation function - create_debate_agent()\ndef create_debate_agent(name, age, traits, status, \n                        llm):\n   \n    memory = GenerativeAgentMemory(\n        llm=llm,\n        memory_retriever=create_new_memory_retriever(),\n        verbose=False,\n        reflection_threshold= 7.5,  # adjust as needed for reflection frequency\n    )\n    \n    agent = GenerativeAgent(\n        name=name,\n        age=age,\n        traits=traits,\n        status=status,\n        memory_retriever=create_new_memory_retriever(),\n        llm=llm,\n        memory=memory,\n    )\n    return agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:51:57.674177Z","iopub.execute_input":"2025-01-09T17:51:57.674903Z","iopub.status.idle":"2025-01-09T17:51:57.679537Z","shell.execute_reply.started":"2025-01-09T17:51:57.674868Z","shell.execute_reply":"2025-01-09T17:51:57.678731Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Define Agent Traits","metadata":{}},{"cell_type":"code","source":"# Create debate agents (MPs) with their respective characteristics\nTrott = create_debate_agent(name=\"Laura Trott\", age=38, llm = LLM,\n                            traits= \"highly disciplined, sharp, and pragmatic. Strategic, focus on “quiet competence” rather than loud rhetoric, detail-oriented and a stickler for facts\",\n                            status=\"Conservative MP\")\n\nJohnson = create_debate_agent(name=\"Boris Johnson\", age=57, llm = LLM,\n                            traits=\"charismatic, chaotic, opportunistic, larger-than-life personality, thrives on spectacle and Blitz-spirit optimism, mixes humor with charm and a dash of bluster, unpredictable yet captivating, a showman who values headlines over substance\",\n                            status=\"Conservative MP\")\n\nFarage = create_debate_agent(name=\"Nigel Farage\", age=60, llm = LLM,\n                             traits=\"unapologetically bold, confrontational, divisive, a provocateur, skilled at stirring public opinion with blunt populist rhetoric, political brawle, highly skilled at galvanizing crowds\",\n                             status=\"Former UKIP leader, Brexit Party leader, and political commentator\")\n\nSunak = create_debate_agent(name=\"Rishi Sunak\", age=44, llm = LLM,\n                            traits=\"technocratic, astute, polished, financially extremely wealthy, meticulous, highly analytical, known as the Fiscal-Guardian, out of touch with the middle-class\",\n                            status=\"Conservative MP, Former Prime Minister\")\n\nStarmer = create_debate_agent(name=\"Sir Keir Starmer\", age=61, llm = LLM,\n                              traits=\"methodical, earnest, intense focus on justice and reform, calm demeanor, seeks accountability, values facts over flair, deliver points with precision rather than emotion\",\n                              status=\"Leader of the Labour Party\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:51:59.388649Z","iopub.execute_input":"2025-01-09T17:51:59.389051Z","iopub.status.idle":"2025-01-09T17:51:59.396268Z","shell.execute_reply.started":"2025-01-09T17:51:59.389019Z","shell.execute_reply":"2025-01-09T17:51:59.395466Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Define Base Memories","metadata":{}},{"cell_type":"code","source":"# Creat Memory objects for each agent\nTrott_memory = Trott.memory\nJohnson_memory = Johnson.memory\nFarage_memory = Farage.memory   \nSunak_memory = Sunak.memory\nStarmer_memory = Starmer.memory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:52:01.593392Z","iopub.execute_input":"2025-01-09T17:52:01.594177Z","iopub.status.idle":"2025-01-09T17:52:01.598226Z","shell.execute_reply.started":"2025-01-09T17:52:01.594141Z","shell.execute_reply":"2025-01-09T17:52:01.597404Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Base Observations \nTrott_observations = [\n    \"Trott attended Oxted School, studied history and economics at Oxford University\",\n    \"Trott is preparing for a debate on the economy\",\n    \"Trott advocates for responsible budgeting and cautious government spending\",\n    \"Trott emphasize business growth and pragmatic economic solutions\",\n    \"Trott generally conservative but supports progressive stances on education and family policies\",\n    \"Trott focuses on pragmatic rather than ideological approaches\",\n]\nJohnson_observations = [\n    \"Johnson attended Eton College, studied Classics Oxford University\",\n    \"Johnson is Pro-Brexit and economically nationalist\",\n    \"Johnson advocates for deregulation, minimal government intervention, and strong support for British businesses\",\n    \"Johnson is a populist, often aligning with traditional conservative values, though flexible when politically advantageous\",\n    \"Johnson is support strong national identity and sovereignty\",\n]\nFarage_observations = [\n    \"Farage attended Dulwich College but did not attend university\",\n    \"Farage is strongly Eurosceptic, advocates for British sovereignty, deregulation, and cutting ties with EU economic policies\",\n    \"Farage prioritizes domestic industry and independence from European influence\",\n    \"Farage is a Nationalist, anti-globalist, and socially conservative\",\n    \"Farage advocates for strict immigration controls and promotes traditional British values\"\n]\nSunak_observations = [\n    \"Sunak studied Philosophy, Politics, and Economics at Oxford University and later earned an MBA from Stanford University\",\n    \"Sunak is fiscal conservative with a focus on budget balancing\",\n    \"Sunak advocates for responsible spending and a cautious approach to government intervention\",\n    \"Sunak prioritizes stability over drastic reforms\",\n    \"Sunak focus on pragmatism over ideology, holds relatively conservative views on social issues, often supporting traditional family values\",\n]\nStarmer_observations = [\n    \"Starmer attended Reigate Grammar School, studied law at the University of Leeds and completed studies at Oxford University\",\n    \"Starmer focuses on investment in public services, especially the NHS, and progressive taxation\",\n    \"Starmer prioritizes worker rights and social equality, advocating for a balanced but progressive approach\",\n    \"Starmer supports expanded public services, social justice, and inclusivity\",\n    \"Starmer Focuses on social reform and government accountability\",\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:52:02.938267Z","iopub.execute_input":"2025-01-09T17:52:02.938874Z","iopub.status.idle":"2025-01-09T17:52:02.944228Z","shell.execute_reply.started":"2025-01-09T17:52:02.938840Z","shell.execute_reply":"2025-01-09T17:52:02.943407Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Loop through the observations and add to memory\ntuples = [(Trott_observations, Trott_memory), (Johnson_observations, Johnson_memory), \n          (Farage_observations, Farage_memory), (Sunak_observations, Sunak_memory), (Starmer_observations, Starmer_memory)]\n\nfor observations, memory in tuples:\n    for observation in observations:\n        memory.add_memory(observation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T00:07:44.017039Z","iopub.execute_input":"2025-01-07T00:07:44.017631Z","iopub.status.idle":"2025-01-07T00:07:56.521550Z","shell.execute_reply.started":"2025-01-07T00:07:44.017596Z","shell.execute_reply":"2025-01-07T00:07:56.520681Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2176407211.py:39: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  return LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n/tmp/ipykernel_30/2176407211.py:116: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  score = self.chain(prompt).run(memory_content=memory_content).strip()\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"for observation in Johnson_observations:\n    Johnson_memory.add_memory(observation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T15:51:02.732649Z","iopub.execute_input":"2025-01-09T15:51:02.733124Z","iopub.status.idle":"2025-01-09T15:51:05.956741Z","shell.execute_reply.started":"2025-01-09T15:51:02.733092Z","shell.execute_reply":"2025-01-09T15:51:05.955678Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# View stored memories\nprint(\"Trott's stored memories:\")\nprint(Trott_memory.memory_retriever.memory_stream)\n\nprint(\"\\nJohnson's stored memories:\")\nprint(Johnson_memory.memory_retriever.memory_stream)\n\nprint(\"\\nFarage's stored memories:\")\nprint(Farage_memory.memory_retriever.memory_stream)\n\nprint(\"\\nSunak's stored memories:\")\nprint(Sunak_memory.memory_retriever.memory_stream)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T16:19:21.454136Z","iopub.execute_input":"2025-01-09T16:19:21.454958Z","iopub.status.idle":"2025-01-09T16:19:21.461980Z","shell.execute_reply.started":"2025-01-09T16:19:21.454916Z","shell.execute_reply":"2025-01-09T16:19:21.460702Z"}},"outputs":[{"name":"stdout","text":"Trott's stored memories:\n[Document(metadata={'importance': 0.105, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 49, 57, 713824), 'created_at': datetime.datetime(2025, 1, 9, 15, 49, 57, 713824), 'buffer_idx': 0}, page_content='Trott attended Oxted School, studied history and economics at Oxford University'), Document(metadata={'importance': 0.06, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 49, 58, 513843), 'created_at': datetime.datetime(2025, 1, 9, 15, 49, 58, 513843), 'buffer_idx': 1}, page_content='Trott is preparing for a debate on the economy'), Document(metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 49, 59, 205650), 'created_at': datetime.datetime(2025, 1, 9, 15, 49, 59, 205650), 'buffer_idx': 2}, page_content='Trott advocates for responsible budgeting and cautious government spending'), Document(metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 50, 0, 332074), 'created_at': datetime.datetime(2025, 1, 9, 15, 50, 0, 332074), 'buffer_idx': 3}, page_content='Trott emphasize business growth and pragmatic economic solutions'), Document(metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 50, 1, 58029), 'created_at': datetime.datetime(2025, 1, 9, 15, 50, 1, 58029), 'buffer_idx': 4}, page_content='Trott generally conservative but supports progressive stances on education and family policies'), Document(metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 50, 2, 113786), 'created_at': datetime.datetime(2025, 1, 9, 15, 50, 2, 113786), 'buffer_idx': 5}, page_content='Trott focuses on pragmatic rather than ideological approaches')]\n\nJohnson's stored memories:\n[Document(metadata={'importance': 0.12, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 51, 3, 73830), 'created_at': datetime.datetime(2025, 1, 9, 15, 51, 3, 73830), 'buffer_idx': 0}, page_content='Johnson attended Eton College, studied Classics Oxford University'), Document(metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 51, 3, 839592), 'created_at': datetime.datetime(2025, 1, 9, 15, 51, 3, 839592), 'buffer_idx': 1}, page_content='Johnson is Pro-Brexit and economically nationalist'), Document(metadata={'importance': 0.075, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 51, 4, 447151), 'created_at': datetime.datetime(2025, 1, 9, 15, 51, 4, 447151), 'buffer_idx': 2}, page_content='Johnson advocates for deregulation, minimal government intervention, and strong support for British businesses'), Document(metadata={'importance': 0.03, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 51, 4, 902353), 'created_at': datetime.datetime(2025, 1, 9, 15, 51, 4, 902353), 'buffer_idx': 3}, page_content='Johnson is a populist, often aligning with traditional conservative values, though flexible when politically advantageous'), Document(metadata={'importance': 0.06, 'last_accessed_at': datetime.datetime(2025, 1, 9, 15, 51, 5, 480572), 'created_at': datetime.datetime(2025, 1, 9, 15, 51, 5, 480572), 'buffer_idx': 4}, page_content='Johnson is support strong national identity and sovereignty')]\n\nFarage's stored memories:\n[]\n\nSunak's stored memories:\n[]\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## Add Historical Memories","metadata":{}},{"cell_type":"code","source":"def process_and_add_historical_memories (df, agent_memory, mp_name):\n    \"\"\"\n    Process the Parliamentary transcript and add the selected MP's historical memories\n    with accurate timestamps and preceding dialogue context.\n    \"\"\"\n    mp_transcripts = df[df['speaker'] == mp_name]\n\n    for _, row in mp_transcripts.iterrows():\n        # Extract all prior exchanges for the same date and agenda\n        relevant_context = df[\n            (df['date'] == row['date']) &\n            (df['agenda'] == row['agenda']) &\n            (df['speechnumber'] < row['speechnumber'])  # Prior to the MP's statement\n        ]\n\n        # Format the preceding context\n        context = \"\\n\".join(\n            f\"{r['speaker']} said: {r['text']}\" for _, r in relevant_context.iterrows()\n        )\n\n        # Format the observation with context and the MP's contribution\n        observation = (\n            f\"Date: {row['date']}\\n\"\n            f\"Agenda: {row['agenda']}\\n\"\n            f\"Context:\\n{context}\\n\"\n            f\"{mp_name} said: {row['text']}\" )\n\n        # Parse the date column into a datetime object\n        memory_date = datetime.strptime(row['date'], \"%Y-%m-%d\")\n\n        # Add the memory with historical date and full context\n        agent_memory.add_historical_memory(memory_content=observation, memory_date=memory_date)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T13:50:39.997854Z","iopub.execute_input":"2025-01-09T13:50:39.998194Z","iopub.status.idle":"2025-01-09T13:50:40.004458Z","shell.execute_reply.started":"2025-01-09T13:50:39.998162Z","shell.execute_reply":"2025-01-09T13:50:40.003577Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"process_and_add_historical_memories(df_HoC_2016, Johnson_memory, \"Boris Johnson\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T13:50:41.725004Z","iopub.execute_input":"2025-01-09T13:50:41.725351Z","iopub.status.idle":"2025-01-09T13:50:42.034659Z","shell.execute_reply.started":"2025-01-09T13:50:41.725319Z","shell.execute_reply":"2025-01-09T13:50:42.033576Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m process_and_add_historical_memories(\u001b[43mdf_HoC_2016\u001b[49m, Johnson_memory, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoris Johnson\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'df_HoC_2016' is not defined"],"ename":"NameError","evalue":"name 'df_HoC_2016' is not defined","output_type":"error"}],"execution_count":23},{"cell_type":"markdown","source":"# Create Simulation","metadata":{}},{"cell_type":"code","source":"# List of agents in the debate\nagents = [Trott, Johnson, Farage, Sunak, Starmer]\n# Define the initial debate topic\ninitial_observation = \"Should the UK rejoin the European Union?\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T00:42:15.183901Z","iopub.execute_input":"2025-01-07T00:42:15.184202Z","iopub.status.idle":"2025-01-07T00:42:15.188512Z","shell.execute_reply.started":"2025-01-07T00:42:15.184177Z","shell.execute_reply":"2025-01-07T00:42:15.187591Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## Framework 2\nEach agent gets `X`-number of speaking slots allocated **randomly**","metadata":{}},{"cell_type":"code","source":"def run_HoC_debate_framework_2 (agents: List[GenerativeAgent],\n                              initial_observation: str) -> None:\n    \"\"\"Runs a conversation between agents, each getting X-number of speaking slots allocated randomly.\"\"\"\n    \n    # Initialize the count of speaking slots for each agent\n    max_slot_each = 2\n    speaking_slots = {agent.name: 0 for agent in agents}\n    max_speaking_slots = max_slot_each * len(agents)\n    turns = 0\n    \n    # Start the debate with an initial observation\n    observation = initial_observation\n    print(observation)\n    \n    # Continue the conversation until each agent has spoken twice\n    while sum(speaking_slots.values()) < max_speaking_slots:\n        \n        # Randomly select an agent who hasn't spoken twice yet\n        agent = random.choice([agent for agent in agents if speaking_slots[agent.name] < max_slot_each])\n        \n        # Each agent generates a response to the latest observation\n        stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n        print(observation)\n        \n        # Increment the speaking slot count for the agent\n        speaking_slots[agent.name] += 1\n        \n        # Increment the turn count\n        turns += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:17:26.564234Z","iopub.execute_input":"2024-12-08T12:17:26.564752Z","iopub.status.idle":"2024-12-08T12:17:26.573552Z","shell.execute_reply.started":"2024-12-08T12:17:26.564713Z","shell.execute_reply":"2024-12-08T12:17:26.572069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run the debate\nrun_HoC_debate_framework_2 (agents, initial_observation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:17:29.101747Z","iopub.execute_input":"2024-12-08T12:17:29.102136Z","iopub.status.idle":"2024-12-08T12:18:26.199499Z","shell.execute_reply.started":"2024-12-08T12:17:29.102103Z","shell.execute_reply":"2024-12-08T12:18:26.198049Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Framework 3\n1. Each agent add new-observation into memory. \n2. Each agent does a quick reflection on this new-observation, to whether to \"respond or not respond\" - depending on personal saliency (a custom function within the class `GenerativeAgent`). Output `decide_to_respond` as either True or False\n3. Randomly select one agent from the list of agents that decide to respond to the observation.\n4. Print this selected generate_dialogue_response as the new observation.","metadata":{}},{"cell_type":"code","source":"# Testing the `decide_to_respond()` function for each agent\nrandom_observation = \"Should the official UK national dish be changed??\"\nrandom_observation = initial_observation\n# Who would respond to the observation? Trott, Johnson, Farage, Sunak, Starmer\nprint(Trott.decide_to_respond(random_observation))\nprint(Johnson.decide_to_respond(random_observation))\nprint(Farage.decide_to_respond(random_observation))\nprint(Sunak.decide_to_respond(random_observation))\nprint(Starmer.decide_to_respond(random_observation))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T12:18:29.061809Z","iopub.execute_input":"2024-12-08T12:18:29.062256Z","iopub.status.idle":"2024-12-08T12:18:51.722819Z","shell.execute_reply.started":"2024-12-08T12:18:29.062206Z","shell.execute_reply":"2024-12-08T12:18:51.721561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Testing the `generate_dialogue_response()` function\nStarmer.generate_dialogue_response(initial_observation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T13:47:34.301532Z","iopub.execute_input":"2024-12-08T13:47:34.302014Z","iopub.status.idle":"2024-12-08T13:47:39.1781Z","shell.execute_reply.started":"2024-12-08T13:47:34.301975Z","shell.execute_reply":"2024-12-08T13:47:39.176814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_HoC_debate_framework_3 (agents: List[GenerativeAgent],             # get a list of agents\n                     initial_observation: str) -> None:         # get the 1st observation\n    \"\"\"Runs a conversation between agents, until a maximum number of turns is reached.\"\"\"\n    \n    max_turns = 10\n    turns = 0\n    \n    # Start the debate with an initial observation\n    observation = initial_observation\n    print(observation)\n    \n    # Enters a loop where agents take turns generating responses\n    while turns < max_turns:\n        \n        # Step 1: Each agent adds the new observation into memory\n        for agent in agents:\n            agent.memory.add_memory(observation)\n            \n        # Step 2: Randomly select one agent from the list of agents that decide to respond to the observation\n        responding_agents = [agent for agent in agents if agent.decide_to_respond(observation)]\n        if responding_agents:\n            agent = random.choice(responding_agents)\n            # The selected agent generates a response to the latest observation\n            stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n            print(observation)\n            \n        # Increment the turn count after each full round of responses\n        turns += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T13:47:50.956482Z","iopub.execute_input":"2024-12-08T13:47:50.956903Z","iopub.status.idle":"2024-12-08T13:47:50.965199Z","shell.execute_reply.started":"2024-12-08T13:47:50.95687Z","shell.execute_reply":"2024-12-08T13:47:50.963944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"run_HoC_debate_framework_3(agents, initial_observation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T13:47:52.805233Z","iopub.execute_input":"2024-12-08T13:47:52.806166Z","iopub.status.idle":"2024-12-08T13:52:52.072043Z","shell.execute_reply.started":"2024-12-08T13:47:52.806125Z","shell.execute_reply":"2024-12-08T13:52:52.070617Z"}},"outputs":[],"execution_count":null}]}