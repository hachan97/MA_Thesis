{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"87340102aee54b358cb522e41aa46e82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_922d18fb9bac440c84a480c86e170e62","IPY_MODEL_58269724075f4f49a77e10541117129a","IPY_MODEL_c635ea0c7af1420c9e19e99fac0d8911"],"layout":"IPY_MODEL_fd5e1e41a6f541ccb5b49100bc93dd99"}},"922d18fb9bac440c84a480c86e170e62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77483ad48d6d498fb18134f467bef8f4","placeholder":"​","style":"IPY_MODEL_8bab809e2b1e42ef91ea3e2a5dce5b6f","value":"Map: 100%"}},"58269724075f4f49a77e10541117129a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dcee8fe207847f293472bbece41da3b","max":2213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0c1d4eacad0483394791bcf48c2afd6","value":2213}},"c635ea0c7af1420c9e19e99fac0d8911":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50b7a8edf7034f69a0d469194a318eec","placeholder":"​","style":"IPY_MODEL_7900f333b9984334b3fbc3106383818f","value":" 2213/2213 [00:02&lt;00:00, 888.82 examples/s]"}},"fd5e1e41a6f541ccb5b49100bc93dd99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77483ad48d6d498fb18134f467bef8f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bab809e2b1e42ef91ea3e2a5dce5b6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dcee8fe207847f293472bbece41da3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c1d4eacad0483394791bcf48c2afd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50b7a8edf7034f69a0d469194a318eec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7900f333b9984334b3fbc3106383818f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85a2d7c5a3924e8cb051a3f5173e2af6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f6335d155b1429daaa3c935b17adde7","IPY_MODEL_68f19a11fe814bcca26e835051900787","IPY_MODEL_94b7a7ecc67944efb5ddf7f01d77e382"],"layout":"IPY_MODEL_3ae974ba8adf4e1fbdf2e2a677385366"}},"9f6335d155b1429daaa3c935b17adde7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b062ec0b7a4347979308126a0eb49e9e","placeholder":"​","style":"IPY_MODEL_f103cbd0af934fe9be65457fe6129819","value":"Loading checkpoint shards: 100%"}},"68f19a11fe814bcca26e835051900787":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b61089229d94d7a81db3960e0fb825c","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1049990845b74bb996724702b35fd652","value":2}},"94b7a7ecc67944efb5ddf7f01d77e382":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d04728683004307bde1e05ea7dbbaa0","placeholder":"​","style":"IPY_MODEL_1aef3e9062d54ea192ec6b582a7045b0","value":" 2/2 [00:32&lt;00:00, 14.62s/it]"}},"3ae974ba8adf4e1fbdf2e2a677385366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b062ec0b7a4347979308126a0eb49e9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f103cbd0af934fe9be65457fe6129819":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b61089229d94d7a81db3960e0fb825c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1049990845b74bb996724702b35fd652":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d04728683004307bde1e05ea7dbbaa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1aef3e9062d54ea192ec6b582a7045b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":214479266,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup Packages","metadata":{"id":"hIkR4TmZN3Yt"}},{"cell_type":"code","source":"# Import libraries\n\n# Standard Python libraries\nimport pandas as pd\nimport pyreadr\nfrom datasets import load_dataset, Dataset  # For loading datasets\nimport os\nimport json\n\n# Hugging Face Transformers\nimport transformers\nfrom transformers import (\n    AutoTokenizer,            # For tokenizing text\n    AutoModelForCausalLM,     # For loading the GPT-2 model\n    Trainer,                  # For training the model\n    TrainingArguments,        # For specifying training arguments\n    logging,                  # For logging\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    pipeline,\n    DataCollatorWithPadding )\n\n# PyTorch\nimport torch  # For tensor operations and GPU support\n\n\n# For PEFT\nfrom peft import prepare_model_for_kbit_training, LoraConfig, PeftModel, get_peft_model  # For LoRA configuration and model\nfrom trl import SFTTrainer  # For supervised fine-tuning","metadata":{"id":"R46fDGCFN_ly","trusted":true,"execution":{"iopub.status.busy":"2024-12-24T01:51:08.591962Z","iopub.execute_input":"2024-12-24T01:51:08.592861Z","iopub.status.idle":"2024-12-24T01:51:27.635539Z","shell.execute_reply.started":"2024-12-24T01:51:08.592793Z","shell.execute_reply":"2024-12-24T01:51:27.634584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"id":"pFIpZiSFo3hG","outputId":"a0ddc125-bdd8-4047-e2cd-10be6f90a7e2","trusted":true,"execution":{"iopub.status.busy":"2024-12-24T01:51:33.216380Z","iopub.execute_input":"2024-12-24T01:51:33.217351Z","iopub.status.idle":"2024-12-24T01:51:33.268855Z","shell.execute_reply.started":"2024-12-24T01:51:33.217305Z","shell.execute_reply":"2024-12-24T01:51:33.267887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Login to Hugging Face\n\n# Set API Keys\nfrom kaggle_secrets import UserSecretsClient # API Loggins\nuser_secrets = UserSecretsClient()\n\n## Hugging Face\nHugging_Face_token = user_secrets.get_secret(\"Hugging_Face_token\")\nfrom huggingface_hub import login\n\nlogin(Hugging_Face_token)","metadata":{"id":"rdFLz2PjYADL","trusted":true,"execution":{"iopub.status.busy":"2024-12-24T01:51:34.545431Z","iopub.execute_input":"2024-12-24T01:51:34.545796Z","iopub.status.idle":"2024-12-24T01:51:34.746402Z","shell.execute_reply.started":"2024-12-24T01:51:34.545764Z","shell.execute_reply":"2024-12-24T01:51:34.745600Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Data","metadata":{"id":"icaFCRI0UOLy"}},{"cell_type":"code","source":"# Load Data \n\nwith open('/kaggle/input/preprocess-data-ipynb/HoC_boris_johnson.jsonl') as f:\n    HoC_json_boris_johnson = [json.loads(line) for line in f]","metadata":{"id":"YlRfVmATegW4","trusted":true,"execution":{"iopub.status.busy":"2024-12-24T01:51:36.544951Z","iopub.execute_input":"2024-12-24T01:51:36.545306Z","iopub.status.idle":"2024-12-24T01:51:36.575185Z","shell.execute_reply.started":"2024-12-24T01:51:36.545276Z","shell.execute_reply":"2024-12-24T01:51:36.574492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert to Hugging Face Dataset\ndf_Boris_Johnson = Dataset.from_list(HoC_json_boris_johnson)","metadata":{"id":"AAm7QEyBg7WS","trusted":true,"execution":{"iopub.status.busy":"2024-12-24T01:51:38.359286Z","iopub.execute_input":"2024-12-24T01:51:38.359601Z","iopub.status.idle":"2024-12-24T01:51:38.436461Z","shell.execute_reply.started":"2024-12-24T01:51:38.359577Z","shell.execute_reply":"2024-12-24T01:51:38.435706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_Boris_Johnson","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T01:51:40.102289Z","iopub.execute_input":"2024-12-24T01:51:40.103095Z","iopub.status.idle":"2024-12-24T01:51:40.108734Z","shell.execute_reply.started":"2024-12-24T01:51:40.103060Z","shell.execute_reply":"2024-12-24T01:51:40.107863Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tokenize Data\n\nDifferent models may require different preprocessing steps based on their *architecture*, *tokenizer type*, and *task*","metadata":{"id":"58ehESMeeIRA"}},{"cell_type":"code","source":"# Tokenize your dataset\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")    # Define the Tokenizer\ntokenizer.pad_token = tokenizer.eos_token                               # Set the padding token to the end-of-sequence token","metadata":{"id":"IWjIJQ0se5PI","outputId":"a88953a5-9e6a-4b89-d425-d338edee9319","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:42:59.118258Z","iopub.execute_input":"2024-12-22T15:42:59.118617Z","iopub.status.idle":"2024-12-22T15:43:00.580585Z","shell.execute_reply.started":"2024-12-22T15:42:59.118587Z","shell.execute_reply":"2024-12-22T15:43:00.579684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenize dataset\ndef preprocess(examples):\n    inputs = tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True, max_length=512)\n    return {\"input_ids\": inputs[\"input_ids\"], \"attention_mask\": inputs[\"attention_mask\"], \"labels\": inputs[\"input_ids\"]}\n\ntokenized_df_Boris_Johnson = df_Boris_Johnson.map(preprocess, batched=True)","metadata":{"id":"IWjIJQ0se5PI","outputId":"a88953a5-9e6a-4b89-d425-d338edee9319","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:51:49.586979Z","iopub.execute_input":"2024-12-22T15:51:49.587358Z","iopub.status.idle":"2024-12-22T15:51:51.058756Z","shell.execute_reply.started":"2024-12-22T15:51:49.587324Z","shell.execute_reply":"2024-12-22T15:51:51.057573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preview tokenized dataset\ntokenized_df_Boris_Johnson","metadata":{"id":"BqudYuPaiPEf","outputId":"0b8aa2fa-0330-42ff-aa0d-d08d3d707cb8","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:34.313917Z","iopub.execute_input":"2024-12-22T15:52:34.314651Z","iopub.status.idle":"2024-12-22T15:52:34.319800Z","shell.execute_reply.started":"2024-12-22T15:52:34.314618Z","shell.execute_reply":"2024-12-22T15:52:34.318953Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Setup","metadata":{"id":"MxR8Gwq_RzBC"}},{"cell_type":"code","source":"# Optimize Performance with Configurations\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,                      # Load model in 4bit, to redeuce memory and computational requirements\n    bnb_4bit_use_double_quant=True,         # Double quantization, further compress the model weights\n    bnb_4bit_quant_type=\"nf4\",              # Quantization type = nf4\n    bnb_4bit_compute_dtype=torch.bfloat16,  # Compute in 16bit format, to speed up computation\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"meta-llama/Llama-3.2-3B-Instruct\",\n    quantization_config=bnb_config,\n    device_map=\"auto\"  # Automatically assigns model to GPU if available\n)","metadata":{"id":"t5O7mYRNOXb6","outputId":"99c584fb-ea1e-444f-c661-aa2a22be38b0","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:39:44.209323Z","iopub.execute_input":"2024-12-22T15:39:44.210089Z","iopub.status.idle":"2024-12-22T15:42:25.434691Z","shell.execute_reply.started":"2024-12-22T15:39:44.210053Z","shell.execute_reply":"2024-12-22T15:42:25.433777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply PEFT (Adapter, LoRA and others)\nmodel.gradient_checkpointing_enable()               # Reduce memory usage by saving intermediate activations\nmodel = prepare_model_for_kbit_training(model)      # Prepare model for kbit training to reduce memory usage","metadata":{"id":"49St8Yk2a0Gx","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:57:45.513525Z","iopub.execute_input":"2024-12-22T15:57:45.514501Z","iopub.status.idle":"2024-12-22T15:57:45.537400Z","shell.execute_reply.started":"2024-12-22T15:57:45.514463Z","shell.execute_reply":"2024-12-22T15:57:45.536745Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inspect Model Architecture\n\nThe attention mechanism in this model is implemented with **modular projections**, as opposed to a **combined module**: `query_key_value` .\nThe model uses distinct linear layers for the query (q_proj), key (k_proj), and value (v_proj) projections","metadata":{"id":"ej943P1ic5D4"}},{"cell_type":"code","source":"# Inspect Model Architecture\nprint(model)","metadata":{"id":"ixxwyp4Ucc6h","outputId":"660e1a47-c111-4411-ac7b-c9072f8ca8c5","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:57:47.749290Z","iopub.execute_input":"2024-12-22T15:57:47.749645Z","iopub.status.idle":"2024-12-22T15:57:47.755853Z","shell.execute_reply.started":"2024-12-22T15:57:47.749616Z","shell.execute_reply":"2024-12-22T15:57:47.755067Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define LoRA","metadata":{"id":"zd0ezAzCc8YR"}},{"cell_type":"code","source":"# Define LoRA configuration\nlora_config = LoraConfig(\n    r=8,                                  # Rank of the low-rank matrices, lower ranks -> lower computational load & memory usage\n    lora_alpha=32,                        # Scaling factor\n    target_modules=[\"q_proj\", \"v_proj\"],  # Specifies the modules that should be adapted using LoRA (*Depends on model architecture)\n    lora_dropout=0.1,                     # A Regularization technique used to prevent overfitting\n    bias=\"none\",                          # specifies that no additional bias terms should be added\n    task_type=\"CAUSAL_LM\"                 # Define the model: one that is 'predicting the next word'\n)\n\n# Apply LoRA to the model\nmodel = get_peft_model(model, lora_config)","metadata":{"id":"suhZIIp7kaWn","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:57:50.078724Z","iopub.execute_input":"2024-12-22T15:57:50.079531Z","iopub.status.idle":"2024-12-22T15:57:50.176913Z","shell.execute_reply.started":"2024-12-22T15:57:50.079496Z","shell.execute_reply":"2024-12-22T15:57:50.176222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n\nprint_trainable_parameters(model)","metadata":{"id":"BWB1QURMa9La","outputId":"0ee74809-aa4c-4ff9-fe8a-0691eae2f583","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:57:52.023921Z","iopub.execute_input":"2024-12-22T15:57:52.024571Z","iopub.status.idle":"2024-12-22T15:57:52.032748Z","shell.execute_reply.started":"2024-12-22T15:57:52.024535Z","shell.execute_reply":"2024-12-22T15:57:52.031851Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define Training Parameters\nDefine training parameters, including batch size, learning rate, and the number of training epochs.","metadata":{"id":"dxJCSt_-jSGR"}},{"cell_type":"code","source":"# Set up Hyperparameters\ntraining_args = transformers.TrainingArguments(\n    output_dir=\"outputs\",\n    optim=\"paged_adamw_8bit\",\n    eval_strategy=\"no\",\n    #report_to=\"none\",                       # Disable WandB integration\n    per_device_train_batch_size=3,          # Adjust the batch size\n    gradient_accumulation_steps=4,          # Increaset gradient-steps to reduce memory usage\n    warmup_steps=2,                         # Helps to stabilize training\n    num_train_epochs=3,                     # Control duration of Training (use either 'max_steps' or 'num_train_epochs')\n    learning_rate=2e-5,\n    logging_steps=10,                       # Frequency of Training metrics logs for detailed feedback on process\n    weight_decay=0.01,\n\n    fp16=True,                              # Enable mixed precision training\n    gradient_checkpointing=True,            # Storing only a subset of activations\n)","metadata":{"id":"apUq0LYGmBJ2","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:57:54.999821Z","iopub.execute_input":"2024-12-22T15:57:55.000122Z","iopub.status.idle":"2024-12-22T15:57:55.035612Z","shell.execute_reply.started":"2024-12-22T15:57:55.000094Z","shell.execute_reply":"2024-12-22T15:57:55.034973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args= training_args,                                 # input Training Arguments\n    train_dataset= tokenized_df_Boris_Johnson,           # input Tokenized Dataset\n    data_collator= transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),   # Format batches of data for training\n)","metadata":{"id":"cM0vXRznl7CO","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:57:56.400106Z","iopub.execute_input":"2024-12-22T15:57:56.400469Z","iopub.status.idle":"2024-12-22T15:57:56.724497Z","shell.execute_reply.started":"2024-12-22T15:57:56.400439Z","shell.execute_reply":"2024-12-22T15:57:56.723678Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fine-Tune the Model","metadata":{"id":"JDekRjeKyCz9"}},{"cell_type":"code","source":"# Log in to W&B\nimport wandb\n\nwandb_api_key = os.getenv(\"wand_API_Key\")\nwandb.login(key=wandb_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T02:10:10.228750Z","iopub.execute_input":"2024-12-24T02:10:10.229668Z","iopub.status.idle":"2024-12-24T02:10:10.240047Z","shell.execute_reply.started":"2024-12-24T02:10:10.229632Z","shell.execute_reply":"2024-12-24T02:10:10.239197Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Train the model\nmodel.config.use_cache = False        # disable caching\ntrainer.train()","metadata":{"id":"EbVIQpWNoirt","outputId":"70c66134-e2dd-4ca5-9f95-a1f16ad00d17","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:58:05.278837Z","iopub.execute_input":"2024-12-22T15:58:05.280017Z","iopub.status.idle":"2024-12-22T16:14:19.111048Z","shell.execute_reply.started":"2024-12-22T15:58:05.279979Z","shell.execute_reply":"2024-12-22T16:14:19.110354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run inference on the model\nmodel.eval()  # Set model to evaluation mode\n\n# Define the pipeline\ntext_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n\n# Generate text\ntext_generator(\"Should the UK rejoin the EU?\", max_length=100, num_return_sequences=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:20:58.918481Z","iopub.execute_input":"2024-12-22T16:20:58.918867Z","iopub.status.idle":"2024-12-22T16:21:20.221060Z","shell.execute_reply.started":"2024-12-22T16:20:58.918834Z","shell.execute_reply":"2024-12-22T16:21:20.220248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()\nmodel.config.use_cache = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:14:48.457076Z","iopub.execute_input":"2024-12-22T16:14:48.457440Z","iopub.status.idle":"2024-12-22T16:14:49.780661Z","shell.execute_reply.started":"2024-12-22T16:14:48.457411Z","shell.execute_reply":"2024-12-22T16:14:49.779828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the Fine-Tuned Model\nmodel.save_pretrained(\"./kaggle/working/fine-tuned-llama_hoc_Boris\")\ntokenizer.save_pretrained(\"./kaggle/working/fine-tuned-llama_hoc_Boris\")","metadata":{"id":"-hnBov-CojD9","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:15:40.926739Z","iopub.execute_input":"2024-12-22T16:15:40.927097Z","iopub.status.idle":"2024-12-22T16:15:41.291130Z","shell.execute_reply.started":"2024-12-22T16:15:40.927066Z","shell.execute_reply":"2024-12-22T16:15:41.290281Z"}},"outputs":[],"execution_count":null}]}