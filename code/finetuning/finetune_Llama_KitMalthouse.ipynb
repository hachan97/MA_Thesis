{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"87340102aee54b358cb522e41aa46e82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_922d18fb9bac440c84a480c86e170e62","IPY_MODEL_58269724075f4f49a77e10541117129a","IPY_MODEL_c635ea0c7af1420c9e19e99fac0d8911"],"layout":"IPY_MODEL_fd5e1e41a6f541ccb5b49100bc93dd99"}},"922d18fb9bac440c84a480c86e170e62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77483ad48d6d498fb18134f467bef8f4","placeholder":"​","style":"IPY_MODEL_8bab809e2b1e42ef91ea3e2a5dce5b6f","value":"Map: 100%"}},"58269724075f4f49a77e10541117129a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dcee8fe207847f293472bbece41da3b","max":2213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0c1d4eacad0483394791bcf48c2afd6","value":2213}},"c635ea0c7af1420c9e19e99fac0d8911":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50b7a8edf7034f69a0d469194a318eec","placeholder":"​","style":"IPY_MODEL_7900f333b9984334b3fbc3106383818f","value":" 2213/2213 [00:02&lt;00:00, 888.82 examples/s]"}},"fd5e1e41a6f541ccb5b49100bc93dd99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77483ad48d6d498fb18134f467bef8f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bab809e2b1e42ef91ea3e2a5dce5b6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dcee8fe207847f293472bbece41da3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c1d4eacad0483394791bcf48c2afd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50b7a8edf7034f69a0d469194a318eec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7900f333b9984334b3fbc3106383818f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85a2d7c5a3924e8cb051a3f5173e2af6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f6335d155b1429daaa3c935b17adde7","IPY_MODEL_68f19a11fe814bcca26e835051900787","IPY_MODEL_94b7a7ecc67944efb5ddf7f01d77e382"],"layout":"IPY_MODEL_3ae974ba8adf4e1fbdf2e2a677385366"}},"9f6335d155b1429daaa3c935b17adde7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b062ec0b7a4347979308126a0eb49e9e","placeholder":"​","style":"IPY_MODEL_f103cbd0af934fe9be65457fe6129819","value":"Loading checkpoint shards: 100%"}},"68f19a11fe814bcca26e835051900787":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b61089229d94d7a81db3960e0fb825c","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1049990845b74bb996724702b35fd652","value":2}},"94b7a7ecc67944efb5ddf7f01d77e382":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d04728683004307bde1e05ea7dbbaa0","placeholder":"​","style":"IPY_MODEL_1aef3e9062d54ea192ec6b582a7045b0","value":" 2/2 [00:32&lt;00:00, 14.62s/it]"}},"3ae974ba8adf4e1fbdf2e2a677385366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b062ec0b7a4347979308126a0eb49e9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f103cbd0af934fe9be65457fe6129819":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b61089229d94d7a81db3960e0fb825c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1049990845b74bb996724702b35fd652":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d04728683004307bde1e05ea7dbbaa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1aef3e9062d54ea192ec6b582a7045b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10884736,"sourceType":"datasetVersion","datasetId":6763766},{"sourceId":225022932,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup Packages","metadata":{"id":"hIkR4TmZN3Yt"}},{"cell_type":"code","source":"# Import libraries\n\n# Standard Python libraries\nimport pandas as pd\n#import pyreadr\nfrom datasets import load_dataset, load_from_disk, Dataset  # For loading datasets\nimport datetime\nimport os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"expandable_segments:True\"\nimport json\nimport matplotlib.pyplot as plt\n\n# Hugging Face Transformers\nimport transformers\nfrom transformers import (\n    AutoTokenizer,            # For tokenizing text\n    AutoModelForCausalLM,     # For loading the GPT-2 model\n    Trainer,                  # For training the model\n    TrainingArguments,        # For specifying training arguments\n    logging,                  # For logging\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    pipeline,\n    DataCollatorWithPadding )\n\n# PyTorch\nimport torch  # For tensor operations and GPU support\n\n# For PEFT\nfrom peft import prepare_model_for_kbit_training, LoraConfig, PeftModel, get_peft_model  # For LoRA configuration and model\nfrom trl import SFTTrainer  # For supervised fine-tuning","metadata":{"id":"R46fDGCFN_ly","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T10:24:25.048232Z","iopub.execute_input":"2025-02-24T10:24:25.048559Z","iopub.status.idle":"2025-02-24T10:24:48.47931Z","shell.execute_reply.started":"2025-02-24T10:24:25.048532Z","shell.execute_reply":"2025-02-24T10:24:48.478699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"id":"pFIpZiSFo3hG","outputId":"a0ddc125-bdd8-4047-e2cd-10be6f90a7e2","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T10:24:54.870266Z","iopub.execute_input":"2025-02-24T10:24:54.870587Z","iopub.status.idle":"2025-02-24T10:24:54.949447Z","shell.execute_reply.started":"2025-02-24T10:24:54.87056Z","shell.execute_reply":"2025-02-24T10:24:54.948488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set API Keys\nfrom kaggle_secrets import UserSecretsClient # API Loggins\nuser_secrets = UserSecretsClient()\n\n## Hugging Face\nHugging_Face_token = user_secrets.get_secret(\"Hugging_Face_token\")\n\n# Login to Hugging Face\nfrom huggingface_hub import login\n\nlogin(Hugging_Face_token)","metadata":{"id":"rdFLz2PjYADL","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T10:24:56.48963Z","iopub.execute_input":"2025-02-24T10:24:56.489922Z","iopub.status.idle":"2025-02-24T10:24:56.650131Z","shell.execute_reply.started":"2025-02-24T10:24:56.4899Z","shell.execute_reply":"2025-02-24T10:24:56.649502Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Tokenizer","metadata":{}},{"cell_type":"code","source":"BASE_MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n\n# Create the tokenizer to measure the length of the text\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, \n                                          add_bos_token=False, \n                                          trust_remote_code=True, \n                                          use_fast=True, \n                                          force_download=False)\n\n#tokenizer.add_special_tokens({'pad_token': '[PAD]'})\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.model_max_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T10:50:50.653081Z","iopub.execute_input":"2025-02-24T10:50:50.653353Z","iopub.status.idle":"2025-02-24T10:50:52.363525Z","shell.execute_reply.started":"2025-02-24T10:50:50.653333Z","shell.execute_reply":"2025-02-24T10:50:52.362773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.special_tokens_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T15:45:03.558366Z","iopub.execute_input":"2025-02-19T15:45:03.558794Z","iopub.status.idle":"2025-02-19T15:45:03.565105Z","shell.execute_reply.started":"2025-02-19T15:45:03.55876Z","shell.execute_reply":"2025-02-19T15:45:03.564203Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Preprocessed Data","metadata":{"id":"icaFCRI0UOLy"}},{"cell_type":"code","source":"today_date = datetime.datetime.now().strftime(\"%d %b %Y\")\n\n# Load the preprocessed JSONL dataset\nwith open(\"/kaggle/input/training-data/preprocessed_KitMalthouse.jsonl\", \"r\") as f:\n    raw_data = [json.loads(line) for line in f]\n\n# Convert into a dataset format that follows the guide\nformatted_data = []\n\nfor convo in raw_data:\n    messages = []\n    \n    for turn in convo[\"conversation\"]:\n        if turn[\"role\"] == \"system\":\n            messages.append({\"role\": \"system\", \"content\": turn[\"content\"]})\n        elif turn[\"role\"] == \"user\":\n            messages.append({\"role\": \"user\", \"content\": turn[\"content\"]})\n        elif turn[\"role\"] == \"assistant\":\n            messages.append({\"role\": \"assistant\", \"content\": turn[\"content\"]})\n    \n    # Apply chat template\n    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    prompt = prompt.replace(f\"Cutting Knowledge Date: December 2023\\nToday Date: {today_date}\\n\\n\",\"\")\n    \n    formatted_data.append({\"prompt\": prompt})\n\n\n# Convert to Hugging Face Dataset\ndataset = Dataset.from_list(formatted_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T10:50:56.174557Z","iopub.execute_input":"2025-02-24T10:50:56.17484Z","iopub.status.idle":"2025-02-24T10:50:56.758484Z","shell.execute_reply.started":"2025-02-24T10:50:56.174819Z","shell.execute_reply":"2025-02-24T10:50:56.757598Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tokenize Data","metadata":{}},{"cell_type":"code","source":"def tokenize_function(example):\n    tokens = tokenizer(example['prompt'], \n                       add_special_tokens=False,\n                       padding=\"max_length\", \n                       truncation=True, \n                       max_length=2048)\n    \n    tokens['labels'] = [-100 if token == tokenizer.pad_token_id else token for token in tokens['input_ids']]\n\n    return tokens\n\n# Apply tokenization \ntokenized_dataset_KitMalthouse = dataset.map(tokenize_function, batched=True)\ntokenized_dataset_KitMalthouse = tokenized_dataset_KitMalthouse.remove_columns(['prompt'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T10:51:37.966228Z","iopub.execute_input":"2025-02-24T10:51:37.966508Z","iopub.status.idle":"2025-02-24T10:51:44.210564Z","shell.execute_reply.started":"2025-02-24T10:51:37.966485Z","shell.execute_reply":"2025-02-24T10:51:44.20988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Distribution of Token Lenghts\ntoken_lengths = [len(sample[\"input_ids\"]) for sample in tokenized_dataset_KitMalthouse]\n\n# Plot histogram\nplt.figure(figsize=(8, 5))\nplt.hist(token_lengths, bins=50, color=\"blue\", edgecolor=\"black\", alpha=0.7)\nplt.xlabel(\"Token Length\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of Tokenized Sequence Lengths\")\n#plt.axvline(x=4096, color=\"red\", linestyle=\"dashed\", label=\"Max Length (4096)\")\nplt.legend()\nplt.show()\n\nprint(f\"Max Length: {max(token_lengths)} | Min Length: {min(token_lengths)} | Avg Length: {sum(token_lengths)/len(token_lengths)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T10:53:03.663643Z","iopub.execute_input":"2025-02-24T10:53:03.66393Z","iopub.status.idle":"2025-02-24T10:53:07.709202Z","shell.execute_reply.started":"2025-02-24T10:53:03.663908Z","shell.execute_reply":"2025-02-24T10:53:07.708479Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Setup","metadata":{"id":"MxR8Gwq_RzBC"}},{"cell_type":"code","source":"# Optimize Performance with Configurations\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,                      # Load model in 4bit, to redeuce memory and computational requirements\n    bnb_4bit_use_double_quant=True,         # Double quantization, further compress the model weights\n    bnb_4bit_quant_type=\"nf4\",              # Quantization type = nf4\n    bnb_4bit_compute_dtype=torch.bfloat16,  # Compute in 16bit format, to speed up computation\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL_ID,\n    quantization_config=bnb_config,\n    device_map=\"auto\"  # Automatically assigns model to GPU if available\n)","metadata":{"id":"t5O7mYRNOXb6","outputId":"99c584fb-ea1e-444f-c661-aa2a22be38b0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply PEFT (Adapter, LoRA and others)\nmodel.gradient_checkpointing_enable()               # Reduce memory usage by saving intermediate activations\nmodel = prepare_model_for_kbit_training(model)      # Prepare model for kbit training to reduce memory usage","metadata":{"id":"49St8Yk2a0Gx","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:08:54.246259Z","iopub.execute_input":"2025-02-19T14:08:54.246541Z","iopub.status.idle":"2025-02-19T14:08:54.25991Z","shell.execute_reply.started":"2025-02-19T14:08:54.246519Z","shell.execute_reply":"2025-02-19T14:08:54.259002Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inspect Model Architecture\n\nThe attention mechanism in this model is implemented with **modular projections**, as opposed to a **combined module**: `query_key_value` .\nThe model uses distinct linear layers for the query (q_proj), key (k_proj), and value (v_proj) projections","metadata":{"id":"ej943P1ic5D4"}},{"cell_type":"code","source":"# Inspect Model Architecture\nprint(model)","metadata":{"id":"ixxwyp4Ucc6h","outputId":"660e1a47-c111-4411-ac7b-c9072f8ca8c5","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T15:35:39.993957Z","iopub.execute_input":"2025-02-19T15:35:39.994321Z","iopub.status.idle":"2025-02-19T15:35:40.002902Z","shell.execute_reply.started":"2025-02-19T15:35:39.994292Z","shell.execute_reply":"2025-02-19T15:35:40.002084Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define LoRA","metadata":{"id":"zd0ezAzCc8YR"}},{"cell_type":"code","source":"# Define LoRA configuration\nlora_config = LoraConfig(\n    r=8,                                  # Rank of the low-rank matrices, lower ranks -> lower computational load & memory usage\n    lora_alpha=32,                        # Scaling factor\n    target_modules=[\"q_proj\", \"v_proj\"],  # Specifies the modules that should be adapted using LoRA (*Depends on model architecture)\n    lora_dropout=0.1,                     # A Regularization technique used to prevent overfitting\n    bias=\"none\",                          # specifies that no additional bias terms should be added\n    task_type=\"CAUSAL_LM\"                 # Define the model: one that is 'predicting the next word'\n)\n\n# Apply LoRA to the model\nmodel = get_peft_model(model, lora_config)","metadata":{"id":"suhZIIp7kaWn","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:44:08.996764Z","iopub.execute_input":"2025-02-19T14:44:08.997121Z","iopub.status.idle":"2025-02-19T14:44:09.058323Z","shell.execute_reply.started":"2025-02-19T14:44:08.997095Z","shell.execute_reply":"2025-02-19T14:44:09.057271Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n\nprint_trainable_parameters(model)","metadata":{"id":"BWB1QURMa9La","outputId":"0ee74809-aa4c-4ff9-fe8a-0691eae2f583","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:44:04.936677Z","iopub.execute_input":"2025-02-19T14:44:04.937007Z","iopub.status.idle":"2025-02-19T14:44:04.944399Z","shell.execute_reply.started":"2025-02-19T14:44:04.936979Z","shell.execute_reply":"2025-02-19T14:44:04.943578Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define Training Parameters\nDefine training parameters, including batch size, learning rate, and the number of training epochs.","metadata":{"id":"dxJCSt_-jSGR"}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"outputs\",\n    optim=\"paged_adamw_8bit\",\n    eval_strategy=\"no\",\n    #report_to=\"none\",                       # Disable WandB integration\n    per_device_train_batch_size=3,          # Adjust the batch size\n    gradient_accumulation_steps=4,          # Increaset gradient-steps to reduce memory usage\n    warmup_steps=2,                         # Helps to stabilize training\n    num_train_epochs=3,                     # Control duration of Training (use either 'max_steps' or 'num_train_epochs')\n    learning_rate=2e-5,\n    logging_steps=10,                       # Frequency of Training metrics logs for detailed feedback on process\n    weight_decay=0.01,\n\n    fp16=True,                              # Enable mixed precision training\n    gradient_checkpointing=True,            # Storing only a subset of activations\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args= training_args,                                 # input Training Arguments\n    train_dataset= tokenized_dataset_KitMalthouse,           # input Tokenized Dataset\n    data_collator= transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),   # Format batches of data for training\n)","metadata":{"id":"cM0vXRznl7CO","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:08:19.829137Z","iopub.execute_input":"2025-02-19T14:08:19.829417Z","iopub.status.idle":"2025-02-19T14:08:19.867384Z","shell.execute_reply.started":"2025-02-19T14:08:19.829396Z","shell.execute_reply":"2025-02-19T14:08:19.866196Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fine-Tune the Model","metadata":{"id":"JDekRjeKyCz9"}},{"cell_type":"code","source":"# Log in to W&B\nimport wandb\n\nwandb_api_key = user_secrets.get_secret(\"wand_API_Key\")\n\nwandb.login(key=wandb_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:01:28.13288Z","iopub.execute_input":"2025-02-19T14:01:28.133215Z","iopub.status.idle":"2025-02-19T14:01:34.69212Z","shell.execute_reply.started":"2025-02-19T14:01:28.133188Z","shell.execute_reply":"2025-02-19T14:01:34.69125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nmodel.config.use_cache = False        # disable caching\ntrainer.train()","metadata":{"id":"EbVIQpWNoirt","outputId":"70c66134-e2dd-4ca5-9f95-a1f16ad00d17","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:01:36.083638Z","iopub.execute_input":"2025-02-19T14:01:36.084301Z","iopub.status.idle":"2025-02-19T14:01:37.305355Z","shell.execute_reply.started":"2025-02-19T14:01:36.084267Z","shell.execute_reply":"2025-02-19T14:01:37.303961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the Fine-Tuned Model\nmodel.save_pretrained(\"./kaggle/working/fine-tuned-llama_KitMalthouse\")\ntokenizer.save_pretrained(\"./kaggle/working/fine-tuned-llama_KitMalthouse\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}