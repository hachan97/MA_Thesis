---
title: "UK_HouseOfCommons"
author: "Haoting Chan"
format: html
editor: visual
---

# Setup

```{r Setup}
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
  c("tidyverse",
    "tidytext",
    "stringi",                         # for string manipulation
    "DataExplorer", "skimr",  "VIM",   # for EDA
    "modelsummary",                    # Descriptive statistics & Models Summary
    "haven", "foreign", "here"         # for STATA data type
    )

packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]

if (length(p_to_install) > 0) {
  install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
```

# Load Raw Data

## Blumenau(2021): 1979 - 2019

Data set from Blumenau, Jack (2021). House of Commons Parliamentary Debates, 1979-2019

https://reshare.ukdataservice.ac.uk/854292/

```{r}
setwd("H:/MA_Thesis/data/Blumenau_2021/")

df_HoC_2016_raw <- read.csv("2016.csv")

# Filter for the top 10 'name' with the most 'count'
df_HoC_2016_raw %>% 
  group_by(name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  head(10)

df_HoC_2016 <- df_HoC_2016_raw %>% 
  select(name, hdate, body, parent, n_words)

# Sum up the numbers in the 'n_words' column for name == 'Boris Johnson'
df_HoC_2016_raw %>% 
  filter(name == "Boris Johnson") %>% 
  summarise(total_words = sum(n_words))


```

```{r}
# Histogram showing Distribution of df_HoC_2016 n_words
ggplot(df_HoC_2016, aes(x = n_words)) +
  geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of n_words in df_HoC_2016",
       x = "Number of Words",
       y = "Frequency") +
  theme_minimal()

# Top 20 Most appeared names in the 'name' column of df_HoC_2016
df_HoC_2016 %>% 
  count(name, sort = TRUE) %>% 
  head(20) %>% 
  ggplot(aes(x = reorder(name, n), y = n)) +
  geom_col(fill = "blue", color = "black", alpha = 0.7) +
  coord_flip() +
  labs(title = "Top 20 Most appeared names in df_HoC_2016",
       x = "Name",
       y = "Frequency") +
  theme_minimal()

# Investigate if the 'parent' column contains words like 'applaus'
df_HoC_2016 %>% 
  filter(str_detect(parent, "applaus")) %>% 
  select(parent, body) %>% 
  head(10)
```


## ParlSpeech (2020): 1988 - 2019

Data set from Harvard Dataverse: ParlSpeech V2 data set. UK House of Commons, 1988 - 2019 https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L4OAKN

```{r}
# Load the Rauh_Schwalbach_2020_ParlSpeech
#setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
setwd("C:/Users/Bryan Chan/Documents/Projects/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_raw <- readRDS("Corp_HouseOfCommons_V2.rds")

df_HoC_raw <- readRDS("C:/Users/chanho/Downloads/Corp_HouseOfCommons_V2.rds")

df_HoC_raw %>% head(10)
```

```{r}
# Process and clean the dataset df_HoC for 1997-2000
df_HoC_1990s <- df_HoC_raw %>% 
  select(-c(parliament, iso3country)) %>%
  mutate(
    date = as.Date(date, format = "%Y-%m-%d"),
    agenda = as.factor(agenda),
    speaker = as.factor(speaker),
    party = as.factor(party),
    chair = as.factor(chair),
    terms = as.factor(terms)
  ) %>%
  filter(date < "2000-01-01") %>% 
  
  # Enhanced text cleaning
  mutate(text = stri_unescape_unicode(text) %>%  # Decode Unicode artifacts
           str_replace_all("\\s+", " ") %>%       # Normalize whitespace
           str_trim() %>%                         # Trim leading/trailing spaces
      
      # Replace specific Unicode artifacts
      str_replace_all("\\u00c2\\u00a3", "£") %>% 
      str_replace_all("\\u00e2\\u20ac\\u0153", "€") %>%
      str_replace_all("\\u00e2\\u20ac\\u009d", "”") %>%
      str_replace_all("\\u00e2\\u20ac\\u02dc", "'") %>% 
      str_replace_all("\\u00e2\\u20ac\\u02dcs", "'s") %>% 
      str_replace_all("\\u00e2\\u20ac\\u201c", "–") %>% 
      str_replace_all("\\u00e2\\u20ac\\u201d", "—") %>% 
      str_replace_all("\\u00e2\\u20ac\\u02dc", "‘") %>% 
      str_replace_all("\\u00e2\\u20ac\\u02dc", "’") %>% 
      str_replace_all("\\u00e2\\u20ac", "€") %>% 
      str_replace_all("\\\\\\\"", "\"") %>%  # Convert escaped quotes
      str_replace_all("\\\\u00a", " ") %>%   # Remove other artifacts like \u00a
      str_replace_all("\\\\u00b", " ") %>%   # Handle \u00b
      str_replace_all("\\\\u00c", " ") %>%   # Handle \u00c

      # Remove any remaining Unicode sequences
      str_replace_all("\\\\u[0-9a-fA-F]{4}", "") %>%
      
      # Optional: Replace common placeholders or fallback text for unmatched Unicode
      str_replace_all("\u0090£", "£") %>%
      str_replace_all("\u20acOn", "€ On") %>%  # Contextual corrections
      str_replace_all("[^[:print:]]", "")     # Remove non-printable characters
  )
```



```{r}
# Process and clean the dataset df_HoC for 2000-2019
df_HoC_2000s <- df_HoC_raw %>% 
  select(-c(parliament, iso3country)) %>% 
  mutate(
    date = as.Date(date, format = "%Y-%m-%d"),
    agenda = as.factor(agenda),
    speaker = as.factor(speaker),
    party = as.factor(party),
    chair = as.factor(chair),
    terms = as.factor(terms)
  ) %>% 
  filter(date >= "2000-01-01" & date <= "2020-12-31") %>% 
  
  # Enhanced text cleaning
  mutate(text = stri_unescape_unicode(text) %>%  # Decode Unicode artifacts
           str_replace_all("\\s+", " ") %>%       # Normalize whitespace
           str_trim() %>%                         # Trim leading/trailing spaces
      
      # Replace specific Unicode artifacts
      str_replace_all("\\u00c2\\u00a3", "£") %>% 
      str_replace_all("\\u00e2\\u20ac\\u0153", "€") %>%
      str_replace_all("\\u00e2\\u20ac\\u009d", "”") %>%
      str_replace_all("\\u00e2\\u20ac\\u02dc", "'") %>% 
      str_replace_all("\\u00e2\\u20ac\\u02dcs", "'s") %>% 
      str_replace_all("\\u00e2\\u20ac\\u201c", "–") %>% 
      str_replace_all("\\u00e2\\u20ac\\u201d", "—") %>% 
      str_replace_all("\\u00e2\\u20ac\\u02dc", "‘") %>% 
      str_replace_all("\\u00e2\\u20ac\\u02dc", "’") %>% 
      str_replace_all("\\u00e2\\u20ac", "€") %>% 
      str_replace_all("\\\\\\\"", "\"") %>%  # Convert escaped quotes
      str_replace_all("\\\\u00a", " ") %>%   # Remove other artifacts like \u00a
      str_replace_all("\\\\u00b", " ") %>%   # Handle \u00b
      str_replace_all("\\\\u00c", " ") %>%   # Handle \u00c

      # Remove any remaining Unicode sequences
      str_replace_all("\\\\u[0-9a-fA-F]{4}", "") %>%
      
      # Optional: Replace common placeholders or fallback text for unmatched Unicode
      str_replace_all("\u0090£", "£") %>%
      str_replace_all("\u20acOn", "€ On") %>%  # Contextual corrections
      str_replace_all("[^[:print:]]", "")     # Remove non-printable characters
  )
```


```{r}
# Check for Remaining Unicode Artifacts
df_HoC_1990s %>% 
  filter(str_detect(text, "\u00c2\u00a3")) %>% 
  count()

df_HoC_1990s %>%
  filter(str_detect(text, "\u00e2\u20ac\u0153")) %>% 
  count()

df_HoC_1990s %>%
  filter(str_detect(text, "\u00e2\u20ac\u009d")) %>% 
  count()

df_HoC_1990s %>%
  filter(str_detect(text, "\\\\")) %>% 
  count()

# Check for "\u00e2\u0090\u00a3"
df_HoC_1990s %>%
  filter(str_detect(text, "\u00a")) %>% 
  count()

# remove df_HoC_raw from memory
#rm(df_HoC_raw)
```

```{r}
# Save df_HoC_2000s as a csv file
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)

# Save df_HoC_1990s as a csv file
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
setwd("C:/Users/Bryan Chan/Documents/Projects/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
write.csv(df_HoC_1990s, "df_HoC_1990s.csv", row.names = FALSE)

```


```{r}
# Load up df_HoC_2000s
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_2000s <- read.csv("df_HoC_2000s.csv")
```


### EDA

```{r}
# The range of dates where David Cameron has spoken in the House of Commons
df_HoC_raw %>%
  filter(speaker == "David Cameron") %>%
  summarize(min_date = min(date),
            max_date = max(date))

# The range of dates where Theresa May has spoken in the House of Commons
df_HoC_1990s %>%
  filter(speaker == "Theresa May") %>%
  summarize(min_date = min(date),
            max_date = max(date))


```



```{r}
# The number of other speeches between successive appearances by Boris Johnson within the same agenda and date.
df_HoC_2000s %>%
  group_by(date, agenda) %>%
  mutate(row_number = row_number()) %>%
  filter(speaker == "Boris Johnson") %>%
  mutate(diff = row_number - lag(row_number) - 1) %>%
  filter(!is.na(diff)) %>%
  ungroup() %>%
  count(diff) %>%
  arrange(diff)
```

```{r}
# which year has the most of where speeches by Boris Johnson?
df_HoC_2000s %>%
  filter(speaker == "Boris Johnson") %>%
  mutate(year = year(date)) %>%
  count(year) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col() +
  labs(title = "Number of Speeches by Boris Johnson by Year",
       x = "Year",
       y = "Count")

# Summarize the distribution of 'terms'
df_HoC_2000s %>% 
  count(terms) %>% 
  ggplot(aes(x = terms, y = n)) +
  geom_col(fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of 'terms' in df_HoC_2000s",
       x = "Terms",
       y = "Frequency") +
  theme_minimal()
```






# Create Subsets

## Party DF

```{r}
# Create separate Dataframe for each party
df_Lab <- df_HoC_2000s %>% filter(party == "Lab")
df_Con <- df_HoC_2000s %>% filter(party == "Con")
df_LibDem <- df_HoC_2000s %>% filter(party == "LibDem")
df_SNP <- df_HoC_2000s %>% filter(party == "SNP")
df_PlaidCymru <- df_HoC_2000s %>% filter(party == "PlaidCymru")
df_UKIP <- df_HoC_2000s %>% filter(party == "UKIP")
df_GPEW <- df_HoC_2000s %>% filter(party == "GPEW")
df_Independent <- df_HoC_2000s %>% filter(party == "Independent")
df_DUP <- df_HoC_2000s %>% filter(party == "DUP")
df_UUP <- df_HoC_2000s %>% filter(party == "UUP")
df_SDLP <- df_HoC_2000s %>% filter(party == "SDLP")
df_APNI <- df_HoC_2000s %>% filter(party == "APNI")
df_Respect <- df_HoC_2000s %>% filter(party == "Respect")
df_UKUP <- df_HoC_2000s %>% filter(party == "UKUP")
df_ChangeUK <- df_HoC_2000s %>% filter(party == "Change UK")
df_TheIndependents <- df_HoC_2000s %>% filter(party == "The Independents")
df_BirkenheadSocialJustice <- df_HoC_2000s %>% filter(party == "Birkenhead Social Justice")
df_other <- df_HoC_2000s %>% filter(party == "other")

# Save the dataframes into csv.
setwd("C:/Users/Bryan Chan/Documents/Projects/MA_Thesis/data/")
write.csv(df_Lab, "df_Lab.csv", row.names = FALSE)
write.csv(df_Con, "df_Con.csv", row.names = FALSE)
write.csv(df_LibDem, "df_LibDem.csv", row.names = FALSE)

#write.csv(df_SNP, "df_SNP.csv", row.names = FALSE)
#write.csv(df_PlaidCymru, "df_PlaidCymru.csv", row.names = FALSE)
#write.csv(df_UKIP, "df_UKIP.csv", row.names = FALSE)
#write.csv(df_GPEW, "df_GPEW.csv", row.names = FALSE)
#write.csv(df_Independent, "df_Independent.csv", row.names = FALSE)
#write.csv(df_DUP, "df_DUP.csv", row.names = FALSE)
#write.csv(df_UUP, "df_UUP.csv", row.names = FALSE)
#write.csv(df_SDLP, "df_SDLP.csv", row.names = FALSE)
#write.csv(df_APNI, "df_APNI.csv", row.names = FALSE)
#write.csv(df_Respect, "df_Respect.csv", row.names = FALSE)
#write.csv(df_UKUP, "df_UKUP.csv", row.names = FALSE)
#write.csv(df_ChangeUK, "df_ChangeUK.csv", row.names = FALSE)
#write.csv(df_TheIndependents, "df_TheIndependents.csv", row.names = FALSE)
#write.csv(df_BirkenheadSocialJustice, "df_BirkenheadSocialJustice.csv", row.names = FALSE)
#write.csv(df_other, "df_other.csv", row.names = FALSE)

```

## MPs DF

```{r}
setwd("H:/MA_Thesis/data/")
df_Con <- read.csv("Rauh_Schwalbach_2020_ParlSpeech/df_Con.csv")

# Filter for 'Boris Johnson' in the speaker column and select only the text column
df_Boris_Johnson <- df_Con %>% 
  filter(speaker == "Boris Johnson") %>% 
  select(text)

# Save the text column as a csv file
setwd("H:/MA_Thesis/data/")
write.csv(df_Boris_Johnson, "Rauh_Schwalbach_2020_ParlSpeech/df_Boris_Johnson_2001-19.csv", 
          row.names = FALSE)

# count the number of words in the text column
df_Boris_Johnson %>% 
  mutate(n_words = str_count(text, "\\S+")) %>% 
  summarise(total_words = sum(n_words))
  # total_words = 259608
```

# Exploratory Data Analysis

```{r}
# Get Overiew
dataset_overview <- plot_intro(df_HoC_raw)
```

```{r}
DGplot_categorical <- df_HoC_2000s %>% 
  plot_bar(title = "Distribution of Categorical variables", ncol = 2)

DGplot_continuous <- df_HoC_2000s %>% 
  plot_histogram(title = "Distribution of Continuous variables", ncol = 2)
```

```{r}
setwd("C:/Users/Bryan Chan/Documents/Projects/MA_Thesis/outputs/") 

# Speech Over Time
plot_speech_overTime <- df_HoC_2000s %>%
  ggplot(aes(x = date)) +
  geom_line(stat = "count") +
  labs(x = "Date", y = "Count", title = "Distribution of Dates")
ggsave("plot_speech_overTime.png", plot_speech_overTime)

# Speeches by Party
plot_speech_byParty <- df_HoC_2000s %>%
  group_by(party) %>%
  summarise(n = n()) %>%
  filter(n > 1000) %>%       # only speeches above 1000
  ggplot(aes(x = party, y = n)) +
  geom_bar(stat = "identity") +
  labs(x = "Party", y = "Count", title = "Number of Speeches by Party") 
ggsave("plot_speech_byParty.png", plot_speech_byParty)

# Speech Length
plot_speech_length <- df_HoC_2000s %>%
  mutate(speech_length = str_count(text, "\\S+")) %>%
  ggplot(aes(x = party, y = speech_length)) +
  geom_boxplot() +
  labs(x = "Party", y = "Speech Length", title = "Speech Length by Party")
ggsave("plot_speech_length.png", plot_speech_length)

# Speech Term Frequency
plot_Term_Frequency <- df_HoC_2000s %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE) %>%
  filter(!word %in% stop_words$word) %>%
  head(10) %>%
  ggplot(aes(reorder(word, n), n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Word", y = "Count", title = "Most Common Words in Speeches")
ggsave("plot_Term_Frequency.png", plot_Term_Frequency)

# Top 10 most frequent speakers
plot_Top10_speakers <- df_HoC_2000s %>%
  group_by(speaker) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>%
  head(10) %>%
  ggplot(aes(reorder(speaker, n), n)) +
  geom_col() +
  coord_flip() +
  labs(x = "Speaker", y = "Count", title = "Top 10 Most Frequent Speakers")
ggsave("plot_Top10_speakers.png", plot_Top10_speakers)
```
