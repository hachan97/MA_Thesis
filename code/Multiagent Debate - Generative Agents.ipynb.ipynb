{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9732067-71c7-46f7-ad09-381b3bf21a27",
   "metadata": {},
   "source": [
    "# Generative Agents in LangChain\n",
    "\n",
    "This notebook implements a generative agent based on the paper [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442) by Park, et. al.\n",
    "\n",
    "In it, we leverage a time-weighted Memory object backed by a LangChain Retriever."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db61fa",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f81c37-db45-4fdc-843c-aa8fd2a9e99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "# Use termcolor to make it easy to colorize the outputs.\n",
    "!pip install termcolor > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3128fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8851c370-b395-4b80-a79d-486a38ffc244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81824e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER_NAME = \"Bryan Chan\"  # The name you want to use when interviewing the agent.\n",
    "LLM = ChatOpenAI(max_tokens=1500)  # Can be any LLM you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da774331",
   "metadata": {},
   "source": [
    "# Create Memory Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da1649-d88f-4973-b655-7042975cde7e",
   "metadata": {},
   "source": [
    "### Generative Agent Memory Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05891979",
   "metadata": {},
   "source": [
    "\n",
    "This tutorial highlights the memory of generative agents and its impact on their behavior. The memory varies from standard LangChain Chat memory in two aspects:\n",
    "\n",
    "1. **Memory Formation**\n",
    "\n",
    "   Generative Agents have extended memories, stored in a single stream:\n",
    "      1. Observations - from dialogues or interactions with the virtual world, about self or others\n",
    "      2. Reflections - resurfaced and summarized core memories\n",
    "\n",
    "\n",
    "2. **Memory Recall**\n",
    "\n",
    "   Memories are retrieved using a weighted sum of salience, recency, and importance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d875f",
   "metadata": {},
   "source": [
    "\n",
    "You can review the definitions of the functions & keyword arguments in the reference documentation:\n",
    "\n",
    "- [GenerativeAgentMemory](https://python.langchain.com/api_reference/experimental/generative_agents/langchain_experimental.generative_agents.memory.GenerativeAgentMemory.html): **Memory** for the generative agent \n",
    "   - `llm`\n",
    "   - `memory_retriever` = create_new_memory_retriever()\n",
    "   - `current_plan`\n",
    "   - `reflection_threshold`\n",
    "   - `add_memory`\n",
    "\n",
    "- [GenerativeAgent](https://python.langchain.com/api_reference/experimental/generative_agents.html): Agent as a character with **memory** and innate **characteristics**,  \n",
    "   - basics like `name`, `age` and `llm`\n",
    "   - `memory` object that combines relevance, recency, and ‘importance’\n",
    "   - `summary` and `summary_refresh_seconds` to set how frequently to re-generate the summary\n",
    "   - `summarize_related_memories`: Summarize memories that are most relevant to an observation\n",
    "   - `status` traits of the character you wish not to change\n",
    "   - `traits` set Permanent traits to ascribe to the character \n",
    "   - `generate_dialogue_response`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043e5203-6a41-431c-9efa-3e1743d7d25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.generative_agents import (\n",
    "    GenerativeAgent,\n",
    "    GenerativeAgentMemory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e51b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GenerativeAgent in module langchain_experimental.generative_agents.generative_agent:\n",
      "\n",
      "class GenerativeAgent(pydantic.main.BaseModel)\n",
      " |  GenerativeAgent(*, name: str, age: Optional[int] = None, traits: str = 'N/A', status: str, memory: langchain_experimental.generative_agents.memory.GenerativeAgentMemory, llm: langchain_core.language_models.base.BaseLanguageModel, verbose: bool = False, summary: str = '', summary_refresh_seconds: int = 3600, last_refreshed: datetime.datetime = None, daily_summaries: List[str] = None) -> None\n",
      " |\n",
      " |  Agent as a character with memory and innate characteristics.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      GenerativeAgent\n",
      " |      pydantic.main.BaseModel\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  chain(self, prompt: langchain_core.prompts.prompt.PromptTemplate) -> langchain.chains.llm.LLMChain\n",
      " |      Create a chain with the same settings as the agent.\n",
      " |\n",
      " |  generate_dialogue_response(self, observation: str, now: Optional[datetime.datetime] = None) -> Tuple[bool, str]\n",
      " |      React to a given observation.\n",
      " |\n",
      " |  generate_reaction(self, observation: str, now: Optional[datetime.datetime] = None) -> Tuple[bool, str]\n",
      " |      React to a given observation.\n",
      " |\n",
      " |  get_full_header(self, force_refresh: bool = False, now: Optional[datetime.datetime] = None) -> str\n",
      " |      Return a full header of the agent's status, summary, and current time.\n",
      " |\n",
      " |  get_summary(self, force_refresh: bool = False, now: Optional[datetime.datetime] = None) -> str\n",
      " |      Return a descriptive summary of the agent.\n",
      " |\n",
      " |  summarize_related_memories(self, observation: str) -> str\n",
      " |      Summarize memories that are most relevant to an observation.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {'age': typing.Optional[int], 'daily_summaries': typ...\n",
      " |\n",
      " |  __class_vars__ = set()\n",
      " |\n",
      " |  __private_attributes__ = {}\n",
      " |\n",
      " |  __pydantic_complete__ = True\n",
      " |\n",
      " |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'langchain_...\n",
      " |\n",
      " |  __pydantic_custom_init__ = False\n",
      " |\n",
      " |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      " |\n",
      " |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      " |\n",
      " |  __pydantic_parent_namespace__ = None\n",
      " |\n",
      " |  __pydantic_post_init__ = None\n",
      " |\n",
      " |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      " |      Model...\n",
      " |\n",
      " |  __pydantic_validator__ = SchemaValidator(title=\"GenerativeAgent\", vali...\n",
      " |\n",
      " |  __signature__ = <Signature (*, name: str, age: Optional[int] = N...Non...\n",
      " |\n",
      " |  model_computed_fields = {}\n",
      " |\n",
      " |  model_config = {'arbitrary_types_allowed': True}\n",
      " |\n",
      " |  model_fields = {'age': FieldInfo(annotation=Union[int, NoneType], requ...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __copy__(self) -> 'Self'\n",
      " |      Returns a shallow copy of the model.\n",
      " |\n",
      " |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      " |      Returns a deep copy of the model.\n",
      " |\n",
      " |  __delattr__(self, item: 'str') -> 'Any'\n",
      " |      Implement delattr(self, name).\n",
      " |\n",
      " |  __eq__(self, other: 'Any') -> 'bool'\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __getattr__(self, item: 'str') -> 'Any'\n",
      " |\n",
      " |  __getstate__(self) -> 'dict[Any, Any]'\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __init__(self, /, **data: 'Any') -> 'None'\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |\n",
      " |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
      " |      validated to form a valid model.\n",
      " |\n",
      " |      `self` is explicitly positional-only to allow `self` as a field name.\n",
      " |\n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      So `dict(model)` works.\n",
      " |\n",
      " |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      " |\n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __repr_args__(self) -> '_repr.ReprArgs'\n",
      " |\n",
      " |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |\n",
      " |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      " |\n",
      " |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      " |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      " |\n",
      " |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      " |      Implement setattr(self, name, value).\n",
      " |\n",
      " |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      " |\n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |\n",
      " |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      Returns a copy of the model.\n",
      " |\n",
      " |      !!! warning \"Deprecated\"\n",
      " |          This method is now deprecated; use `model_copy` instead.\n",
      " |\n",
      " |      If you need `include` or `exclude`, use:\n",
      " |\n",
      " |      ```py\n",
      " |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      " |      data = {**data, **(update or {})}\n",
      " |      copied = self.model_validate(data)\n",
      " |      ```\n",
      " |\n",
      " |      Args:\n",
      " |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      " |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      " |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      " |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      " |\n",
      " |      Returns:\n",
      " |          A copy of the model with included, excluded and updated fields as specified.\n",
      " |\n",
      " |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'\n",
      " |\n",
      " |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'\n",
      " |\n",
      " |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#model_copy\n",
      " |\n",
      " |      Returns a copy of the model.\n",
      " |\n",
      " |      Args:\n",
      " |          update: Values to change/add in the new model. Note: the data is not validated\n",
      " |              before creating the new model. You should trust this data.\n",
      " |          deep: Set to `True` to make a deep copy of the model.\n",
      " |\n",
      " |      Returns:\n",
      " |          New model instance.\n",
      " |\n",
      " |  model_dump(self, *, mode: \"Literal['json', 'python'] | str\" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#modelmodel_dump\n",
      " |\n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |\n",
      " |      Args:\n",
      " |          mode: The mode in which `to_python` should run.\n",
      " |              If mode is 'json', the output will only contain JSON serializable types.\n",
      " |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      " |          include: A set of fields to include in the output.\n",
      " |          exclude: A set of fields to exclude from the output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |\n",
      " |      Returns:\n",
      " |          A dictionary representation of the model.\n",
      " |\n",
      " |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: \"bool | Literal['none', 'warn', 'error']\" = True, serialize_as_any: 'bool' = False) -> 'str'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#modelmodel_dump_json\n",
      " |\n",
      " |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      " |\n",
      " |      Args:\n",
      " |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      " |          include: Field(s) to include in the JSON output.\n",
      " |          exclude: Field(s) to exclude from the JSON output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to serialize using field aliases.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON string representation of the model.\n",
      " |\n",
      " |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'\n",
      " |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      " |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      " |\n",
      " |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'\n",
      " |      Hook into generating the model's CoreSchema.\n",
      " |\n",
      " |      Args:\n",
      " |          source: The class we are generating a schema for.\n",
      " |              This will generally be the same as the `cls` argument if this is a classmethod.\n",
      " |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n",
      " |\n",
      " |      Returns:\n",
      " |          A `pydantic-core` `CoreSchema`.\n",
      " |\n",
      " |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'\n",
      " |      Hook into generating the model's JSON schema.\n",
      " |\n",
      " |      Args:\n",
      " |          core_schema: A `pydantic-core` CoreSchema.\n",
      " |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      " |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      " |              or just call the handler with the original schema.\n",
      " |          handler: Call into Pydantic's internal JSON schema generation.\n",
      " |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      " |              generation fails.\n",
      " |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      " |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      " |              for a type.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON schema, as a Python object.\n",
      " |\n",
      " |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      " |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      " |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n",
      " |      be present when this is called.\n",
      " |\n",
      " |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      " |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      " |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      " |\n",
      " |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      " |      any kwargs passed to the class definition that aren't used internally by pydantic.\n",
      " |\n",
      " |      Args:\n",
      " |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      " |              by pydantic.\n",
      " |\n",
      " |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      " |\n",
      " |  from_orm(obj: 'Any') -> 'Self'\n",
      " |\n",
      " |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      " |      Creates a new instance of the `Model` class with validated data.\n",
      " |\n",
      " |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |\n",
      " |      !!! note\n",
      " |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      " |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      " |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      " |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      " |          an error if extra values are passed, but they will be ignored.\n",
      " |\n",
      " |      Args:\n",
      " |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      " |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      " |              Otherwise, the field names from the `values` argument will be used.\n",
      " |          values: Trusted or pre-validated data dictionary.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new instance of the `Model` class with validated data.\n",
      " |\n",
      " |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'\n",
      " |      Generates a JSON schema for a model class.\n",
      " |\n",
      " |      Args:\n",
      " |          by_alias: Whether to use attribute aliases or not.\n",
      " |          ref_template: The reference template.\n",
      " |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      " |              `GenerateJsonSchema` with your desired modifications\n",
      " |          mode: The mode in which to generate the schema.\n",
      " |\n",
      " |      Returns:\n",
      " |          The JSON schema for the given model class.\n",
      " |\n",
      " |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      " |      Compute the class name for parametrizations of generic classes.\n",
      " |\n",
      " |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      " |\n",
      " |      Args:\n",
      " |          params: Tuple of types of the class. Given a generic class\n",
      " |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      " |              the value `(str, int)` would be passed to `params`.\n",
      " |\n",
      " |      Returns:\n",
      " |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      " |\n",
      " |      Raises:\n",
      " |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      " |\n",
      " |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'\n",
      " |      Try to rebuild the pydantic-core schema for the model.\n",
      " |\n",
      " |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      " |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      " |\n",
      " |      Args:\n",
      " |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      " |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      " |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      " |          _types_namespace: The types namespace, defaults to `None`.\n",
      " |\n",
      " |      Returns:\n",
      " |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      " |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      " |\n",
      " |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      " |      Validate a pydantic model instance.\n",
      " |\n",
      " |      Args:\n",
      " |          obj: The object to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          from_attributes: Whether to extract data from object attributes.\n",
      " |          context: Additional context to pass to the validator.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValidationError: If the object could not be validated.\n",
      " |\n",
      " |      Returns:\n",
      " |          The validated model instance.\n",
      " |\n",
      " |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      " |      Usage docs: https://docs.pydantic.dev/2.9/concepts/json/#json-parsing\n",
      " |\n",
      " |      Validate the given JSON data against the Pydantic model.\n",
      " |\n",
      " |      Args:\n",
      " |          json_data: The JSON data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |\n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      " |\n",
      " |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'\n",
      " |      Validate the given object with string data against the Pydantic model.\n",
      " |\n",
      " |      Args:\n",
      " |          obj: The object containing string data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |\n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |\n",
      " |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      " |\n",
      " |  parse_obj(obj: 'Any') -> 'Self'\n",
      " |\n",
      " |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'\n",
      " |\n",
      " |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      " |\n",
      " |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'\n",
      " |\n",
      " |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      " |\n",
      " |  validate(value: 'Any') -> 'Self'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __fields_set__\n",
      " |\n",
      " |  model_extra\n",
      " |      Get extra fields set during validation.\n",
      " |\n",
      " |      Returns:\n",
      " |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      " |\n",
      " |  model_fields_set\n",
      " |      Returns the set of fields that have been explicitly set on this model instance.\n",
      " |\n",
      " |      Returns:\n",
      " |          A set of strings representing the fields that have been set,\n",
      " |              i.e. that were not filled from defaults.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __pydantic_extra__\n",
      " |\n",
      " |  __pydantic_fields_set__\n",
      " |\n",
      " |  __pydantic_private__\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __hash__ = None\n",
      " |\n",
      " |  __pydantic_root_model__ = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View generative_agents library documentation\n",
    "help(GenerativeAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361bd49e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Memory Lifecycle\n",
    "\n",
    "Summarizing the key methods in the above: `add_memory` and `summarize_related_memories`.\n",
    "\n",
    "When an agent ***makes* an observation**, it stores the memory:\n",
    "    \n",
    "1. Language model scores the memory's importance (1 for mundane - 10 for poignant)\n",
    "2. Observation and importance are stored within a document by TimeWeightedVectorStoreRetriever, with a `last_accessed_time`.\n",
    "\n",
    "When an agent ***responds* to an observation**:\n",
    "\n",
    "1. Generates query(s) for retriever, which fetches documents based on salience + recency + importance.\n",
    "2. Summarizes the retrieved information\n",
    "3. Updates the `last_accessed_time` for the used documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3ca02",
   "metadata": {},
   "source": [
    "## Create a Generative Character\n",
    "\n",
    "Now that we've walked through the definition, we will create two characters named \"Tommie\" and \"Eve\".\n",
    "\n",
    "We use the `faiss` (**Facebook AI Similarity Search**) library to quickly search for embeddings of multimedia documents that are similar to each other, particularly useful for tasks involving large-scale nearest neighbor search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee9c1a1d-c311-4f1c-8131-75fccd9025b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import math\n",
    "import faiss #for efficient similarity search and clustering of dense vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b7deebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevance Score function\n",
    "def relevance_score_fn(score: float) -> float:\n",
    "    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
    "\n",
    "    return 1.0 - score / math.sqrt(2)\n",
    "\n",
    "    # This will differ depending on a few things:\n",
    "    # - the distance / similarity metric used by the VectorStore\n",
    "    # - the scale of your embeddings (OpenAI's are unit norm. Many others are not!)\n",
    "\n",
    "    # This function converts the euclidean norm of normalized embeddings\n",
    "    # (0 is most similar, sqrt(2) most dissimilar)\n",
    "    # to a similarity function (0 to 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e380d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create <emory Retriever\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "\n",
    "    # Define your embedding model\n",
    "    embeddings_model = OpenAIEmbeddings()\n",
    "    \n",
    "    # Initialize the vectorstore as empty\n",
    "    embedding_size = 1536                           # set dimension of the embeddings (produced by the embedding model)\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(\n",
    "        embeddings_model.embed_query,\n",
    "        index,\n",
    "        InMemoryDocstore({}),                       # initialize an empty Memory docstore\n",
    "        {},                                         # index-to-document store ID mapping\n",
    "        relevance_score_fn = relevance_score_fn,    # scoring the relevance of search results\n",
    "    )\n",
    "\n",
    "    # Time-weighted scoring mechanism\n",
    "    return TimeWeightedVectorStoreRetriever(vectorstore=vectorstore,            \n",
    "                                            other_score_keys=[\"importance\"],    # add also the importance score\n",
    "                                            k=15                                # return up to 15 relevant documents\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b971aa",
   "metadata": {},
   "source": [
    "# Single Agent Setup\n",
    "\n",
    "Using the functions of `GenerativeAgentMemory()` and `GenerativeAgent()` from [Langchain Library](https://python.langchain.com/api_reference/experimental/generative_agents.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7884f9dd-c597-4c27-8c77-1402c71bc2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Memory Management system (storing, retrieval, reflection)\n",
    "tommies_memory = GenerativeAgentMemory(\n",
    "    llm=LLM,\n",
    "    memory_retriever = create_new_memory_retriever(),\n",
    "    verbose=False,\n",
    "    reflection_threshold = 8,  # we will give this a relatively low number to show how reflection works\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45993d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Agent Characteristics\n",
    "# (name, age, traits, status, memory_retriever, llm, memory)\n",
    "tommie = GenerativeAgent(\n",
    "    name=\"Tommie\",\n",
    "    age=25,\n",
    "    traits=\"anxious, likes design, talkative\",  # You can add more persistent traits here\n",
    "    status=\"looking for a job\",  # When connected to a virtual world, we can have the characters update their status\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    llm=LLM,\n",
    "    memory=tommies_memory, # Assign the memory management system to the agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c524d529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design, talkative\n",
      "Tommie is independent, confident, and straightforward.\n"
     ]
    }
   ],
   "source": [
    "# The current \"Summary\" of a character can't be made because the agent hasn't made\n",
    "# any observations yet.\n",
    "print(tommie.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be60979-d56e-4abf-a636-b34ffa8b7fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of Additional Observations\n",
    "tommie_observations = [\n",
    "    \"Tommie remembers his dog, Bruno, from when he was a kid\",\n",
    "    \"Tommie feels tired from driving so far\",\n",
    "    \"Tommie sees the new home\",\n",
    "    \"The new neighbors have a cat\",\n",
    "    \"The road is noisy at night\",\n",
    "    \"Tommie is hungry\",\n",
    "    \"Tommie tries to get some rest.\",\n",
    "]\n",
    "\n",
    "# Add the observations to the memory using the 'add_memory()' function\n",
    "for observation in tommie_observations:\n",
    "    tommie.memory.add_memory(observation) # loop through the observations and add to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6992b48b-697f-4973-9560-142ef85357d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design, talkative\n",
      "Tommie is nostalgic, hungry, tired, and trying to rest in a new home with noisy neighbors and a cat nearby.\n"
     ]
    }
   ],
   "source": [
    "# Now that Tommie has 'memories', their self-summary is more descriptive, though still rudimentary.\n",
    "# We will see how this summary updates after more observations to create a more rich description.\n",
    "print(tommie.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d39a32-838c-4a03-8b27-a52c76c402e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-Interview with Character\n",
    "\n",
    "Before sending our character on their way, let's ask them a few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf125d8-f54c-4c5f-b6af-32789b1f7d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create agent to interview Tommie\n",
    "def interview_agent(agent: GenerativeAgent, message: str) -> str:\n",
    "    \"\"\"Help the notebook user interact with the agent.\"\"\"\n",
    "    \n",
    "    new_message = f\"{USER_NAME} says {message}\"\n",
    "    return agent.generate_dialogue_response(new_message)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54024d41-6e83-4914-91e5-73140e2dd9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tommie said \"I really enjoy design and talking with people. What about you?\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e2e8cc-921e-4816-82f1-66962b2c1055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tommie said \"Well, I\\'m actually looking for a job right now, so hopefully I can find some job postings online and start applying. How about you, Person A? What\\'s on your schedule for today?\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are you looking forward to doing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2521ffc-7050-4ac3-9a18-4cccfc798c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tommie said \"Honestly, I\\'m feeling pretty anxious about finding a job. It\\'s been a bit of a struggle lately, but I\\'m trying to stay positive and keep searching. How about you, Person A? What worries you?\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"What are you most worried about today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509c468-f7cd-4d72-9f3a-f4aba28b1eea",
   "metadata": {},
   "source": [
    "## Run Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "154dee3d-bfe0-4828-b963-ed7e885799b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add Additional Observations & Events\n",
    "observations = [\n",
    "    \"Tommie wakes up to the sound of a noisy construction site outside his window.\",\n",
    "    \"Tommie gets out of bed and heads to the kitchen to make himself some coffee.\",\n",
    "    \"Tommie realizes he forgot to buy coffee filters and starts rummaging through his moving boxes to find some.\",\n",
    "    \"Tommie finally finds the filters and makes himself a cup of coffee.\",\n",
    "    \"The coffee tastes bitter, and Tommie regrets not buying a better brand.\",\n",
    "    \"Tommie checks his email and sees that he has no job offers yet.\",\n",
    "    \"Tommie spends some time updating his resume and cover letter.\",\n",
    "    \"Tommie heads out to explore the city and look for job openings.\",\n",
    "    \"Tommie sees a sign for a job fair and decides to attend.\",\n",
    "    \"The line to get in is long, and Tommie has to wait for an hour.\",\n",
    "    \"Tommie meets several potential employers at the job fair but doesn't receive any offers.\",\n",
    "    \"Tommie leaves the job fair feeling disappointed.\",\n",
    "    \"Tommie stops by a local diner to grab some lunch.\",\n",
    "    \"The service is slow, and Tommie has to wait for 30 minutes to get his food.\",\n",
    "    \"Tommie overhears a conversation at the next table about a job opening.\",\n",
    "    \"Tommie asks the diners about the job opening and gets some information about the company.\",\n",
    "    \"Tommie decides to apply for the job and sends his resume and cover letter.\",\n",
    "    \"Tommie continues his search for job openings and drops off his resume at several local businesses.\",\n",
    "    \"Tommie takes a break from his job search to go for a walk in a nearby park.\",\n",
    "    \"A dog approaches and licks Tommie's feet, and he pets it for a few minutes.\",\n",
    "    \"Tommie sees a group of people playing frisbee and decides to join in.\",\n",
    "    \"Tommie has fun playing frisbee but gets hit in the face with the frisbee and hurts his nose.\",\n",
    "    \"Tommie goes back to his apartment to rest for a bit.\",\n",
    "    \"A raccoon tore open the trash bag outside his apartment, and the garbage is all over the floor.\",\n",
    "    \"Tommie starts to feel frustrated with his job search.\",\n",
    "    \"Tommie calls his best friend to vent about his struggles.\",\n",
    "    \"Tommie's friend offers some words of encouragement and tells him to keep trying.\",\n",
    "    \"Tommie feels slightly better after talking to his friend.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b7713b",
   "metadata": {},
   "source": [
    "Run the simulation for a day. \n",
    "- Estimated duration: 17.5 minutes\n",
    "- Cost: $0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "238be49c-edb3-4e26-a2b6-98777ba8de86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTommie wakes up to the sound of a noisy construction site outside his window.\u001b[0m Tommie covers his ears and tries to go back to sleep.\n",
      "\u001b[32mTommie gets out of bed and heads to the kitchen to make himself some coffee.\u001b[0m Tommie smiles and thinks to himself, \"Coffee always helps me start the day right.\"\n",
      "\u001b[32mTommie realizes he forgot to buy coffee filters and starts rummaging through his moving boxes to find some.\u001b[0m Tommie sighs in frustration and makes a mental note to buy coffee filters later.\n",
      "\u001b[32mTommie finally finds the filters and makes himself a cup of coffee.\u001b[0m Tommie takes a sip of his coffee and feels a sense of relief.\n",
      "\u001b[32mThe coffee tastes bitter, and Tommie regrets not buying a better brand.\u001b[0m Tommie grimaces at the bitter taste and makes a mental note to buy a better brand next time.\n",
      "\u001b[32mTommie checks his email and sees that he has no job offers yet.\u001b[0m Tommie feels a pang of disappointment but remains determined to keep looking for job opportunities.\n",
      "\u001b[32mTommie spends some time updating his resume and cover letter.\u001b[0m Tommie feels a sense of accomplishment after updating his resume and cover letter.\n",
      "\u001b[32mTommie heads out to explore the city and look for job openings.\u001b[0m Tommie feels a sense of excitement and determination as he heads out to explore the city and look for job openings.\n",
      "\u001b[32mTommie sees a sign for a job fair and decides to attend.\u001b[0m Tommie feels a surge of hope and excitement at the prospect of finding job opportunities at the job fair.\n",
      "\u001b[32mThe line to get in is long, and Tommie has to wait for an hour.\u001b[0m Tommie feels impatient but tries to stay positive and remind himself that good things come to those who wait.\n",
      "\u001b[32mTommie meets several potential employers at the job fair but doesn't receive any offers.\u001b[0m Tommie feels disappointed but remains determined to keep searching for job opportunities.\n",
      "\u001b[32mTommie leaves the job fair feeling disappointed.\u001b[0m Tommie feels disappointed but remains determined to keep searching for job opportunities.\n",
      "\u001b[32mTommie stops by a local diner to grab some lunch.\u001b[0m Tommie enjoys the comforting atmosphere of the diner and savors his lunch.\n",
      "\u001b[32mThe service is slow, and Tommie has to wait for 30 minutes to get his food.\u001b[0m Tommie feels impatient but tries to stay positive and remind himself that good things come to those who wait.\n",
      "\u001b[32mTommie overhears a conversation at the next table about a job opening.\u001b[0m Tommie feels a surge of excitement and interest in the job opening.\n",
      "\u001b[32mTommie asks the diners about the job opening and gets some information about the company.\u001b[0m Tommie said \"Can you tell me more about the job opening and the company?\"\n",
      "\u001b[32mTommie decides to apply for the job and sends his resume and cover letter.\u001b[0m Tommie feels hopeful and proud of himself for taking action in applying for the job.\n",
      "\u001b[32mTommie continues his search for job openings and drops off his resume at several local businesses.\u001b[0m Tommie feels hopeful and determined after dropping off his resume at several local businesses.\n",
      "\u001b[32mTommie takes a break from his job search to go for a walk in a nearby park.\u001b[0m Tommie feels a sense of relief and relaxation as he takes a break from his job search to go for a walk in a nearby park.\n",
      "\u001b[32mA dog approaches and licks Tommie's feet, and he pets it for a few minutes.\u001b[0m Tommie feels a sense of comfort and nostalgia as he pets the dog, reminiscing about his childhood dog, Bruno.\n",
      "****************************************\n",
      "\u001b[34mAfter 20 observations, Tommie's summary is:\n",
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design, talkative\n",
      "Tommie is a determined and hopeful individual who is actively seeking job opportunities and remains positive despite facing disappointments. He values nostalgia, comfort, and accomplishment, as seen through his interactions with a dog, memories of his childhood dog Bruno, and updating his resume. Tommie also enjoys design and talking with people, showing his sociable and creative side.\u001b[0m\n",
      "****************************************\n",
      "\u001b[32mTommie sees a group of people playing frisbee and decides to join in.\u001b[0m Tommie feels a sense of curiosity and amusement as he watches the group of people playing frisbee.\n",
      "\u001b[32mTommie has fun playing frisbee but gets hit in the face with the frisbee and hurts his nose.\u001b[0m Tommie winces in pain and holds his nose, feeling a mix of embarrassment and discomfort.\n",
      "\u001b[32mTommie goes back to his apartment to rest for a bit.\u001b[0m Tommie feels grateful for the chance to rest and recharge before continuing his job search.\n",
      "\u001b[32mA raccoon tore open the trash bag outside his apartment, and the garbage is all over the floor.\u001b[0m Tommie feels annoyed and frustrated at the mess the raccoon made.\n",
      "\u001b[32mTommie starts to feel frustrated with his job search.\u001b[0m Tommie takes a deep breath and reminds himself to stay positive and keep pushing forward with his job search.\n",
      "\u001b[32mTommie calls his best friend to vent about his struggles.\u001b[0m Tommie feels relieved after venting to his best friend.\n",
      "\u001b[32mTommie's friend offers some words of encouragement and tells him to keep trying.\u001b[0m Tommie feels grateful for his friend's support and encouragement.\n",
      "\u001b[32mTommie feels slightly better after talking to his friend.\u001b[0m Tommie feels grateful for his friend's support and encouragement.\n"
     ]
    }
   ],
   "source": [
    "# Run Simulation\n",
    "# loops over a collection of observations, generating and printing reactions for each observation\n",
    "for i, observation in enumerate(observations):\n",
    "    _, reaction = tommie.generate_reaction(observation)\n",
    "\n",
    "    # Print the observation and the agent's reaction\n",
    "    print(colored(observation, \"green\"), reaction)\n",
    "\n",
    "    # Every 20 observations, print a summary of the agent's state \n",
    "    # using the 'get_summary()' function\n",
    "    if ((i + 1) % 20) == 0:\n",
    "        print(\"*\" * 40)\n",
    "        print(\n",
    "            colored(\n",
    "                f\"After {i+1} observations, Tommie's summary is:\\n{tommie.get_summary(force_refresh=True)}\",\n",
    "                \"blue\",\n",
    "            )\n",
    "        )\n",
    "        print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd62a275-7290-43ca-aa0f-504f3a706d09",
   "metadata": {},
   "source": [
    "## Interview after the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6336ab5d-3074-4831-951f-c9e2cba5dfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tommie said \"It\\'s been a bit of a rollercoaster, to be honest. I\\'ve had some setbacks in my job search, but I also had some good moments today, like sending out a few resumes and meeting some potential employers at a job fair. How about you?\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"Tell me about how your day has been going\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "809ac906-69b7-4326-99ec-af638d32bb20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tommie said \"I really enjoy coffee, but sometimes I regret not buying a better brand. How about you?\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"How do you feel about coffee?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f733a431-19ea-421a-9101-ae2593a8c626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tommie said \"Oh, I had a dog named Bruno when I was a kid. He was a golden retriever and my best friend. I have so many fond memories of him.\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"Tell me about your childhood dog!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4220d306",
   "metadata": {},
   "source": [
    "# Multi Agent Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9261428-778a-4c0b-b725-bc9e91b71391",
   "metadata": {},
   "source": [
    "## Adding Second Character\n",
    "\n",
    "Let's add a second character to have a conversation with Tommie, using the same functions of `GenerativeAgentMemory()` and `GenerativeAgent()` from [Langchain Library](https://python.langchain.com/api_reference/experimental/generative_agents.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8bbe18-a021-419c-bf1f-23d34732cd99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GenerativeAgentMemory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Memory Management system (storing, retrieval, reflection)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m eves_memory \u001b[38;5;241m=\u001b[39m \u001b[43mGenerativeAgentMemory\u001b[49m(\n\u001b[0;32m      3\u001b[0m     llm\u001b[38;5;241m=\u001b[39mLLM,\n\u001b[0;32m      4\u001b[0m     memory_retriever\u001b[38;5;241m=\u001b[39mcreate_new_memory_retriever(),\n\u001b[0;32m      5\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m     reflection_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GenerativeAgentMemory' is not defined"
     ]
    }
   ],
   "source": [
    "# Memory Management system (storing, retrieval, reflection)\n",
    "eves_memory = GenerativeAgentMemory(\n",
    "    llm=LLM,\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    verbose=False,\n",
    "    reflection_threshold=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767265d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Agent Characteristics\n",
    "eve = GenerativeAgent(\n",
    "    name=\"Eve\",\n",
    "    age=34,\n",
    "    traits=\"curious, helpful\",  # You can add more persistent traits here\n",
    "    status=\"N/A\",  # When connected to a virtual world, we can have the characters update their status\n",
    "    llm=LLM,\n",
    "    daily_summaries=[\n",
    "        (\n",
    "            \"Eve started her new job as a career counselor last week and received her first assignment, a client named Tommie.\"\n",
    "        )\n",
    "    ],\n",
    "    memory=eves_memory,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e2745f5-e0da-4abd-98b4-830802ce6698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add Base Observations\n",
    "yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%A %B %d\")\n",
    "\n",
    "eve_observations = [\n",
    "    \"Eve wakes up and hear's the alarm\",\n",
    "    \"Eve eats a boal of porridge\",\n",
    "    \"Eve helps a coworker on a task\",\n",
    "    \"Eve plays tennis with her friend Xu before going to work\",\n",
    "    \"Eve overhears her colleague say something about Tommie being hard to work with\",\n",
    "]\n",
    "\n",
    "for observation in eve_observations:\n",
    "    eve.memory.add_memory(observation)\n",
    "\n",
    "# View the current observations in eve memory\n",
    "eve.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de4726e3-4bb1-47da-8fd9-f317a036fe0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Eve (age: 34)\n",
      "Innate traits: curious, helpful\n",
      "Eve is a helpful and active person who enjoys sports and takes care of her physical health. She is attentive to her surroundings, including her colleagues, and has good time management skills.\n"
     ]
    }
   ],
   "source": [
    "print(eve.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837524e9-7f7e-4e9f-b610-f454062f5915",
   "metadata": {},
   "source": [
    "## Pre-conversation interviews\n",
    "\n",
    "\n",
    "Let's \"Interview\" Eve before she speaks with Tommie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cda916d-800c-47bc-a7f9-6a2f19187472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eve said \"I\\'m feeling pretty good, thanks for asking! Just trying to stay productive and make the most of the day. How about you?\"'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"How are you feeling about today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "448ae644-0a66-4eb2-a03a-319f36948b37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eve said \"I don\\'t know much about Tommie, but I heard someone mention that they find them difficult to work with. Have you had any experiences working with Tommie?\"'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"What do you know about Tommie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "493fc5b8-8730-4ef8-9820-0f1769ce1691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eve said \"That\\'s interesting. I don\\'t know much about Tommie\\'s work experience, but I would probably ask about his strengths and areas for improvement. What about you?\"'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(\n",
    "    eve,\n",
    "    \"Tommie is looking to find a job. What are are some things you'd like to ask him?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b46452a-6c54-4db2-9d87-18597f70fec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eve said \"Sure, I can keep the conversation going and ask plenty of questions. I want to make sure Tommie feels comfortable and supported. Thanks for letting me know.\"'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(\n",
    "    eve,\n",
    "    \"You'll have to ask him. He may be a bit anxious, so I'd appreciate it if you keep the conversation going and ask as many questions as possible.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd780655-1d73-4fcb-a78d-79fd46a20636",
   "metadata": {},
   "source": [
    "## Run Simulation\n",
    "\n",
    " an infinite loop where each agent ***takes turns*** generating responses based on the latest observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "042ea271-4bf1-4247-9082-239a6fea43b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_conversation(agents: List[GenerativeAgent],             # get a list of agents\n",
    "                     initial_observation: str) -> None:         # get the 1st observation\n",
    "    \"\"\"Runs a conversation between agents.\"\"\"\n",
    "\n",
    "    _, observation = agents[1].generate_reaction(initial_observation)   # generate a reaction to observation\n",
    "    print(observation)\n",
    "\n",
    "    turns = 0\n",
    "\n",
    "    # Enters a loop where agents take turns generating responses\n",
    "    while True:\n",
    "        break_dialogue = False\n",
    "\n",
    "        for agent in agents:\n",
    "            \n",
    "            # use 'generate_dialogue_response()' to generate 2 values: stay_in_dialogue and observation\n",
    "            stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n",
    "            print(observation)\n",
    "\n",
    "            # observation = f\"{agent.name} said {reaction}\"\n",
    "            if not stay_in_dialogue:\n",
    "                break_dialogue = True           # if agent wants to break the dialogue, set to True\n",
    "                \n",
    "        if break_dialogue:\n",
    "            break\n",
    "        turns += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5462b14-218e-4d85-b035-df57ea8e0f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the List of Agents\n",
    "agents = [tommie, eve]\n",
    "\n",
    "# Run the conversation\n",
    "run_conversation(\n",
    "    agents,\n",
    "    \"Tommie said: Hi, Eve. Thanks for agreeing to meet with me today. I have a bunch of questions and am not sure where to start. Maybe you could first share about your experience?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28fe80-03dc-4399-961d-6e9ee1980216",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's interview our agents after their conversation\n",
    "\n",
    "Since the generative agents retain their memories from the day, we can ask them about their plans, conversations, and other memoreis.\n",
    "\n",
    "We can see a current \"Summary\" of a character based on their own perception of self has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4d252f3-fcc1-474c-846e-a7605a6b4ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design, talkative\n",
      "Tommie is determined and hopeful in his job search, but can also feel discouraged and frustrated at times. He has a strong connection to his childhood dog, Bruno. Tommie seeks support from his friends when feeling overwhelmed and is grateful for their help. He also enjoys exploring his new city.\n"
     ]
    }
   ],
   "source": [
    "# Print the Summary of the Tommie\n",
    "# We can see a current \"Summary\" of a character based on their own perception of self has changed\n",
    "print(tommie.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c04db9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Eve (age: 34)\n",
      "Innate traits: curious, helpful\n",
      "Eve is a helpful and friendly person who enjoys playing sports and staying productive. She is attentive and responsive to others' needs, actively listening and asking questions to understand their perspectives. Eve has experience in event planning and communication, and is willing to share her knowledge and expertise with others. She values teamwork and collaboration, and strives to create a comfortable and supportive environment for everyone.\n"
     ]
    }
   ],
   "source": [
    "# Print the summary of Eve\n",
    "print(eve.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71762558-8fb6-44d7-8483-f5b47fb2a862",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tommie said \"It was really helpful actually. Eve shared some great tips on managing events and handling unexpected issues. I feel like I learned a lot from her experience.\"'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(tommie, \"How was your conversation with Eve?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "085af3d8-ac21-41ea-8f8b-055c56976a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eve said \"It was great, thanks for asking. Tommie was very receptive and had some great questions about event planning. How about you, have you had any interactions with Tommie?\"'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"How was your conversation with Tommie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b439f3c-7849-4432-a697-2bcc85b89dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eve said \"It was great meeting with you, Tommie. If you have any more questions or need any help in the future, don\\'t hesitate to reach out to me. Have a great day!\"'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(eve, \"What do you wish you would have said to Tommie?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
