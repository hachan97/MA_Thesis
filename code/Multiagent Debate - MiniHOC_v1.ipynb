{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f0ae8c",
   "metadata": {
    "papermill": {
     "duration": 0.008899,
     "end_time": "2025-02-24T19:54:34.395454",
     "exception": false,
     "start_time": "2025-02-24T19:54:34.386555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ff09096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:34.411267Z",
     "iopub.status.busy": "2025-02-24T19:54:34.410967Z",
     "iopub.status.idle": "2025-02-24T19:54:54.782427Z",
     "shell.execute_reply": "2025-02-24T19:54:54.781769Z"
    },
    "papermill": {
     "duration": 20.381503,
     "end_time": "2025-02-24T19:54:54.784487",
     "exception": false,
     "start_time": "2025-02-24T19:54:34.402984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import functools\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "import openai\n",
    "import faiss\n",
    "import tenacity\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.utils import mock_now\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage, BaseMemory, Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "# Pydantic imports\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "\n",
    "# Hugging Face imports\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer, AutoConfig, pipeline, AutoModel)\n",
    "from peft import PeftModel, PeftConfig\n",
    "from langchain_huggingface import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62e5aa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:54.796809Z",
     "iopub.status.busy": "2025-02-24T19:54:54.796320Z",
     "iopub.status.idle": "2025-02-24T19:54:55.415141Z",
     "shell.execute_reply": "2025-02-24T19:54:55.414489Z"
    },
    "papermill": {
     "duration": 0.626895,
     "end_time": "2025-02-24T19:54:55.417006",
     "exception": false,
     "start_time": "2025-02-24T19:54:54.790111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set API Keys\n",
    "from kaggle_secrets import UserSecretsClient # API Loggins\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "## Hugging Face\n",
    "Hugging_Face_token = user_secrets.get_secret(\"Hugging_Face_token\")\n",
    "\n",
    "## Openai\n",
    "OPENAI_API_KEY = user_secrets.get_secret(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f0eab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:55.429761Z",
     "iopub.status.busy": "2025-02-24T19:54:55.429158Z",
     "iopub.status.idle": "2025-02-24T19:54:55.692043Z",
     "shell.execute_reply": "2025-02-24T19:54:55.691117Z"
    },
    "papermill": {
     "duration": 0.27117,
     "end_time": "2025-02-24T19:54:55.693769",
     "exception": false,
     "start_time": "2025-02-24T19:54:55.422599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Login to Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(Hugging_Face_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c008e9",
   "metadata": {
    "papermill": {
     "duration": 0.005585,
     "end_time": "2025-02-24T19:54:55.704986",
     "exception": false,
     "start_time": "2025-02-24T19:54:55.699401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618be41d",
   "metadata": {
    "papermill": {
     "duration": 0.005361,
     "end_time": "2025-02-24T19:54:55.715758",
     "exception": false,
     "start_time": "2025-02-24T19:54:55.710397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Model: GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051b8b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:55.728093Z",
     "iopub.status.busy": "2025-02-24T19:54:55.727441Z",
     "iopub.status.idle": "2025-02-24T19:54:55.751478Z",
     "shell.execute_reply": "2025-02-24T19:54:55.750932Z"
    },
    "papermill": {
     "duration": 0.032004,
     "end_time": "2025-02-24T19:54:55.753115",
     "exception": false,
     "start_time": "2025-02-24T19:54:55.721111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLM_gpt  = ChatOpenAI(model=\"gpt-3.5-turbo\", \n",
    "                 max_tokens=1500, \n",
    "                 api_key = OPENAI_API_KEY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6eaf5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:55.765231Z",
     "iopub.status.busy": "2025-02-24T19:54:55.764723Z",
     "iopub.status.idle": "2025-02-24T19:54:58.740699Z",
     "shell.execute_reply": "2025-02-24T19:54:58.739952Z"
    },
    "papermill": {
     "duration": 2.984102,
     "end_time": "2025-02-24T19:54:58.742643",
     "exception": false,
     "start_time": "2025-02-24T19:54:55.758541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: 1536\n"
     ]
    }
   ],
   "source": [
    "selected_embeddings_model = OpenAIEmbeddings(api_key = OPENAI_API_KEY)\n",
    "embedding_size_selectedLLM = len(selected_embeddings_model.embed_query(\"This is a test.\"))\n",
    "print(f\"Embedding size: {embedding_size_selectedLLM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7afff5",
   "metadata": {
    "papermill": {
     "duration": 0.005739,
     "end_time": "2025-02-24T19:54:58.754249",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.748510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generative AI Setup\n",
    "The [codes](https://python.langchain.com/api_reference/experimental/generative_agents.html) for the classes `GenerativeAgentMemory` and `GenerativeAgent` was entirely reused from the **[LangChain Experimental](https://pypi.org/project/langchain-experimental/)** project in the LangChain Python API reference, with a few minor tweaks and proper configuration of the prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a3adaa",
   "metadata": {
    "papermill": {
     "duration": 0.00534,
     "end_time": "2025-02-24T19:54:58.765122",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.759782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generative Agent Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa67c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:58.777508Z",
     "iopub.status.busy": "2025-02-24T19:54:58.777265Z",
     "iopub.status.idle": "2025-02-24T19:54:58.806348Z",
     "shell.execute_reply": "2025-02-24T19:54:58.805603Z"
    },
    "papermill": {
     "duration": 0.03753,
     "end_time": "2025-02-24T19:54:58.807947",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.770417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenerativeAgentMemory(BaseMemory):\n",
    "    \"\"\"Memory for the generative agent.\"\"\"\n",
    "    \n",
    "    llm: BaseLanguageModel\n",
    "    \"\"\"The core language model.\"\"\"\n",
    "    \n",
    "    memory_retriever: TimeWeightedVectorStoreRetriever\n",
    "    \"\"\"The retriever to fetch related memories.\"\"\"\n",
    "    \n",
    "    verbose: bool = False\n",
    "    reflection_threshold: Optional[float] = None\n",
    "    \"\"\"When aggregate_importance exceeds reflection_threshold, stop to reflect.\"\"\"\n",
    "    \n",
    "    current_plan: List[str] = []\n",
    "    \"\"\"The current plan of the agent.\"\"\"\n",
    "    \n",
    "    # A weight of 0.15 makes this less important than it\n",
    "    # would be otherwise, relative to salience and time\n",
    "    importance_weight: float = 0.15\n",
    "    \"\"\"How much weight to assign the memory importance.\"\"\"\n",
    "    aggregate_importance: float = 0.0  # : :meta private:\n",
    "    \"\"\"Track the sum of the 'importance' of recent memories.\n",
    "    Triggers reflection when it reaches reflection_threshold.\"\"\"\n",
    "    max_tokens_limit: int = 1200  # : :meta private:\n",
    "    \n",
    "    # input keys\n",
    "    queries_key: str = \"queries\"\n",
    "    most_recent_memories_token_key: str = \"recent_memories_token\"\n",
    "    add_memory_key: str = \"add_memory\"\n",
    "    \n",
    "    # output keys\n",
    "    relevant_memories_key: str = \"relevant_memories\"\n",
    "    relevant_memories_simple_key: str = \"relevant_memories_simple\"\n",
    "    most_recent_memories_key: str = \"most_recent_memories\"\n",
    "    now_key: str = \"now\"\n",
    "    reflecting: bool = False\n",
    "    \n",
    "    def chain(self, prompt: PromptTemplate) -> LLMChain:\n",
    "        return LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
    "    @staticmethod\n",
    "    \n",
    "    def _parse_list(text: str) -> List[str]:\n",
    "        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n",
    "        lines = re.split(r\"\\n\", text.strip())\n",
    "        lines = [line for line in lines if line.strip()]  # remove empty lines\n",
    "        return [re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", line).strip() for line in lines]\n",
    "    \n",
    "    def _get_topics_of_reflection(self, last_k: int = 50) -> List[str]:\n",
    "        \"\"\"Return the 3 most salient high-level questions about recent observations.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{observations}\\n\\n\"\n",
    "            \"Given only the information above, what are the 3 most salient \"\n",
    "            \"high-level questions we can answer about the subjects in the statements?\\n\"\n",
    "            \"Provide each question on a new line.\"\n",
    "        )\n",
    "        observations = self.memory_retriever.memory_stream[-last_k:]\n",
    "        observation_str = \"\\n\".join(\n",
    "            [self._format_memory_detail(o) for o in observations]\n",
    "        )\n",
    "        result = self.chain(prompt).run(observations=observation_str)\n",
    "        return self._parse_list(result)\n",
    "    \n",
    "    def _get_insights_on_topic(\n",
    "        self, topic: str, now: Optional[datetime] = None\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Generate 'insights' on a topic of reflection, based on pertinent memories.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"Statements relevant to: '{topic}'\\n\"\n",
    "            \"---\\n\"\n",
    "            \"{related_statements}\\n\"\n",
    "            \"---\\n\"\n",
    "            \"What 5 high-level novel insights can you infer from the above statements \"\n",
    "            \"that are relevant for answering the following question?\\n\"\n",
    "            \"Do not include any insights that are not relevant to the question.\\n\"\n",
    "            \"Do not repeat any insights that have already been made.\\n\\n\"\n",
    "            \"Question: {topic}\\n\\n\"\n",
    "            \"(example format: insight (because of 1, 5, 3))\\n\"\n",
    "        )\n",
    "        related_memories = self.fetch_memories(topic, now=now)\n",
    "        related_statements = \"\\n\".join(\n",
    "            [\n",
    "                self._format_memory_detail(memory, prefix=f\"{i+1}. \")\n",
    "                for i, memory in enumerate(related_memories)\n",
    "            ]\n",
    "        )\n",
    "        result = self.chain(prompt).run(\n",
    "            topic=topic, related_statements=related_statements\n",
    "        )\n",
    "        # TODO: Parse the connections between memories and insights\n",
    "        return self._parse_list(result)\n",
    "    \n",
    "    def pause_to_reflect(self, now: Optional[datetime] = None) -> List[str]:\n",
    "        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n",
    "        if self.verbose:\n",
    "            logger.info(\"Character is reflecting\")\n",
    "        new_insights = []\n",
    "        topics = self._get_topics_of_reflection()\n",
    "        for topic in topics:\n",
    "            insights = self._get_insights_on_topic(topic, now=now)\n",
    "            for insight in insights:\n",
    "                self.add_memory(insight, now=now)\n",
    "            new_insights.extend(insights)\n",
    "        return new_insights\n",
    "    \n",
    "    def _score_memory_importance(self, memory_content: str) -> float:\n",
    "        \"\"\"Score the absolute importance of the given memory.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"On the scale of 1 to 10, where 1 is purely mundane\"\n",
    "            + \" (e.g., brushing teeth, making bed) and 10 is\"\n",
    "            + \" extremely poignant (e.g., a break up, college\"\n",
    "            + \" acceptance), rate the likely poignancy of the\"\n",
    "            + \" following piece of memory. Respond with a single integer.\"\n",
    "            + \"\\nMemory: {memory_content}\"\n",
    "            + \"\\nRating: \"\n",
    "        )\n",
    "        score = self.chain(prompt).run(memory_content=memory_content).strip()\n",
    "        if self.verbose:\n",
    "            logger.info(f\"Importance score: {score}\")\n",
    "        match = re.search(r\"^\\D*(\\d+)\", score)\n",
    "        if match:\n",
    "            return (float(match.group(1)) / 10) * self.importance_weight\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    def _score_memories_importance(self, memory_content: str) -> List[float]:\n",
    "        \"\"\"Score the absolute importance of the given memory.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"On the scale of 1 to 10, where 1 is purely mundane\"\n",
    "            + \" (e.g., brushing teeth, making bed) and 10 is\"\n",
    "            + \" extremely poignant (e.g., a break up, college\"\n",
    "            + \" acceptance), rate the likely poignancy of the\"\n",
    "            + \" following piece of memory. Always answer with only a list of numbers.\"\n",
    "            + \" If just given one memory still respond in a list.\"\n",
    "            + \" Memories are separated by semi colans (;)\"\n",
    "            + \"\\nMemories: {memory_content}\"\n",
    "            + \"\\nRating: \"\n",
    "        )\n",
    "        scores = self.chain(prompt).run(memory_content=memory_content).strip()\n",
    "        if self.verbose:\n",
    "            logger.info(f\"Importance scores: {scores}\")\n",
    "        # Split into list of strings and convert to floats\n",
    "        scores_list = [float(x) for x in scores.split(\";\")]\n",
    "        return scores_list\n",
    "    \n",
    "    def add_memories(\n",
    "        self, memory_content: str, now: Optional[datetime] = None\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Add an observations or memories to the agent's memory.\"\"\"\n",
    "        importance_scores = self._score_memories_importance(memory_content)\n",
    "        self.aggregate_importance += max(importance_scores)\n",
    "        memory_list = memory_content.split(\";\")\n",
    "        documents = []\n",
    "        for i in range(len(memory_list)):\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=memory_list[i],\n",
    "                    metadata={\"importance\": importance_scores[i]},\n",
    "                )\n",
    "            )\n",
    "        result = self.memory_retriever.add_documents(documents, current_time=now)\n",
    "        # After an agent has processed a certain amount of memories (as measured by\n",
    "        # aggregate importance), it is time to reflect on recent events to add\n",
    "        # more synthesized memories to the agent's memory stream.\n",
    "        if (\n",
    "            self.reflection_threshold is not None\n",
    "            and self.aggregate_importance > self.reflection_threshold\n",
    "            and not self.reflecting\n",
    "        ):\n",
    "            self.reflecting = True\n",
    "            self.pause_to_reflect(now=now)\n",
    "            # Hack to clear the importance from reflection\n",
    "            self.aggregate_importance = 0.0\n",
    "            self.reflecting = False\n",
    "        return result\n",
    "    \n",
    "    def add_memory(\n",
    "        self, memory_content: str, now: Optional[datetime] = None\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Add an observation or memory to the agent's memory.\"\"\"\n",
    "        importance_score = self._score_memory_importance(memory_content)\n",
    "        self.aggregate_importance += importance_score\n",
    "        document = Document(\n",
    "            page_content=memory_content, metadata={\"importance\": importance_score}\n",
    "        )\n",
    "        result = self.memory_retriever.add_documents([document], current_time=now)\n",
    "        # After an agent has processed a certain amount of memories (as measured by\n",
    "        # aggregate importance), it is time to reflect on recent events to add\n",
    "        # more synthesized memories to the agent's memory stream.\n",
    "        if (\n",
    "            self.reflection_threshold is not None\n",
    "            and self.aggregate_importance > self.reflection_threshold\n",
    "            and not self.reflecting\n",
    "        ):\n",
    "            self.reflecting = True\n",
    "            self.pause_to_reflect(now=now)\n",
    "            # Hack to clear the importance from reflection\n",
    "            self.aggregate_importance = 0.0\n",
    "            self.reflecting = False\n",
    "        return result\n",
    "    \n",
    "    def fetch_memories(\n",
    "        self, observation: str, now: Optional[datetime] = None\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Fetch related memories.\"\"\"\n",
    "        if now is not None:\n",
    "            with mock_now(now):\n",
    "                return self.memory_retriever.invoke(observation)\n",
    "        else:\n",
    "            return self.memory_retriever.invoke(observation)\n",
    "    \n",
    "    def format_memories_detail(self, relevant_memories: List[Document]) -> str:\n",
    "        content = []\n",
    "        for mem in relevant_memories:\n",
    "            content.append(self._format_memory_detail(mem, prefix=\"- \"))\n",
    "        return \"\\n\".join([f\"{mem}\" for mem in content])\n",
    "    \n",
    "    def _format_memory_detail(self, memory: Document, prefix: str = \"\") -> str:\n",
    "        created_time = memory.metadata[\"created_at\"].strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        return f\"{prefix}[{created_time}] {memory.page_content.strip()}\"\n",
    "    \n",
    "    def format_memories_simple(self, relevant_memories: List[Document]) -> str:\n",
    "        return \"; \".join([f\"{mem.page_content}\" for mem in relevant_memories])\n",
    "    \n",
    "    def _get_memories_until_limit(self, consumed_tokens: int) -> str:\n",
    "        \"\"\"Reduce the number of tokens in the documents.\"\"\"\n",
    "        result = []\n",
    "        for doc in self.memory_retriever.memory_stream[::-1]:\n",
    "            if consumed_tokens >= self.max_tokens_limit:\n",
    "                break\n",
    "            consumed_tokens += self.llm.get_num_tokens(doc.page_content)\n",
    "            if consumed_tokens < self.max_tokens_limit:\n",
    "                result.append(doc)\n",
    "        return self.format_memories_simple(result)\n",
    "    @property\n",
    "    \n",
    "    def memory_variables(self) -> List[str]:\n",
    "        \"\"\"Input keys this memory class will load dynamically.\"\"\"\n",
    "        return []\n",
    "   \n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n",
    "        \"\"\"Return key-value pairs given the text input to the chain.\"\"\"\n",
    "        queries = inputs.get(self.queries_key)\n",
    "        now = inputs.get(self.now_key)\n",
    "        if queries is not None:\n",
    "            relevant_memories = [\n",
    "                mem for query in queries for mem in self.fetch_memories(query, now=now)\n",
    "            ]\n",
    "            return {\n",
    "                self.relevant_memories_key: self.format_memories_detail(\n",
    "                    relevant_memories\n",
    "                ),\n",
    "                self.relevant_memories_simple_key: self.format_memories_simple(\n",
    "                    relevant_memories\n",
    "                ),\n",
    "            }\n",
    "        most_recent_memories_token = inputs.get(self.most_recent_memories_token_key)\n",
    "        if most_recent_memories_token is not None:\n",
    "            return {\n",
    "                self.most_recent_memories_key: self._get_memories_until_limit(\n",
    "                    most_recent_memories_token\n",
    "                )\n",
    "            }\n",
    "        return {}\n",
    "    \n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, Any]) -> None:\n",
    "        \"\"\"Save the context of this model run to memory.\"\"\"\n",
    "        # TODO: fix the save memory key\n",
    "        mem = outputs.get(self.add_memory_key)\n",
    "        now = outputs.get(self.now_key)\n",
    "        if mem:\n",
    "            self.add_memory(mem, now=now)\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear memory contents.\"\"\"\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e60cd2",
   "metadata": {
    "papermill": {
     "duration": 0.005216,
     "end_time": "2025-02-24T19:54:58.818597",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.813381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generative Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2852d77d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:58.830720Z",
     "iopub.status.busy": "2025-02-24T19:54:58.830473Z",
     "iopub.status.idle": "2025-02-24T19:54:58.854437Z",
     "shell.execute_reply": "2025-02-24T19:54:58.853649Z"
    },
    "papermill": {
     "duration": 0.031869,
     "end_time": "2025-02-24T19:54:58.855987",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.824118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenerativeAgent(BaseModel):\n",
    "    \"\"\"Agent as a character with memory and innate characteristics.\"\"\"\n",
    "    name: str\n",
    "    \"\"\"The character's name.\"\"\"\n",
    "    age: Optional[int] = None\n",
    "    \"\"\"The optional age of the character.\"\"\"\n",
    "    traits: str = \"N/A\"\n",
    "    \"\"\"Permanent traits to ascribe to the character.\"\"\"\n",
    "    status: str\n",
    "    \"\"\"The traits of the character you wish not to change.\"\"\"\n",
    "    memory: GenerativeAgentMemory\n",
    "    \"\"\"The memory object that combines relevance, recency, and 'importance'.\"\"\"\n",
    "    llm: BaseLanguageModel\n",
    "    \"\"\"The underlying language model.\"\"\"\n",
    "    verbose: bool = False\n",
    "    summary: str = \"\"  #: :meta private:\n",
    "    \"\"\"Stateful self-summary generated via reflection on the character's memory.\"\"\"\n",
    "    summary_refresh_seconds: int = 3600  #: :meta private:\n",
    "    \"\"\"How frequently to re-generate the summary.\"\"\"\n",
    "    last_refreshed: datetime = Field(default_factory=datetime.now)  # : :meta private:\n",
    "    \"\"\"The last time the character's summary was regenerated.\"\"\"\n",
    "    daily_summaries: List[str] = Field(default_factory=list)  # : :meta private:\n",
    "    \"\"\"Summary of the events in the plan that the agent took.\"\"\"\n",
    "    model_config = ConfigDict(\n",
    "        arbitrary_types_allowed=True,\n",
    "    )\n",
    "    # LLM-related methods\n",
    "    @staticmethod\n",
    "    \n",
    "    def _parse_list(text: str) -> List[str]:\n",
    "        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n",
    "        lines = re.split(r\"\\n\", text.strip())\n",
    "        return [re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", line).strip() for line in lines]\n",
    "        \n",
    "    def chain(self, prompt: PromptTemplate) -> LLMChain:\n",
    "        \"\"\"Create a chain with the same settings as the agent.\"\"\"\n",
    "        return LLMChain(\n",
    "            llm=self.llm, prompt=prompt, verbose=self.verbose, memory=self.memory\n",
    "        )\n",
    "        \n",
    "    def _get_entity_from_observation(self, observation: str) -> str:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"What is the observed entity in the following observation? {observation}\"\n",
    "            + \"\\nEntity=\"\n",
    "        )\n",
    "        return self.chain(prompt).run(observation=observation).strip()\n",
    "        \n",
    "    def _get_entity_action(self, observation: str, entity_name: str) -> str:\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"What is the {entity} doing in the following observation? {observation}\"\n",
    "            + \"\\nThe {entity} is\"\n",
    "        )\n",
    "        return (\n",
    "            self.chain(prompt).run(entity=entity_name, observation=observation).strip()\n",
    "        )\n",
    "\n",
    "## Summarize Most relevant memories\n",
    "    def summarize_related_memories(self, observation: str) -> str:\n",
    "        \"\"\"Summarize memories that are most relevant to an observation.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            {q1}?\n",
    "            Context from memory:\n",
    "            {relevant_memories}\n",
    "            Relevant context: \n",
    "            \"\"\"\n",
    "        )\n",
    "        entity_name = self._get_entity_from_observation(observation)\n",
    "        entity_action = self._get_entity_action(observation, entity_name)\n",
    "        q1 = f\"What is the relationship between {self.name} and {entity_name}\"\n",
    "        q2 = f\"{entity_name} is {entity_action}\"\n",
    "        return self.chain(prompt=prompt).run(q1=q1, queries=[q1, q2]).strip()\n",
    "        \n",
    "## Generate Summary of the agent + reaction \n",
    "    def _generate_reaction(\n",
    "        self, observation: str, suffix: str, now: Optional[datetime] = None\n",
    "    ) -> str:\n",
    "        \"\"\"React to a given observation or dialogue act.\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"{agent_summary_description}\"\n",
    "            + \"\\nIt is {current_time}.\"\n",
    "            + \"\\n{agent_name}'s status: {agent_status}\"\n",
    "            + \"\\nSummary of relevant context from {agent_name}'s memory:\"\n",
    "            + \"\\n{relevant_memories}\"\n",
    "            + \"\\nMost recent observations: {most_recent_memories}\"\n",
    "            + \"\\nObservation: {observation}\"\n",
    "            + \"\\n\\n\"\n",
    "            + suffix\n",
    "        )\n",
    "        agent_summary_description = self.get_summary(now=now)\n",
    "        relevant_memories_str = self.summarize_related_memories(observation)\n",
    "        current_time_str = (\n",
    "            datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "            if now is None\n",
    "            else now.strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        )\n",
    "        kwargs: Dict[str, Any] = dict(\n",
    "            agent_summary_description=agent_summary_description,\n",
    "            current_time=current_time_str,\n",
    "            relevant_memories=relevant_memories_str,\n",
    "            agent_name=self.name,\n",
    "            observation=observation,\n",
    "            agent_status=self.status,\n",
    "        )\n",
    "        consumed_tokens = self.llm.get_num_tokens(\n",
    "            prompt.format(most_recent_memories=\"\", **kwargs)\n",
    "        )\n",
    "        kwargs[self.memory.most_recent_memories_token_key] = consumed_tokens\n",
    "        return self.chain(prompt=prompt).run(**kwargs).strip()\n",
    "        \n",
    "## Clean response\n",
    "    def _clean_response(self, text: str) -> str:\n",
    "        return re.sub(f\"^{self.name} \", \"\", text.strip()).strip()\n",
    "    \n",
    "## Generate Dialogue response\n",
    "    def generate_dialogue_response(\n",
    "        self, observation: str, now: Optional[datetime] = None) -> Tuple[bool, str]:\n",
    "        \"\"\"React to a given observation.\"\"\"\n",
    "        \n",
    "        call_to_action_template = (\n",
    "            \"You are {agent_name}, a Member of Parliament responding in a debate session in the UK House of Commons.\\n\"\n",
    "            \"Act as {agent_name} would, using your distinct voice and perspective. \\n\"\n",
    "            \"Respond to the most recent observations\"\n",
    "            \"Ensure that your response is direct, fully in character, and reflects your established views and tone. \\n\"\n",
    "            \"Respond exactly as {agent_name} would speak in this context.\"\n",
    "        )\n",
    "        \n",
    "        # Generating response with updated prompt\n",
    "        full_result = self._generate_reaction(observation, call_to_action_template, now=now)\n",
    "        #result = re.findall(r'\"(.*?)\"', full_result)[0]\n",
    "        \n",
    "        response_text = self._clean_response(full_result.strip())\n",
    "        self.memory.save_context(\n",
    "            {},\n",
    "            {\n",
    "                self.memory.add_memory_key: f\"{self.name} observed \"\n",
    "                f\"{observation} and said {response_text}\",\n",
    "                self.memory.now_key: now,\n",
    "            },\n",
    "        )\n",
    "        return True, f\"{self.name} said {response_text}\"\n",
    "\n",
    "## Decide if the agent wants to respond to the observation\n",
    "    def decide_to_respond(self, observation: str, now: Optional[datetime] = None,\n",
    "                          threshold: float = 7.0) -> bool:\n",
    "        \"\"\"Decide whether the agent wants to respond to the observation.\"\"\"\n",
    "\n",
    "        call_to_action_template = (\n",
    "            \"You are {agent_name}, a Member of Parliament currently sitting in the UK House of Commons.\"\n",
    "            \"\\nDiscussion Statement:\\n{observation}\\n\\n\"\n",
    "            \"On a scale of 1 to 10, how salient is this discussion to you as an MP?\"\n",
    "            \"\\n- 1: Not relevant at all\"\n",
    "            \"\\n- 10: Extremely relevant\"\n",
    "            \"\\n\\nRespond ONLY with a single integer between 1 and 10.\"\n",
    "            )\n",
    "        \n",
    "        full_result = self._generate_reaction(observation, call_to_action_template, now=now)\n",
    "        result = full_result.strip().lower()  # Normalize result to lowercase for consistent comparison\n",
    "        \n",
    "        try:\n",
    "            relevance_score = float(result)\n",
    "        except ValueError:\n",
    "            #logging.warning(f\"Unexpected non-numeric response from agent: {result}\")\n",
    "            print(f\"Unexpected non-numeric response from agent: {result}\")\n",
    "            relevance_score = 5  # Default low relevance for unexpected responses\n",
    "\n",
    "        # Save the decision context to memory\n",
    "        self.memory.save_context(\n",
    "            {},\n",
    "            {\n",
    "                self.memory.add_memory_key: f\"{self.name} observed \"\n",
    "                f\"that the relevance of the discussion '{observation}' was scored as {result}\",\n",
    "                self.memory.now_key: now,\n",
    "            },\n",
    "        )\n",
    "         \n",
    "        # Check if the model returned \"yes\" or \"no\"\n",
    "        if relevance_score < threshold:\n",
    "            return False\n",
    "        elif relevance_score >= threshold:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Unexpected response: {result}\")  # For debugging purposes\n",
    "            return False\n",
    "    \n",
    "    ######################################################\n",
    "    # Agent stateful' summary methods.                   #\n",
    "    # Each dialog or response prompt includes a header   #\n",
    "    # summarizing the agent's self-description. This is  #\n",
    "    # updated periodically through probing its memories  #\n",
    "    ######################################################\n",
    "    \n",
    "    def _compute_agent_summary(self) -> str:\n",
    "        \"\"\"\"\"\"\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"How would you summarize {name}'s core characteristics given the\"\n",
    "            + \" following statements:\\n\"\n",
    "            + \"{relevant_memories}\"\n",
    "            + \"Do not embellish.\"\n",
    "            + \"\\n\\nSummary: \"\n",
    "        )\n",
    "        # The agent seeks to think about their core characteristics.\n",
    "        return (\n",
    "            self.chain(prompt)\n",
    "            .run(name=self.name, queries=[f\"{self.name}'s core characteristics\"])\n",
    "            .strip()\n",
    "        )\n",
    "    \n",
    "    def get_summary(\n",
    "        self, force_refresh: bool = False, now: Optional[datetime] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Return a descriptive summary of the agent.\"\"\"\n",
    "        current_time = datetime.now() if now is None else now\n",
    "        since_refresh = (current_time - self.last_refreshed).seconds\n",
    "        if (\n",
    "            not self.summary\n",
    "            or since_refresh >= self.summary_refresh_seconds\n",
    "            or force_refresh\n",
    "        ):\n",
    "            self.summary = self._compute_agent_summary()\n",
    "            self.last_refreshed = current_time\n",
    "        age = self.age if self.age is not None else \"N/A\"\n",
    "        return (\n",
    "            f\"Name: {self.name} (age: {age})\"\n",
    "            + f\"\\nInnate traits: {self.traits}\"\n",
    "            + f\"\\n{self.summary}\"\n",
    "        )\n",
    "    \n",
    "    def get_full_header(\n",
    "        self, force_refresh: bool = False, now: Optional[datetime] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Return a full header of the agent's status, summary, and current time.\"\"\"\n",
    "        now = datetime.now() if now is None else now\n",
    "        summary = self.get_summary(force_refresh=force_refresh, now=now)\n",
    "        current_time_str = now.strftime(\"%B %d, %Y, %I:%M %p\")\n",
    "        return (\n",
    "            f\"{summary}\\nIt is {current_time_str}.\\n{self.name}'s status: {self.status}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46c8b8",
   "metadata": {
    "papermill": {
     "duration": 0.005617,
     "end_time": "2025-02-24T19:54:58.867000",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.861383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Agent\n",
    "- [GenerativeAgentMemory](https://python.langchain.com/api_reference/experimental/generative_agents/langchain_experimental.generative_agents.memory.GenerativeAgentMemory.html): **Memory** for the generative agent \n",
    "   - `llm`\n",
    "   - `memory_retriever` = create_new_memory_retriever()\n",
    "   - `current_plan`\n",
    "   - `reflection_threshold`\n",
    "   - `add_memory` add observation/memory\n",
    "- [GenerativeAgent](https://python.langchain.com/api_reference/experimental/generative_agents.html): Agent as a character with **memory** and innate **characteristics**,  \n",
    "   - basics like `name`, `age` and `llm`\n",
    "   - `memory` object that combines relevance, recency, and ‘importance’\n",
    "   - `summary` and `summary_refresh_seconds` to set how frequently to re-generate the summary\n",
    "   - `summarize_related_memories`: Summarize memories that are most relevant to an observation\n",
    "   - `status` fix-objectives / traits of the character you wish not to change\n",
    "   - `traits` set Permanent traits to ascribe to the character \n",
    "   - `generate_dialogue_response`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a08441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:58.878805Z",
     "iopub.status.busy": "2025-02-24T19:54:58.878539Z",
     "iopub.status.idle": "2025-02-24T19:54:58.882164Z",
     "shell.execute_reply": "2025-02-24T19:54:58.881366Z"
    },
    "papermill": {
     "duration": 0.011415,
     "end_time": "2025-02-24T19:54:58.883857",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.872442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Relevance Score function - relevance_score_fn()\n",
    "def relevance_score_fn(score: float) -> float:\n",
    "    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
    "    return 1.0 - score / math.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b7ffdf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:58.895994Z",
     "iopub.status.busy": "2025-02-24T19:54:58.895537Z",
     "iopub.status.idle": "2025-02-24T19:54:58.900067Z",
     "shell.execute_reply": "2025-02-24T19:54:58.899264Z"
    },
    "papermill": {
     "duration": 0.012065,
     "end_time": "2025-02-24T19:54:58.901518",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.889453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Memory Retriever function - create_new_memory_retriever()\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    \n",
    "    embeddings_model = selected_embeddings_model  \n",
    "    \n",
    "    # Initialize the vectorstore as empty\n",
    "    embedding_size = embedding_size_selectedLLM           #use: 1536 (GPT3.5) or 3072 (Llamma)\n",
    "    \n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(\n",
    "        embeddings_model.embed_query,  #use: embeddings_model.embed_query OR llama_embedding_function\n",
    "        index,\n",
    "        InMemoryDocstore({}),  # empty Memory docstore\n",
    "        {},  # index-to-document store ID mapping\n",
    "        relevance_score_fn=relevance_score_fn,\n",
    "    )\n",
    "    \n",
    "    # Time-weighted scoring mechanism\n",
    "    return TimeWeightedVectorStoreRetriever(\n",
    "        vectorstore=vectorstore,\n",
    "        other_score_keys=[\"importance\"],\n",
    "        k=15  # retrieve up to 15 relevant memories\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6123b83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:58.914049Z",
     "iopub.status.busy": "2025-02-24T19:54:58.913299Z",
     "iopub.status.idle": "2025-02-24T19:54:58.917498Z",
     "shell.execute_reply": "2025-02-24T19:54:58.916943Z"
    },
    "papermill": {
     "duration": 0.012027,
     "end_time": "2025-02-24T19:54:58.919061",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.907034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Agent Creation function - create_debate_agent()\n",
    "def create_debate_agent(name, age, traits, status, \n",
    "                        #reflection_threshold, \n",
    "                        llm):\n",
    "   \n",
    "    memory = GenerativeAgentMemory(\n",
    "        llm=llm,\n",
    "        memory_retriever=create_new_memory_retriever(),\n",
    "        verbose=False,\n",
    "        #reflection_threshold=reflection_threshold,  # adjust as needed for reflection frequency\n",
    "    )\n",
    "    \n",
    "    agent = GenerativeAgent(\n",
    "        name=name,\n",
    "        age=age,\n",
    "        traits=traits,\n",
    "        status=status,\n",
    "        memory_retriever=create_new_memory_retriever(),\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc4ad45",
   "metadata": {
    "papermill": {
     "duration": 0.005106,
     "end_time": "2025-02-24T19:54:58.929664",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.924558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Agent Traits\n",
    "\n",
    "'Christine Jardine', 'Kit Malthouse', 'Steve Double', 'Tim Farron', 'Jo Stevens', 'Rachael Maskell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31242264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:58.941782Z",
     "iopub.status.busy": "2025-02-24T19:54:58.941067Z",
     "iopub.status.idle": "2025-02-24T19:54:58.947865Z",
     "shell.execute_reply": "2025-02-24T19:54:58.947208Z"
    },
    "papermill": {
     "duration": 0.014192,
     "end_time": "2025-02-24T19:54:58.949353",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.935161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create agents for each MP\n",
    "ChristineJardine = create_debate_agent(\n",
    "    name=\"Christine Jardine\",\n",
    "    age=2019-1960,  # Example age\n",
    "    traits=\"Advocate for EU citizens' rights, empathetic communicator\",\n",
    "    status=\"Scottish Liberal Democrat politician; Opposes ending free movement; highlights contributions of EU nationals to the UK.\",\n",
    "    llm=LLM_gpt\n",
    ")\n",
    "\n",
    "KitMalthouse = create_debate_agent(\n",
    "    name=\"Kit Malthouse\",\n",
    "    age=2019-1966,  # Example age\n",
    "    traits=\"Firm on immigration control, prioritizes national sovereignty\",\n",
    "    status=\"British Conservative Party politician; Supports ending free movement; focuses on controlled immigration policies.\",\n",
    "    llm=LLM_gpt\n",
    ")\n",
    "\n",
    "SteveDouble = create_debate_agent(\n",
    "    name=\"Steve Double\",\n",
    "    age=2019-1966,  # Example age\n",
    "    traits=\"Emphasizes national interests, supportive of government policies\",\n",
    "    status=\"British Conservative Party politician; Advocates for ending free movement; reassures EU citizens are welcome under new schemes.\",\n",
    "    llm=LLM_gpt\n",
    ")\n",
    "\n",
    "TimFarron = create_debate_agent(\n",
    "    name=\"Tim Farron\",\n",
    "    age=2019-1970,  # Example age\n",
    "    traits=\"Pro-European, champions individual rights\",\n",
    "    status=\"British Liberal Democrats Party politician; Opposes ending free movement; stresses benefits of EU integration.\",\n",
    "    llm=LLM_gpt\n",
    ")\n",
    "\n",
    "JoStevens = create_debate_agent(\n",
    "    name=\"Jo Stevens\",\n",
    "    age=2019-1966,  # Example age\n",
    "    traits=\"Defender of workers' rights, critical of government policies\",\n",
    "    status=\"British Labour Party politician; Questions impact of ending free movement on labor markets and rights.\",\n",
    "    llm=LLM_gpt\n",
    ")\n",
    "\n",
    "RachaelMaskell = create_debate_agent(\n",
    "    name=\"Rachael Maskell\",\n",
    "    age=2019-1972,  # Example age\n",
    "    traits=\"Advocate for social justice, focuses on community welfare\",\n",
    "    status=\"British Labour and Co-operative Party politician; Concerns about social implications of ending free movement; emphasizes inclusive policies.\",\n",
    "    llm=LLM_gpt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba483e45",
   "metadata": {
    "papermill": {
     "duration": 0.005405,
     "end_time": "2025-02-24T19:54:58.960246",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.954841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Base Memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db89ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:58.971869Z",
     "iopub.status.busy": "2025-02-24T19:54:58.971610Z",
     "iopub.status.idle": "2025-02-24T19:54:58.975478Z",
     "shell.execute_reply": "2025-02-24T19:54:58.974718Z"
    },
    "papermill": {
     "duration": 0.011333,
     "end_time": "2025-02-24T19:54:58.977019",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.965686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creat Memory objects for each agent\n",
    "ChristineJardine_memory = ChristineJardine.memory\n",
    "KitMalthouse_memory = KitMalthouse.memory\n",
    "SteveDouble_memory = SteveDouble.memory   \n",
    "TimFarron_memory = TimFarron.memory\n",
    "JoStevens_memory = JoStevens.memory\n",
    "RachaelMaskell_memory = RachaelMaskell.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbb0f25f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:58.989001Z",
     "iopub.status.busy": "2025-02-24T19:54:58.988752Z",
     "iopub.status.idle": "2025-02-24T19:54:58.993571Z",
     "shell.execute_reply": "2025-02-24T19:54:58.992772Z"
    },
    "papermill": {
     "duration": 0.012599,
     "end_time": "2025-02-24T19:54:58.995137",
     "exception": false,
     "start_time": "2025-02-24T19:54:58.982538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base Observations \n",
    "ChristineJardine_observations = [\n",
    "    \"Christine Jardine is a Liberal Democrat MP representing Edinburgh West.\",\n",
    "    \"She has expressed concerns about ending free movement, highlighting its potential negative impact on public services and the economy.\",\n",
    "    \"Jardine emphasizes the human cost of ending free movement, noting that many EU nationals in her constituency feel unwelcome and uncertain about their future.\"\n",
    "]\n",
    "\n",
    "# Base Observations for Kit Malthouse\n",
    "KitMalthouse_observations = [\n",
    "    \"Kit Malthouse is a Conservative MP who has served as the Minister for Crime, Policing and the Fire Service.\",\n",
    "    \"During debates, he has stated that the government is committed to ending free movement as part of the Brexit process.\",\n",
    "    \"Malthouse has reassured that EU citizens residing in the UK are welcome to stay and that the government has implemented the EU Settlement Scheme to facilitate their continued residence.\"\n",
    "]\n",
    "\n",
    "SteveDouble_observations = [\n",
    "    \"Steve Double is a Conservative MP representing St Austell and Newquay.\",\n",
    "    \"He has expressed support for ending free movement, aligning with the government's stance on controlling immigration post-Brexit.\",\n",
    "    \"Double has emphasized that the government has provided a clear message that EU citizens currently residing in the UK are welcome to stay, citing the success of the EU Settlement Scheme.\"\n",
    "]\n",
    "\n",
    "TimFarron_observations = [\n",
    "    \"Tim Farron is a Liberal Democrat MP representing Westmorland and Lonsdale.\",\n",
    "    \"He has criticized the decision to end free movement, arguing that it sends a negative message to EU citizens and undermines the UK's international standing.\",\n",
    "    \"Farron has highlighted the contributions of EU nationals to the UK and has advocated for their rights to be protected post-Brexit.\"\n",
    "]\n",
    "\n",
    "JoStevens_observations = [\n",
    "    \"Jo Stevens is a Labour MP representing Cardiff Central.\",\n",
    "    \"She has raised concerns about the impact of ending free movement on universities, noting that it could harm the UK's global reputation and deter international students and academics.\",\n",
    "    \"Stevens has advocated for the protection of EU nationals' rights and has questioned the government's approach to immigration post-Brexit.\"\n",
    "]\n",
    "\n",
    "RachaelMaskell_observations = [\n",
    "    \"Rachael Maskell is a Labour/Co-operative MP representing York Central.\",\n",
    "    \"She has expressed concerns about the government's immigration policies post-Brexit, particularly regarding family reunification and the rights of unaccompanied minors.\",\n",
    "    \"Maskell has questioned the government's preparedness for the consequences of ending free movement and has called for more compassionate immigration policies.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b5aab59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:54:59.006756Z",
     "iopub.status.busy": "2025-02-24T19:54:59.006489Z",
     "iopub.status.idle": "2025-02-24T19:55:13.627351Z",
     "shell.execute_reply": "2025-02-24T19:55:13.626393Z"
    },
    "papermill": {
     "duration": 14.629019,
     "end_time": "2025-02-24T19:55:13.629382",
     "exception": false,
     "start_time": "2025-02-24T19:54:59.000363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29/716490825.py:39: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  return LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
      "/tmp/ipykernel_29/716490825.py:116: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  score = self.chain(prompt).run(memory_content=memory_content).strip()\n"
     ]
    }
   ],
   "source": [
    "# Loop through the observations and add to memory\n",
    "tuples = [(ChristineJardine_observations, ChristineJardine.memory), \n",
    "          (KitMalthouse_observations, KitMalthouse.memory), \n",
    "          (SteveDouble_observations, SteveDouble.memory), \n",
    "          (TimFarron_observations, TimFarron.memory), \n",
    "          (JoStevens_observations, JoStevens.memory), \n",
    "          (RachaelMaskell_observations, RachaelMaskell.memory)]\n",
    "\n",
    "for observations, memory in tuples:\n",
    "    for observation in observations:\n",
    "        memory.add_memory(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2ceee75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:55:13.642180Z",
     "iopub.status.busy": "2025-02-24T19:55:13.641913Z",
     "iopub.status.idle": "2025-02-24T19:55:13.647706Z",
     "shell.execute_reply": "2025-02-24T19:55:13.647007Z"
    },
    "papermill": {
     "duration": 0.014573,
     "end_time": "2025-02-24T19:55:13.649949",
     "exception": false,
     "start_time": "2025-02-24T19:55:13.635376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christine Jardine's stored memories:\n",
      "[Document(metadata={'importance': 0.03, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 54, 59, 418711), 'created_at': datetime.datetime(2025, 2, 24, 19, 54, 59, 418711), 'buffer_idx': 0}, page_content='Christine Jardine is a Liberal Democrat MP representing Edinburgh West.'), Document(metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 0, 309303), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 0, 309303), 'buffer_idx': 1}, page_content='She has expressed concerns about ending free movement, highlighting its potential negative impact on public services and the economy.'), Document(metadata={'importance': 0.12, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 0, 992203), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 0, 992203), 'buffer_idx': 2}, page_content='Jardine emphasizes the human cost of ending free movement, noting that many EU nationals in her constituency feel unwelcome and uncertain about their future.')]\n",
      "\n",
      "Kit Malthouse's stored memories:\n",
      "[Document(metadata={'importance': 0.03, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 2, 31350), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 2, 31350), 'buffer_idx': 0}, page_content='Kit Malthouse is a Conservative MP who has served as the Minister for Crime, Policing and the Fire Service.'), Document(metadata={'importance': 0.06, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 2, 890936), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 2, 890936), 'buffer_idx': 1}, page_content='During debates, he has stated that the government is committed to ending free movement as part of the Brexit process.'), Document(metadata={'importance': 0.09, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 3, 917033), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 3, 917033), 'buffer_idx': 2}, page_content='Malthouse has reassured that EU citizens residing in the UK are welcome to stay and that the government has implemented the EU Settlement Scheme to facilitate their continued residence.')]\n",
      "\n",
      "Steve Double's stored memories:\n",
      "[Document(metadata={'importance': 0.03, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 5, 76070), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 5, 76070), 'buffer_idx': 0}, page_content='Steve Double is a Conservative MP representing St Austell and Newquay.'), Document(metadata={'importance': 0.03, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 5, 897697), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 5, 897697), 'buffer_idx': 1}, page_content=\"He has expressed support for ending free movement, aligning with the government's stance on controlling immigration post-Brexit.\"), Document(metadata={'importance': 0.075, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 6, 561106), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 6, 561106), 'buffer_idx': 2}, page_content='Double has emphasized that the government has provided a clear message that EU citizens currently residing in the UK are welcome to stay, citing the success of the EU Settlement Scheme.')]\n",
      "\n",
      "Tim Farron's stored memories:\n",
      "[Document(metadata={'importance': 0.03, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 7, 265138), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 7, 265138), 'buffer_idx': 0}, page_content='Tim Farron is a Liberal Democrat MP representing Westmorland and Lonsdale.'), Document(metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 8, 12373), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 8, 12373), 'buffer_idx': 1}, page_content=\"He has criticized the decision to end free movement, arguing that it sends a negative message to EU citizens and undermines the UK's international standing.\"), Document(metadata={'importance': 0.12, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 8, 945305), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 8, 945305), 'buffer_idx': 2}, page_content='Farron has highlighted the contributions of EU nationals to the UK and has advocated for their rights to be protected post-Brexit.')]\n",
      "\n",
      "Jo Stevens's stored memories:\n",
      "[Document(metadata={'importance': 0.03, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 9, 753127), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 9, 753127), 'buffer_idx': 0}, page_content='Jo Stevens is a Labour MP representing Cardiff Central.'), Document(metadata={'importance': 0.075, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 10, 489866), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 10, 489866), 'buffer_idx': 1}, page_content=\"She has raised concerns about the impact of ending free movement on universities, noting that it could harm the UK's global reputation and deter international students and academics.\"), Document(metadata={'importance': 0.105, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 11, 153190), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 11, 153190), 'buffer_idx': 2}, page_content=\"Stevens has advocated for the protection of EU nationals' rights and has questioned the government's approach to immigration post-Brexit.\")]\n",
      "\n",
      "Rachael Maskell's stored memories:\n",
      "[Document(metadata={'importance': 0.015, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 11, 921007), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 11, 921007), 'buffer_idx': 0}, page_content='Rachael Maskell is a Labour/Co-operative MP representing York Central.'), Document(metadata={'importance': 0.09, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 12, 643080), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 12, 643080), 'buffer_idx': 1}, page_content=\"She has expressed concerns about the government's immigration policies post-Brexit, particularly regarding family reunification and the rights of unaccompanied minors.\"), Document(metadata={'importance': 0.06, 'last_accessed_at': datetime.datetime(2025, 2, 24, 19, 55, 13, 358030), 'created_at': datetime.datetime(2025, 2, 24, 19, 55, 13, 358030), 'buffer_idx': 2}, page_content=\"Maskell has questioned the government's preparedness for the consequences of ending free movement and has called for more compassionate immigration policies.\")]\n"
     ]
    }
   ],
   "source": [
    "# View stored memories for each MP\n",
    "print(\"Christine Jardine's stored memories:\")\n",
    "print(ChristineJardine_memory.memory_retriever.memory_stream)\n",
    "\n",
    "print(\"\\nKit Malthouse's stored memories:\")\n",
    "print(KitMalthouse_memory.memory_retriever.memory_stream)\n",
    "\n",
    "print(\"\\nSteve Double's stored memories:\")\n",
    "print(SteveDouble_memory.memory_retriever.memory_stream)\n",
    "\n",
    "print(\"\\nTim Farron's stored memories:\")\n",
    "print(TimFarron_memory.memory_retriever.memory_stream)\n",
    "\n",
    "print(\"\\nJo Stevens's stored memories:\")\n",
    "print(JoStevens_memory.memory_retriever.memory_stream)\n",
    "\n",
    "print(\"\\nRachael Maskell's stored memories:\")\n",
    "print(RachaelMaskell_memory.memory_retriever.memory_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f016542",
   "metadata": {
    "papermill": {
     "duration": 0.005412,
     "end_time": "2025-02-24T19:55:13.661194",
     "exception": false,
     "start_time": "2025-02-24T19:55:13.655782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7f9f6",
   "metadata": {
    "papermill": {
     "duration": 0.005385,
     "end_time": "2025-02-24T19:55:13.672262",
     "exception": false,
     "start_time": "2025-02-24T19:55:13.666877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Input Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4cf914c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:55:13.684527Z",
     "iopub.status.busy": "2025-02-24T19:55:13.684277Z",
     "iopub.status.idle": "2025-02-24T19:55:43.544008Z",
     "shell.execute_reply": "2025-02-24T19:55:43.543275Z"
    },
    "papermill": {
     "duration": 29.868135,
     "end_time": "2025-02-24T19:55:43.546040",
     "exception": false,
     "start_time": "2025-02-24T19:55:13.677905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_HoC_2000s_raw = pd.read_csv('/kaggle/input/parlspeech/df_HoC_2000s.csv')\n",
    "df_HoC_2000s_raw.columns\n",
    "\n",
    "df_HoC_2000s = df_HoC_2000s_raw[['date', 'agenda', 'speechnumber', 'speaker', 'party','text']]\n",
    "\n",
    "df_HoC_miniDebate = df_HoC_2000s[df_HoC_2000s['agenda'].str.contains('Free Movement of EU Nationals', case=False, na=False)]\n",
    "\n",
    "del df_HoC_2000s_raw\n",
    "del df_HoC_2000s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dc30be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:55:43.559664Z",
     "iopub.status.busy": "2025-02-24T19:55:43.559389Z",
     "iopub.status.idle": "2025-02-24T19:55:43.720319Z",
     "shell.execute_reply": "2025-02-24T19:55:43.719512Z"
    },
    "papermill": {
     "duration": 0.169511,
     "end_time": "2025-02-24T19:55:43.721858",
     "exception": false,
     "start_time": "2025-02-24T19:55:43.552347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Christine Jardine said, \"I beg to move, That this House has considered proposed changes to free movement of EU nationals. I am delighted to raise the issue of freedom of movement in the EU, and I thank you, Sir David, for your chairmanship. €End freedom of movement” is a Brexiteer slogan that we have all become so accustomed to that it is easy to forget what it is really saying, and what it would really mean to this country, people living here and British citizens living abroad. We all know the basic numbers: freedom of movement allows 1.3 million British citizens to live, work, study, fall in love, marry, or retire across the European Union while more than 50,000 non-UK EU citizens work in our national health service, including support staff, nurses and doctors, all of whom play a vital role in our nation\\'s health. More than 80,000 EU citizens work in social care, and even more in the UK construction industry. As the Government love to tell us, unemployment is at its lowest rate for 40 years, but where are the British workers who are queuing up and clamouring to take those jobs? If we end freedom of movement, who will care for our sick and elderly? Who will build the 300,000 homes a year that Britain needs? The Government\\'s own figures show that non-UK EU citizens bring far more to our economy and public services than they use. If free movement ends, services will suffer because we will not have the people to continue to provide them at the same level. Those are the numbers, but what about the human cost and the sheer inhumanity of ending freedom of movement? Edinburgh West has constituents from France, Spain, Poland and many other EU countries who have made their lives in the city. Their children were born there, but now they are being told that they are not welcome. They feel they have no option but to leave.\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_observation = 'Christine Jardine said, \"' + df_HoC_miniDebate.iloc[0]['text'] + '\"'\n",
    "initial_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3647e6f",
   "metadata": {
    "papermill": {
     "duration": 0.005613,
     "end_time": "2025-02-24T19:55:43.733339",
     "exception": false,
     "start_time": "2025-02-24T19:55:43.727726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Debate\n",
    "1. Each agent add new-observation into memory. \n",
    "2. Each agent does a quick reflection on this new-observation, to whether to \"respond or not respond\" - depending on personal saliency (a custom function within the class `GenerativeAgent`). Output `decide_to_respond` as either True or False\n",
    "3. Randomly select one agent from the list of agents that decide to respond to the observation.\n",
    "4. Print this selected generate_dialogue_response as the new observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6f8338d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:55:43.746015Z",
     "iopub.status.busy": "2025-02-24T19:55:43.745495Z",
     "iopub.status.idle": "2025-02-24T19:55:43.749112Z",
     "shell.execute_reply": "2025-02-24T19:55:43.748462Z"
    },
    "papermill": {
     "duration": 0.011488,
     "end_time": "2025-02-24T19:55:43.750656",
     "exception": false,
     "start_time": "2025-02-24T19:55:43.739168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of agents in the debate\n",
    "agents = [ChristineJardine, KitMalthouse, SteveDouble, TimFarron, JoStevens, RachaelMaskell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "888f2823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:55:43.763202Z",
     "iopub.status.busy": "2025-02-24T19:55:43.762964Z",
     "iopub.status.idle": "2025-02-24T19:55:43.769605Z",
     "shell.execute_reply": "2025-02-24T19:55:43.768919Z"
    },
    "papermill": {
     "duration": 0.014772,
     "end_time": "2025-02-24T19:55:43.771200",
     "exception": false,
     "start_time": "2025-02-24T19:55:43.756428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_HoC_debate_framework_3(agents: List[GenerativeAgent], \n",
    "                               initial_observation: str, \n",
    "                               save_path: str) -> None:\n",
    "    \"\"\"Runs a conversation between agents and saves the transcript to a file.\"\"\"\n",
    "    \n",
    "    max_turns = 5\n",
    "    turns = 0\n",
    "    last_speaker = ChristineJardine\n",
    "    \n",
    "    # Start the debate with an initial observation\n",
    "    observation = initial_observation\n",
    "    \n",
    "    # Open the file for writing\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"House of Commons Debate Simulation\\n\")\n",
    "        file.write(\"=\" * 50 + \"\\n\")\n",
    "        file.write(f\"Debate Topic: Free Movement of EU Nationals\\n\")\n",
    "        file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        # Write the initial observation\n",
    "        print(observation)\n",
    "        file.write(f\"{observation}\\n\\n\")\n",
    "    \n",
    "        # Debate loop\n",
    "        while turns < max_turns:\n",
    "            # Step 1: Each agent adds the new observation into memory\n",
    "            for agent in agents:\n",
    "                agent.memory.add_memory(observation)\n",
    "                \n",
    "            # Step 2: Randomly select an agent who decides to respond\n",
    "            responding_agents = [agent for agent in agents if agent.decide_to_respond(observation) and agent != last_speaker]\n",
    "            \n",
    "            if responding_agents:\n",
    "                agent = random.choice(responding_agents)\n",
    "                last_speaker = agent\n",
    "                \n",
    "                # Generate response\n",
    "                stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n",
    "                \n",
    "                # Print response to console\n",
    "                print(observation + \"\\n\")\n",
    "                \n",
    "                # Append response to file\n",
    "                with open(save_path, \"a\", encoding=\"utf-8\") as file:\n",
    "                    file.write(f\"{observation}\\n\\n\")\n",
    "            \n",
    "            # Increment turn count\n",
    "            turns += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "933c1a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:55:43.783827Z",
     "iopub.status.busy": "2025-02-24T19:55:43.783550Z",
     "iopub.status.idle": "2025-02-24T19:55:43.790150Z",
     "shell.execute_reply": "2025-02-24T19:55:43.789507Z"
    },
    "papermill": {
     "duration": 0.014774,
     "end_time": "2025-02-24T19:55:43.791608",
     "exception": false,
     "start_time": "2025-02-24T19:55:43.776834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "def run_HoC_debate_framework_3(agents: List[GenerativeAgent], \n",
    "                               initial_observation: str, \n",
    "                               save_path: str) -> None:\n",
    "    \"\"\"Runs a conversation between agents and saves the transcript as a structured table.\"\"\"\n",
    "    \n",
    "    max_turns = 25  # Adjust as needed\n",
    "    turns = 0\n",
    "    last_speaker = ChristineJardine  # Track last speaker\n",
    "    \n",
    "    observation = initial_observation\n",
    "    print(observation)\n",
    "\n",
    "    debate_records = []\n",
    "    debate_records.append({\"speaker\": \"Christine Jardine\", \"text\": observation})  # Add moderator intro\n",
    "    \n",
    "    # Debate loop\n",
    "    while turns < max_turns:\n",
    "        # Step 1: Each agent adds the new observation into memory\n",
    "        for agent in agents:\n",
    "            agent.memory.add_memory(observation)\n",
    "            \n",
    "        # Step 2: Select an agent who decides to respond (excluding the last speaker)\n",
    "        responding_agents = [agent for agent in agents if agent.decide_to_respond(observation) and agent != last_speaker]\n",
    "        \n",
    "        if responding_agents:\n",
    "            agent = random.choice(responding_agents)\n",
    "            last_speaker = agent\n",
    "            \n",
    "            # Generate response\n",
    "            stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n",
    "            \n",
    "            # Print response to console\n",
    "            print(observation + \"\\n\")\n",
    "            \n",
    "            # Append response to the debate records list\n",
    "            debate_records.append({\"speaker\": agent.name, \"text\": observation})\n",
    "        \n",
    "        # Increment turn count\n",
    "        turns += 1\n",
    "    \n",
    "    # Convert debate records to a DataFrame\n",
    "    df_debate = pd.DataFrame(debate_records)\n",
    "    \n",
    "    # Save the DataFrame as a CSV file\n",
    "    df_debate.to_csv(save_path, index=False, encoding=\"utf-8\")\n",
    "    \n",
    "    print(f\"Debate transcript saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c8c9ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T19:55:43.803880Z",
     "iopub.status.busy": "2025-02-24T19:55:43.803573Z",
     "iopub.status.idle": "2025-02-24T20:15:08.958015Z",
     "shell.execute_reply": "2025-02-24T20:15:08.957222Z"
    },
    "papermill": {
     "duration": 1165.170241,
     "end_time": "2025-02-24T20:15:08.967456",
     "exception": false,
     "start_time": "2025-02-24T19:55:43.797215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christine Jardine said, \"I beg to move, That this House has considered proposed changes to free movement of EU nationals. I am delighted to raise the issue of freedom of movement in the EU, and I thank you, Sir David, for your chairmanship. €End freedom of movement” is a Brexiteer slogan that we have all become so accustomed to that it is easy to forget what it is really saying, and what it would really mean to this country, people living here and British citizens living abroad. We all know the basic numbers: freedom of movement allows 1.3 million British citizens to live, work, study, fall in love, marry, or retire across the European Union while more than 50,000 non-UK EU citizens work in our national health service, including support staff, nurses and doctors, all of whom play a vital role in our nation's health. More than 80,000 EU citizens work in social care, and even more in the UK construction industry. As the Government love to tell us, unemployment is at its lowest rate for 40 years, but where are the British workers who are queuing up and clamouring to take those jobs? If we end freedom of movement, who will care for our sick and elderly? Who will build the 300,000 homes a year that Britain needs? The Government's own figures show that non-UK EU citizens bring far more to our economy and public services than they use. If free movement ends, services will suffer because we will not have the people to continue to provide them at the same level. Those are the numbers, but what about the human cost and the sheer inhumanity of ending freedom of movement? Edinburgh West has constituents from France, Spain, Poland and many other EU countries who have made their lives in the city. Their children were born there, but now they are being told that they are not welcome. They feel they have no option but to leave.\"\n",
      "Tim Farron said Thank you, Christine Jardine, for bringing this crucial issue to light. The impact of ending free movement on our society cannot be understated. As you eloquently pointed out, EU citizens play a vital role in our healthcare, social care, and construction industries, among others. The sheer inhumanity of telling these individuals, who have made their lives in the UK, that they are no longer welcome is deeply concerning.\n",
      "\n",
      "It is not just about numbers or economic benefits; it is about the human cost of such a decision. Families are being torn apart, individuals are feeling unwelcome in the place they call home, and our services are at risk of suffering due to a lack of skilled workers. As a pro-European and advocate for individual rights, I stand firmly against the ending of free movement and will continue to fight for the protection of EU nationals' rights post-Brexit.\n",
      "\n",
      "We cannot ignore the voices of those directly affected by these changes, and we must consider the real-life consequences of such a decision. I urge my colleagues to truly understand the impact of ending free movement and to consider the importance of upholding the rights and dignity of all individuals, regardless of their nationality. Thank you.\n",
      "\n",
      "Steve Double said Thank you for bringing up this important issue, Tim. It's clear that there are differing viewpoints on the topic of free movement post-Brexit, and it's crucial that we continue to have these discussions in a respectful manner.\n",
      "\n",
      "While I understand your concerns about the impact of ending free movement on our society, I believe that the government's stance on controlling immigration is in the best interests of the country. We must prioritize national interests and ensure that our immigration policies are sustainable and effective.\n",
      "\n",
      "I stand by the government's position on this matter and support the measures that have been put in place to address the needs of EU citizens currently residing in the UK. The EU Settlement Scheme has been successful in providing clarity and reassurance to those individuals, and we must continue to uphold their rights post-Brexit.\n",
      "\n",
      "I appreciate your advocacy for individual rights, Tim, but we must also consider the broader implications of our immigration policies and the importance of safeguarding our national interests. Let's continue to have these discussions and work towards finding common ground on this complex issue.\n",
      "\n",
      "Kit Malthouse said Thank you for bringing up this important issue, Steve. I appreciate your perspective on the complexities surrounding the topic of free movement post-Brexit. It is crucial that we continue to engage in respectful discussions and consider the broader implications of our immigration policies.\n",
      "\n",
      "While I understand the concerns about the impact of ending free movement on our society, I firmly believe that prioritizing national interests and implementing controlled immigration policies are in the best interests of our country. The government's stance on this matter is aimed at ensuring sustainable and effective immigration policies that safeguard our national sovereignty.\n",
      "\n",
      "I stand by the government's position and support the measures put in place to address the needs of EU citizens residing in the UK, such as the successful implementation of the EU Settlement Scheme. It is important that we uphold their rights post-Brexit while also considering the long-term implications of our immigration policies.\n",
      "\n",
      "Let us continue to have these discussions and work towards finding common ground on this complex issue. Thank you for highlighting these important points, Steve, and I look forward to further engaging in constructive dialogue on this matter.\n",
      "\n",
      "Christine Jardine said Thank you for your input, Kit. While I appreciate your perspective on prioritizing national interests, I believe it is crucial to consider the human cost and the contributions of EU citizens to our society. Ending free movement could have far-reaching negative impacts on public services and the economy, as well as create uncertainty and anxiety among EU nationals in my constituency. It is essential that we approach this issue with empathy and understanding, while also ensuring that we have sustainable and effective immigration policies in place. Let's continue to engage in respectful discussions and work towards finding common ground on this complex issue.\n",
      "\n",
      "Tim Farron said Thank you, Christine, for your thoughtful input on this crucial issue. I wholeheartedly agree with you on the need to consider the human cost and the invaluable contributions of EU citizens to our society. Ending free movement post-Brexit could indeed have far-reaching negative impacts on various aspects of our country, and it is essential that we approach this issue with empathy and understanding.\n",
      "\n",
      "I also believe that sustainable and effective immigration policies are key to addressing these challenges while upholding the rights of EU nationals in the UK. I echo your sentiments about the importance of respectful discussions and finding common ground on this complex issue. Let's continue to engage in constructive dialogue and work towards solutions that prioritize both national interests and human decency. Thank you for your advocacy on this matter, Christine.\n",
      "\n",
      "Rachael Maskell said Thank you for bringing this important issue to light. It is crucial that we consider the human cost and the invaluable contributions of EU citizens to our society as we navigate the complexities of ending free movement post-Brexit. I wholeheartedly agree that empathy, understanding, and sustainable immigration policies are key to addressing the challenges ahead. Let's continue to engage in respectful discussions and work towards finding common ground on this issue. Thank you for your advocacy, Christine and Kit.\n",
      "\n",
      "Christine Jardine said Thank you for your observations on the importance of considering the human cost and contributions of EU citizens, both in our society and in this debate. It is crucial that we approach the issue of ending free movement post-Brexit with empathy, understanding, and a focus on sustainable immigration policies. I appreciate the support from my colleagues, Rachael Maskell and Tim Farron, in advocating for respectful discussions and finding common ground on this complex issue. Let's continue to work together towards solutions that prioritize the rights and dignity of EU nationals in the UK. Thank you for your advocacy and engagement on this matter.\n",
      "\n",
      "Kit Malthouse said Thank you for your observations, Christine and Rachael. I fully understand the importance of considering the human cost and contributions of EU citizens in our society as we navigate the challenges of ending free movement post-Brexit. It is crucial that we approach this issue with empathy, understanding, and a focus on sustainable immigration policies. I appreciate the advocacy and engagement from my colleagues in finding common ground and prioritizing the rights and dignity of EU nationals in the UK. Let's continue to work together towards solutions that address the complexities of this issue while considering the impact on all individuals involved. Thank you.\n",
      "\n",
      "Christine Jardine said Thank you, Kit, for acknowledging the importance of considering the human cost and contributions of EU citizens in our society as we navigate the challenges of ending free movement post-Brexit. It is essential that we approach this issue with empathy, understanding, and a focus on sustainable immigration policies. I also want to thank my colleagues, Rachael Maskell and Tim Farron, for their support in advocating for respectful discussions and finding common ground on this complex issue. Let's continue working together towards solutions that prioritize the rights and dignity of EU nationals in the UK. Thank you for your engagement and commitment to this matter.\n",
      "\n",
      "Jo Stevens said Thank you, Christine, for your thoughtful remarks on the importance of considering the human cost and contributions of EU citizens in our society post-Brexit. I wholeheartedly agree that we must approach this issue with empathy, understanding, and a focus on sustainable immigration policies. It is crucial that we prioritize the rights and dignity of EU nationals in the UK as we navigate the challenges of ending free movement.\n",
      "\n",
      "I also want to express my gratitude to my colleagues, Rachael Maskell and Tim Farron, for their support in advocating for respectful discussions and finding common ground on this complex issue. It is only through working together towards solutions that we can address the complexities of this issue and ensure that all individuals involved are considered.\n",
      "\n",
      "Let us continue this important work, engaging in dialogue and cooperation, to find the best path forward for all parties involved. Thank you for your commitment and dedication to this matter.\n",
      "\n",
      "Kit Malthouse said Thank you, Jo Stevens, for your thoughtful remarks on the importance of considering the human cost and contributions of EU citizens in our society post-Brexit. I completely agree that we must approach this issue with empathy, understanding, and a focus on sustainable immigration policies. It is vital that we prioritize the rights and dignity of EU nationals in the UK as we navigate the challenges of ending free movement.\n",
      "\n",
      "I also want to express my appreciation to my colleagues, Rachael Maskell and Tim Farron, for their support in advocating for respectful discussions and finding common ground on this complex issue. It is through collaborative efforts that we can address the complexities of this matter and ensure that all parties involved are considered.\n",
      "\n",
      "Let us continue to engage in dialogue and cooperation to find the best path forward for all involved. Thank you for your dedication and commitment to this important issue.\n",
      "\n",
      "Christine Jardine said Thank you, Kit, for your remarks. I wholeheartedly agree that we must approach the issue of ending free movement with empathy and understanding. It is essential that we prioritize the rights and dignity of EU nationals in the UK. I also want to express my appreciation to our colleagues, Rachael and Tim, for their support in advocating for respectful discussions and finding common ground on this complex issue. Collaboration is key in addressing the complexities of this matter and ensuring that all parties involved are considered. Let us continue to engage in dialogue and cooperation to find the best path forward for everyone. Thank you for your commitment to this important issue.\n",
      "\n",
      "Tim Farron said Thank you, Christine and Kit, for your thoughtful remarks on the importance of prioritizing the rights and dignity of EU nationals in the UK post-Brexit. I wholeheartedly agree that approaching the issue of ending free movement with empathy and understanding is crucial. Collaboration and respectful discussions are key in finding solutions that benefit everyone involved. I appreciate the dedication and commitment of all my colleagues in advocating for the rights of EU citizens in our society. Let us continue to engage in dialogue and cooperation to ensure that we find the best path forward for all. Thank you.\n",
      "\n",
      "Steve Double said Thank you for bringing up these discussions, and I appreciate the thoughtful remarks made by Tim Farron, Christine Jardine, and Kit Malthouse regarding the rights and dignity of EU nationals post-Brexit. I agree that empathy and understanding are crucial in addressing the challenges of ending free movement, and I support the collaborative efforts to find the best path forward for everyone involved. Let's continue to engage in dialogue and cooperation to ensure that we prioritize the rights and dignity of EU citizens in the UK. Thank you for your dedication to this important issue.\n",
      "\n",
      "Jo Stevens said Thank you for the observations. It is heartening to see colleagues like Steve Double, Tim Farron, Christine Jardine, and Kit Malthouse coming together to prioritize the rights and dignity of EU nationals post-Brexit. Collaboration and empathy are indeed crucial in addressing the challenges of ending free movement. I appreciate the dedication and commitment of everyone involved in advocating for the rights of EU citizens in the UK. Let us continue to engage in respectful discussions and cooperation to find the best path forward for all. Thank you for your ongoing support on this important issue.\n",
      "\n",
      "Kit Malthouse said Thank you, Jo Stevens, for highlighting the important discussions taking place among my colleagues regarding the rights and dignity of EU nationals post-Brexit. I wholeheartedly agree that collaboration and empathy are essential in addressing the challenges of ending free movement. It is encouraging to see bipartisan efforts to prioritize the rights of EU citizens in the UK. Let us continue to engage in constructive dialogue and cooperation to ensure that we find the best path forward for everyone involved. Thank you for your ongoing support on this crucial issue.\n",
      "\n",
      "Jo Stevens said Thank you for the observations and for highlighting the importance of bipartisan efforts in prioritizing the rights and dignity of EU nationals post-Brexit. It is heartening to see colleagues like Steve Double, Tim Farron, Christine Jardine, and Kit Malthouse coming together to address the challenges of ending free movement with collaboration and empathy. I appreciate the dedication and commitment of everyone involved in advocating for the rights of EU citizens in the UK. Let's continue to engage in respectful discussions and cooperation to find the best path forward for all. Thank you for your ongoing support on this crucial issue.\n",
      "\n",
      "Tim Farron said Thank you, Jo Stevens, for acknowledging the importance of working together to protect the rights and dignity of EU nationals post-Brexit. I stand firm in my belief that collaboration and empathy are essential in addressing the challenges of ending free movement. It is encouraging to see bipartisan efforts towards finding a respectful and constructive path forward for everyone involved. Let us continue to engage in discussions and cooperation to ensure that the rights of EU citizens in the UK are safeguarded. Thank you for your ongoing support on this critical issue.\n",
      "\n",
      "Christine Jardine said Thank you, Tim Farron, for your commitment to collaboration and empathy in protecting the rights of EU nationals post-Brexit. I wholeheartedly agree that working together is essential in addressing the challenges of ending free movement. It is heartening to see bipartisan efforts in prioritizing the rights and dignity of EU citizens in the UK. Let's continue to engage in respectful discussions and cooperation to ensure a positive path forward for everyone involved. Thank you for your ongoing support on this critical issue.\n",
      "\n",
      "Kit Malthouse said Thank you, Christine Jardine, for your thoughtful comments on the importance of collaboration and empathy in protecting the rights of EU nationals post-Brexit. I wholeheartedly agree that working together is crucial in addressing the challenges of ending free movement. It is reassuring to see bipartisan efforts being made to prioritize the rights and dignity of EU citizens in the UK. Let's continue to engage in respectful discussions and cooperation to ensure a positive path forward for everyone involved. Thank you for your ongoing support on this critical issue.\n",
      "\n",
      "Steve Double said Thank you for bringing up the importance of collaboration and empathy in protecting the rights of EU nationals post-Brexit. I wholeheartedly agree that working together is crucial in addressing the challenges of ending free movement. It's reassuring to see bipartisan efforts being made to prioritize the rights and dignity of EU citizens in the UK. Let's continue to engage in respectful discussions and cooperation to ensure a positive path forward for everyone involved. Thank you for your ongoing support on this critical issue.\n",
      "\n",
      "Unexpected non-numeric response from agent: i would respond with a 10 as this discussion is extremely relevant to me as an mp.\n",
      "Jo Stevens said Thank you, Steve Double, for your support and acknowledgment of the importance of collaboration and empathy in protecting the rights of EU nationals post-Brexit. I wholeheartedly agree that working together is crucial in addressing the challenges of ending free movement. It's reassuring to see bipartisan efforts being made to prioritize the rights and dignity of EU citizens in the UK. Let's continue to engage in respectful discussions and cooperation to ensure a positive path forward for everyone involved. I appreciate your ongoing support on this critical issue. Let's keep pushing forward for the rights of all individuals impacted by these changes. Thank you.\n",
      "\n",
      "Kit Malthouse said Thank you, Jo Stevens and Steve Double, for your thoughtful comments and commitment to collaboration in protecting the rights of EU nationals post-Brexit. I share your view that working together is essential to address the challenges of ending free movement while prioritizing the rights and dignity of all individuals involved. It is encouraging to see bipartisan efforts being made to ensure a positive path forward for everyone impacted by these changes. Let's continue to engage in respectful discussions and cooperation to achieve the best outcomes for all. Thank you for your ongoing support on this critical issue.\n",
      "\n",
      "Tim Farron said Thank you, Kit, Jo, and Steve, for your continued dedication to this important issue. It's heartening to see all of us coming together to ensure the rights and dignity of EU nationals post-Brexit. Collaboration and empathy are crucial in navigating the challenges ahead, and I appreciate the bipartisan efforts being made to protect these individuals. Let's keep up the respectful dialogue and cooperation to achieve the best outcomes for all those impacted. Thank you for your unwavering support on this critical issue.\n",
      "\n",
      "Jo Stevens said Thank you for highlighting the importance of collaboration and empathy in protecting the rights of EU nationals post-Brexit. I appreciate the bipartisan efforts being made to prioritize the rights and dignity of all individuals impacted by these changes. Let's continue to engage in respectful discussions and cooperation to ensure the best outcomes for everyone involved. Your support on this critical issue is truly valued. Thank you.\n",
      "\n",
      "Debate transcript saved to /kaggle/working/debate_transcript_gpt.csv\n"
     ]
    }
   ],
   "source": [
    "debate_output_path = \"/kaggle/working/debate_transcript_gpt.csv\"\n",
    "\n",
    "run_HoC_debate_framework_3(agents, initial_observation, debate_output_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6361952,
     "sourceId": 10280888,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1240.120149,
   "end_time": "2025-02-24T20:15:12.044135",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-24T19:54:31.923986",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
