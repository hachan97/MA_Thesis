{"cells":[{"cell_type":"markdown","metadata":{"id":"hIkR4TmZN3Yt"},"source":["# Setup Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-11-20T20:40:46.324050Z","iopub.status.busy":"2024-11-20T20:40:46.323730Z","iopub.status.idle":"2024-11-20T20:41:10.041709Z","shell.execute_reply":"2024-11-20T20:41:10.040762Z","shell.execute_reply.started":"2024-11-20T20:40:46.324020Z"},"id":"c7o0Aea0NmaB","jupyter":{"outputs_hidden":true},"outputId":"3e2ddd54-de4b-4d9a-a15c-df722e0011ec","trusted":true},"outputs":[],"source":["!pip install transformers datasets torch huggingface_hub peft trl bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T20:41:10.044852Z","iopub.status.busy":"2024-11-20T20:41:10.044026Z","iopub.status.idle":"2024-11-20T20:41:26.993020Z","shell.execute_reply":"2024-11-20T20:41:26.992345Z","shell.execute_reply.started":"2024-11-20T20:41:10.044805Z"},"id":"R46fDGCFN_ly","trusted":true},"outputs":[],"source":["# Import libraries\n","\n","# Standard Python libraries\n","import pandas as pd\n","from datasets import load_dataset, Dataset  # For loading datasets\n","import os\n","import torch\n","\n","# API Loggins\n","from kaggle_secrets import UserSecretsClient\n","\n","# Hugging Face Transformers\n","import transformers\n","from transformers import (\n","    AutoTokenizer,            # For tokenizing text\n","    AutoModelForCausalLM,     # For loading the GPT-2 model\n","    Trainer,                  # For training the model\n","    TrainingArguments,        # For specifying training arguments\n","    logging,                  # For logging\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    pipeline,\n","    DataCollatorWithPadding\n",")\n","\n","# PyTorch\n","import torch  # For tensor operations and GPU support\n","\n","# For PEFT\n","from peft import prepare_model_for_kbit_training, LoraConfig, PeftModel, get_peft_model  # For LoRA configuration and model\n","from trl import SFTTrainer  # For supervised fine-tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T20:27:26.182447Z","iopub.status.busy":"2024-11-20T20:27:26.181785Z","iopub.status.idle":"2024-11-20T20:27:26.187749Z","shell.execute_reply":"2024-11-20T20:27:26.186764Z","shell.execute_reply.started":"2024-11-20T20:27:26.182409Z"},"id":"pFIpZiSFo3hG","outputId":"a0ddc125-bdd8-4047-e2cd-10be6f90a7e2","trusted":true},"outputs":[],"source":["# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-21T11:15:09.828593Z","iopub.status.busy":"2024-11-21T11:15:09.828238Z","iopub.status.idle":"2024-11-21T11:15:09.994180Z","shell.execute_reply":"2024-11-21T11:15:09.993157Z","shell.execute_reply.started":"2024-11-21T11:15:09.828560Z"},"id":"rdFLz2PjYADL","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["# Login to Hugging Face\n","user_secrets = UserSecretsClient()\n","Hugging_Face_token = user_secrets.get_secret(\"Hugging_Face_token\")\n","\n","from huggingface_hub import login\n","login(Hugging_Face_token)"]},{"cell_type":"markdown","metadata":{"id":"icaFCRI0UOLy"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T20:19:16.687199Z","iopub.status.busy":"2024-11-20T20:19:16.686846Z","iopub.status.idle":"2024-11-20T20:19:16.690974Z","shell.execute_reply":"2024-11-20T20:19:16.690022Z","shell.execute_reply.started":"2024-11-20T20:19:16.687167Z"},"id":"4mwEDG-OUJ_a","outputId":"ddb9acf8-0375-411b-bc2f-bbbf2bbe3958","trusted":true},"outputs":[],"source":["#from google.colab import files\n","#uploaded = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T20:27:31.740830Z","iopub.status.busy":"2024-11-20T20:27:31.739902Z","iopub.status.idle":"2024-11-20T20:27:31.775692Z","shell.execute_reply":"2024-11-20T20:27:31.774703Z","shell.execute_reply.started":"2024-11-20T20:27:31.740773Z"},"id":"YlRfVmATegW4","trusted":true},"outputs":[],"source":["# Load Data\n","#df_Boris_Johnson = pd.read_csv(\"df_Boris_Johnson_2001-19.csv\")\n","df_Boris_Johnson = pd.read_csv(\"/kaggle/input/df-boris-johnson-2001-19/df_Boris_Johnson_2001-19.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T20:27:33.469312Z","iopub.status.busy":"2024-11-20T20:27:33.468599Z","iopub.status.idle":"2024-11-20T20:27:33.487060Z","shell.execute_reply":"2024-11-20T20:27:33.485947Z","shell.execute_reply.started":"2024-11-20T20:27:33.469274Z"},"id":"AAm7QEyBg7WS","trusted":true},"outputs":[],"source":["# Convert Pandas DataFrame to Hugging Face Dataset\n","df_Boris_Johnson_HF = Dataset.from_pandas(df_Boris_Johnson)"]},{"cell_type":"markdown","metadata":{"id":"58ehESMeeIRA"},"source":["# Tokenize Data\n","\n","Different models may require different preprocessing steps based on their *architecture*, *tokenizer type*, and *task*"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T20:29:06.088618Z","iopub.status.busy":"2024-11-20T20:29:06.087596Z","iopub.status.idle":"2024-11-20T20:29:08.011493Z","shell.execute_reply":"2024-11-20T20:29:08.010304Z","shell.execute_reply.started":"2024-11-20T20:29:06.088575Z"},"id":"IWjIJQ0se5PI","outputId":"a88953a5-9e6a-4b89-d425-d338edee9319","trusted":true},"outputs":[],"source":["# Tokenize your dataset\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")    # Define the Tokenizer\n","tokenizer.pad_token = tokenizer.eos_token                               # Set the padding token to the end-of-sequence token\n","\n","def tokenize_function(examples):\n","    tokenized_output = tokenizer(examples['text'],\n","                                 truncation=True,\n","                                 padding='max_length', max_length=512)\n","    tokenized_output['labels'] = tokenized_output['input_ids'][:]\n","\n","    return tokenized_output\n","\n","# Use Hugging Face Dataset's map function to apply Tokenization\n","tokenized_df_Boris_Johnson = df_Boris_Johnson_HF.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-11-20T20:19:19.889832Z","iopub.status.busy":"2024-11-20T20:19:19.889455Z","iopub.status.idle":"2024-11-20T20:19:19.911930Z","shell.execute_reply":"2024-11-20T20:19:19.911138Z","shell.execute_reply.started":"2024-11-20T20:19:19.889790Z"},"id":"BqudYuPaiPEf","jupyter":{"outputs_hidden":true},"outputId":"0b8aa2fa-0330-42ff-aa0d-d08d3d707cb8","trusted":true},"outputs":[],"source":["# Preview tokenized dataset\n","#tokenized_df_Boris_Johnson[1]"]},{"cell_type":"markdown","metadata":{"id":"MxR8Gwq_RzBC"},"source":["# Model Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-11-20T20:25:50.852409Z","iopub.status.busy":"2024-11-20T20:25:50.852022Z","iopub.status.idle":"2024-11-20T20:25:50.922029Z","shell.execute_reply":"2024-11-20T20:25:50.920730Z","shell.execute_reply.started":"2024-11-20T20:25:50.852367Z"},"id":"t5O7mYRNOXb6","jupyter":{"outputs_hidden":true},"outputId":"99c584fb-ea1e-444f-c661-aa2a22be38b0","trusted":true},"outputs":[],"source":["# Optimize Performance with Configurations\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,                      # Load model in 4bit, to redeuce memory and computational requirements\n","    bnb_4bit_use_double_quant=True,         # Double quantization, further compress the model weights\n","    bnb_4bit_quant_type=\"nf4\",              # Quantization type = nf4\n","    bnb_4bit_compute_dtype=torch.bfloat16,  # Compute in 16bit format, to speed up computation\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"meta-llama/Llama-3.2-3B\",\n","    quantization_config=bnb_config,\n","    device_map=\"auto\"  # Automatically assigns model to GPU if available\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49St8Yk2a0Gx","trusted":true},"outputs":[],"source":["# Apply PEFT (Adapter, LoRA and others)\n","model.gradient_checkpointing_enable()               # Reduce memory usage by saving intermediate activations\n","model = prepare_model_for_kbit_training(model)      # Prepare model for kbit training to reduce memory usage"]},{"cell_type":"markdown","metadata":{"id":"ej943P1ic5D4"},"source":["## Inspect Model Architecture\n","\n","The attention mechanism in this model is implemented with **modular projections**, as opposed to a **combined module**: `query_key_value` .\n","The model uses distinct linear layers for the query (q_proj), key (k_proj), and value (v_proj) projections"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ixxwyp4Ucc6h","outputId":"660e1a47-c111-4411-ac7b-c9072f8ca8c5","trusted":true},"outputs":[],"source":["# Inspect Model Architecture\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"zd0ezAzCc8YR"},"source":["# Define LoRA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"suhZIIp7kaWn","trusted":true},"outputs":[],"source":["# Define LoRA configuration\n","lora_config = LoraConfig(\n","    r=8,                                  # Rank of the low-rank matrices, lower ranks -> lower computational load & memory usage\n","    lora_alpha=32,                        # Scaling factor\n","    target_modules=[\"q_proj\", \"v_proj\"],  # Specifies the modules that should be adapted using LoRA (*Depends on model architecture)\n","    lora_dropout=0.1,                     # A Regularization technique used to prevent overfitting\n","    bias=\"none\",                          # specifies that no additional bias terms should be added\n","    task_type=\"CAUSAL_LM\"                 # Define the model: one that is 'predicting the next word'\n",")\n","\n","# Apply LoRA to the model\n","model = get_peft_model(model, lora_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BWB1QURMa9La","outputId":"0ee74809-aa4c-4ff9-fe8a-0691eae2f583","trusted":true},"outputs":[],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n","\n","print_trainable_parameters(model)"]},{"cell_type":"markdown","metadata":{"id":"dxJCSt_-jSGR"},"source":["# Define Training Parameters\n","Define training parameters, including batch size, learning rate, and the number of training epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T20:43:17.779552Z","iopub.status.busy":"2024-11-20T20:43:17.779206Z","iopub.status.idle":"2024-11-20T20:43:17.816314Z","shell.execute_reply":"2024-11-20T20:43:17.815707Z","shell.execute_reply.started":"2024-11-20T20:43:17.779522Z"},"id":"apUq0LYGmBJ2","trusted":true},"outputs":[],"source":["# Set up Hyperparameters\n","training_args = transformers.TrainingArguments(\n","    output_dir=\"outputs\",\n","    optim=\"paged_adamw_8bit\",\n","    eval_strategy=\"no\",\n","    #report_to=\"none\",                       # Disable WandB integration\n","    per_device_train_batch_size=3,          # Adjust the batch size\n","    gradient_accumulation_steps=4,          # Increaset gradient-steps to reduce memory usage\n","    warmup_steps=2,                         # Helps to stabilize training\n","    num_train_epochs=3,                     # Control duration of Training (use either 'max_steps' or 'num_train_epochs')\n","    learning_rate=2e-5,\n","    logging_steps=10,                       # Frequency of Training metrics logs for detailed feedback on process\n","    weight_decay=0.01,\n","\n","    fp16=True,                              # Enable mixed precision training\n","    gradient_checkpointing=True,            # Storing only a subset of activations\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T20:41:54.132138Z","iopub.status.busy":"2024-11-20T20:41:54.131819Z","iopub.status.idle":"2024-11-20T20:41:54.444318Z","shell.execute_reply":"2024-11-20T20:41:54.443109Z","shell.execute_reply.started":"2024-11-20T20:41:54.132109Z"},"id":"cM0vXRznl7CO","trusted":true},"outputs":[],"source":["# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args= training_args,                                 # input Training Arguments\n","    train_dataset= tokenized_df_Boris_Johnson,           # input Tokenized Dataset\n","    data_collator= transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),   # Format batches of data for training\n",")"]},{"cell_type":"markdown","metadata":{"id":"JDekRjeKyCz9"},"source":["# Fine-Tune the Model"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-21T11:13:13.632046Z","iopub.status.busy":"2024-11-21T11:13:13.631704Z","iopub.status.idle":"2024-11-21T11:13:13.834597Z","shell.execute_reply":"2024-11-21T11:13:13.833754Z","shell.execute_reply.started":"2024-11-21T11:13:13.632017Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhaoting-chan\u001b[0m (\u001b[33mhaoting-chan-gesis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Log in to W&B\n","user_secrets = UserSecretsClient()\n","wand_API_Key = user_secrets.get_secret(\"wand_API_Key\")\n","\n","import wandb\n","wandb.login(key=wand_API_Key)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbVIQpWNoirt","outputId":"70c66134-e2dd-4ca5-9f95-a1f16ad00d17","trusted":true},"outputs":[],"source":["# Train the model\n","model.config.use_cache = False        # disable caching\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-hnBov-CojD9","trusted":true},"outputs":[],"source":["# Save the Fine-Tuned Model\n","model.save_pretrained(\"./fine-tuned-llama\")\n","tokenizer.save_pretrained(\"./fine-tuned-llama\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":6127385,"sourceId":9961575,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1049990845b74bb996724702b35fd652":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1aef3e9062d54ea192ec6b582a7045b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dcee8fe207847f293472bbece41da3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ae974ba8adf4e1fbdf2e2a677385366":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50b7a8edf7034f69a0d469194a318eec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58269724075f4f49a77e10541117129a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dcee8fe207847f293472bbece41da3b","max":2213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0c1d4eacad0483394791bcf48c2afd6","value":2213}},"5b61089229d94d7a81db3960e0fb825c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68f19a11fe814bcca26e835051900787":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b61089229d94d7a81db3960e0fb825c","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1049990845b74bb996724702b35fd652","value":2}},"77483ad48d6d498fb18134f467bef8f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7900f333b9984334b3fbc3106383818f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85a2d7c5a3924e8cb051a3f5173e2af6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f6335d155b1429daaa3c935b17adde7","IPY_MODEL_68f19a11fe814bcca26e835051900787","IPY_MODEL_94b7a7ecc67944efb5ddf7f01d77e382"],"layout":"IPY_MODEL_3ae974ba8adf4e1fbdf2e2a677385366"}},"87340102aee54b358cb522e41aa46e82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_922d18fb9bac440c84a480c86e170e62","IPY_MODEL_58269724075f4f49a77e10541117129a","IPY_MODEL_c635ea0c7af1420c9e19e99fac0d8911"],"layout":"IPY_MODEL_fd5e1e41a6f541ccb5b49100bc93dd99"}},"8bab809e2b1e42ef91ea3e2a5dce5b6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"922d18fb9bac440c84a480c86e170e62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77483ad48d6d498fb18134f467bef8f4","placeholder":"​","style":"IPY_MODEL_8bab809e2b1e42ef91ea3e2a5dce5b6f","value":"Map: 100%"}},"94b7a7ecc67944efb5ddf7f01d77e382":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d04728683004307bde1e05ea7dbbaa0","placeholder":"​","style":"IPY_MODEL_1aef3e9062d54ea192ec6b582a7045b0","value":" 2/2 [00:32&lt;00:00, 14.62s/it]"}},"9d04728683004307bde1e05ea7dbbaa0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f6335d155b1429daaa3c935b17adde7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b062ec0b7a4347979308126a0eb49e9e","placeholder":"​","style":"IPY_MODEL_f103cbd0af934fe9be65457fe6129819","value":"Loading checkpoint shards: 100%"}},"b062ec0b7a4347979308126a0eb49e9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c1d4eacad0483394791bcf48c2afd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c635ea0c7af1420c9e19e99fac0d8911":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50b7a8edf7034f69a0d469194a318eec","placeholder":"​","style":"IPY_MODEL_7900f333b9984334b3fbc3106383818f","value":" 2213/2213 [00:02&lt;00:00, 888.82 examples/s]"}},"f103cbd0af934fe9be65457fe6129819":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd5e1e41a6f541ccb5b49100bc93dd99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":4}
