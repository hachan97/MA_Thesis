# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign"                 # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
# Load the Corp_HouseOfCommons_V2.rds
setwd("C:/Users/Bryan Chan/Documents/Projects/thesis_data")
#setwd("H:/MA_Thesis/")
df_HoC <- readRDS("data/Corp_HouseOfCommons_V2.rds")
setwd("C:/Users/Bryan Chan/Documents/Projects/thesis_data")
#setwd("H:/MA_Thesis/")
df_HoC <- readRDS("data/Corp_HouseOfCommons_V2.rds")
# Load the Corp_HouseOfCommons_V2.rds
setwd("C:/Users/Bryan Chan/Documents/Projects/thesis_data/")
#setwd("H:/MA_Thesis/data/")
df_HoC <- readRDS("Corp_HouseOfCommons_V2.rds")
df_HoC %>% head(10)
# Get Overiew
dataset_overview <- plot_intro(df_HoC)
df_HoC_raw <- df_HoC
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms),
parliament = as.factor(parliament),
iso3country = as.factor(iso3country)) %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms),
parliament = as.factor(parliament),
iso3country = as.factor(iso3country))
View(df_HoC)
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
View(df_HoC_2000s)
DGplot_categorical <- df_HoC_2000s %>%
plot_bar(title = "Distribution of Categorical variables", ncol = 2)
DGplot_categorical <- df_HoC_2000s %>%
plot_bar(title = "Distribution of Categorical variables", ncol = 2)
DGplot_continuous <- df_HoC_2000s %>%
plot_histogram(title = "Distribution of Continuous variables", ncol = 2)
DGplot_continuous <- df_HoC_2000s %>%
plot_histogram(title = "Distribution of Continuous variables", ncol = 2)
df_HoC_2000s$date %>% class
df_HoC_2000s$date %>% hist()
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("chattr",
"tidyverse",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign"                 # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
# Plot the distribution of the 'datae' column
df_HoC_2000s$date %>%
# Plot the distribution of the 'datae' column
df_HoC_2000s$date %>% plot_histogram(title = "Distribution of 'date' column")
# Plot the distribution of the 'datae' column
df_HoC_2000s %>% plot_histogram(title = "Distribution of 'date' column")
# Plot the distribution of the 'datae' column
df_HoC_2000s$date
# Plot the distribution of the 'datae' column
df_HoC_2000s$date %>% class
# Plot the distribution of the 'datae' column
df_HoC_2000s %>%
plot_histogram(date, title = "Distribution of 'date' column")
# Create separate Dataframe for each party
df_Lab <- df_HoC_2000s %>% filter(party == "Lab")
df_Con <- df_HoC_2000s %>% filter(party == "Con")
df_LibDem <- df_HoC_2000s %>% filter(party == "LibDem")
df_SNP <- df_HoC_2000s %>% filter(party == "SNP")
df_PlaidCymru <- df_HoC_2000s %>% filter(party == "PlaidCymru")
df_UKIP <- df_HoC_2000s %>% filter(party == "UKIP")
df_GPEW <- df_HoC_2000s %>% filter(party == "GPEW")
df_Independent <- df_HoC_2000s %>% filter(party == "Independent")
df_DUP <- df_HoC_2000s %>% filter(party == "DUP")
df_UUP <- df_HoC_2000s %>% filter(party == "UUP")
df_SDLP <- df_HoC_2000s %>% filter(party == "SDLP")
df_APNI <- df_HoC_2000s %>% filter(party == "APNI")
df_Respect <- df_HoC_2000s %>% filter(party == "Respect")
df_UKUP <- df_HoC_2000s %>% filter(party == "UKUP")
df_ChangeUK <- df_HoC_2000s %>% filter(party == "Change UK")
df_TheIndependents <- df_HoC_2000s %>% filter(party == "The Independents")
df_BirkenheadSocialJustice <- df_HoC_2000s %>% filter(party == "Birkenhead Social Justice")
df_other <- df_HoC_2000s %>% filter(party == "other")
View(df_other)
# Plot the distribution of the 'datae' column
df_HoC_2000s %>%
ggplot(aes(x = date)) +
geom_line(stat = "count") +
labs(x = "Date", y = "Count", title = "Distribution of Dates")
df_HoC_2000s %>% colnames()
# Speeches by Party
df_HoC_2000s %>%
ggplot(aes(x = party)) +
geom_bar() +
labs(x = "Party", y = "Count", title = "Number of Speeches by Party")
# Speeches by Party
# only Party with speeches above 1000
df_HoC_2000s %>%
group_by(party) %>%
summarise(n = n()) %>%
filter(n > 1000) %>%
ggplot(aes(x = party, y = n)) +
geom_bar(stat = "identity") +
labs(x = "Party", y = "Count", title = "Number of Speeches by Party")
# Speeches by Party (only Party with speeches above 1000) with count number of speeches on top of bar chart
df_HoC_2000s %>%
group_by(party) %>%
summarise(n = n()) %>%
filter(n > 1000) %>%
ggplot(aes(x = party, y = n)) +
geom_bar(stat = "identity") +
labs(x = "Party", y = "Count", title = "Number of Speeches by Party") +
# q: What is the definition of standard error?
```
# q: What is the definition of standard error?
```
# q: What is the definition of standard error?
chattr(df_HoC_2000s$party)
?chattr
??chattr
# Speech Length
df_HoC_2000s %>%
mutate(speech_length = str_count(text, "\\S+")) %>%
ggplot(aes(x = party, y = speech_length)) +
geom_boxplot() +
labs(x = "Party", y = "Speech Length", title = "Speech Length by Party")
# Speech Term Frequency
plot_Term_Frequency <- df_HoC_2000s %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(!word %in% stop_words$word) %>%
head(10) %>%
ggplot(aes(reorder(word, n), n)) +
geom_col() +
coord_flip() +
labs(x = "Word", y = "Count", title = "Most Common Words in Speeches")
# Speech Term Frequency
plot_Term_Frequency <- df_HoC_2000s %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(!word %in% stop_words$word) %>%
head(10) %>%
ggplot(aes(reorder(word, n), n)) +
geom_col() +
coord_flip() +
labs(x = "Word", y = "Count", title = "Most Common Words in Speeches")
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("chattr",
"tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign"                 # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign"                 # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
# Speech Term Frequency
plot_Term_Frequency <- df_HoC_2000s %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(!word %in% stop_words$word) %>%
head(10) %>%
ggplot(aes(reorder(word, n), n)) +
geom_col() +
coord_flip() +
labs(x = "Word", y = "Count", title = "Most Common Words in Speeches")
plot_Term_Frequency
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms),
parliament = as.factor(parliament),
iso3country = as.factor(iso3country))
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms))
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Create separate Dataframe for each party
df_Lab <- df_HoC_2000s %>% filter(party == "Lab")
df_Con <- df_HoC_2000s %>% filter(party == "Con")
df_LibDem <- df_HoC_2000s %>% filter(party == "LibDem")
df_SNP <- df_HoC_2000s %>% filter(party == "SNP")
df_PlaidCymru <- df_HoC_2000s %>% filter(party == "PlaidCymru")
df_UKIP <- df_HoC_2000s %>% filter(party == "UKIP")
df_GPEW <- df_HoC_2000s %>% filter(party == "GPEW")
df_Independent <- df_HoC_2000s %>% filter(party == "Independent")
df_DUP <- df_HoC_2000s %>% filter(party == "DUP")
df_UUP <- df_HoC_2000s %>% filter(party == "UUP")
df_SDLP <- df_HoC_2000s %>% filter(party == "SDLP")
df_APNI <- df_HoC_2000s %>% filter(party == "APNI")
df_Respect <- df_HoC_2000s %>% filter(party == "Respect")
df_UKUP <- df_HoC_2000s %>% filter(party == "UKUP")
df_ChangeUK <- df_HoC_2000s %>% filter(party == "Change UK")
df_TheIndependents <- df_HoC_2000s %>% filter(party == "The Independents")
df_BirkenheadSocialJustice <- df_HoC_2000s %>% filter(party == "Birkenhead Social Justice")
df_other <- df_HoC_2000s %>% filter(party == "other")
# Speech Length
plot_speech_length <- df_HoC_2000s %>%
mutate(speech_length = str_count(text, "\\S+")) %>%
ggplot(aes(x = party, y = speech_length)) +
geom_boxplot() +
labs(x = "Party", y = "Speech Length", title = "Speech Length by Party")
# Speech Over Time
plot_speech_overTime <- df_HoC_2000s %>%
ggplot(aes(x = date)) +
geom_line(stat = "count") +
labs(x = "Date", y = "Count", title = "Distribution of Dates")
# Speeches by Party
plot_speech_byParty <- df_HoC_2000s %>%
group_by(party) %>%
summarise(n = n()) %>%
filter(n > 1000) %>%       # only speeches above 1000
ggplot(aes(x = party, y = n)) +
geom_bar(stat = "identity") +
labs(x = "Party", y = "Count", title = "Number of Speeches by Party")
plot_speech_overTime
plot_Term_Frequency
# Top 10 most frequent speakers
plot_Top10_speakers <- df_HoC_2000s %>%
group_by(speaker) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
head(10) %>%
ggplot(aes(reorder(speaker, n), n)) +
geom_col() +
coord_flip() +
labs(x = "Speaker", y = "Count", title = "Top 10 Most Frequent Speakers")
plot_Top10_speakers
# Save the dataframes into csv.
setwd("C:/Users/Bryan Chan/Documents/Projects/thesis_data/")
# Save the dataframes into csv.
setwd("C:/Users/Bryan Chan/Documents/Projects/thesis_data/")
write.csv(df_Lab, "df_Lab.csv", row.names = FALSE)
write.csv(df_Con, "df_Con.csv", row.names = FALSE)
write.csv(df_LibDem, "df_LibDem.csv", row.names = FALSE)
write.csv(df_SNP, "df_SNP.csv", row.names = FALSE)
write.csv(df_PlaidCymru, "df_PlaidCymru.csv", row.names = FALSE)
write.csv(df_UKIP, "df_UKIP.csv", row.names = FALSE)
write.csv(df_GPEW, "df_GPEW.csv", row.names = FALSE)
write.csv(df_Independent, "df_Independent.csv", row.names = FALSE)
write.csv(df_DUP, "df_DUP.csv", row.names = FALSE)
write.csv(df_UUP, "df_UUP.csv", row.names = FALSE)
write.csv(df_SDLP, "df_SDLP.csv", row.names = FALSE)
write.csv(df_APNI, "df_APNI.csv", row.names = FALSE)
write.csv(df_Respect, "df_Respect.csv", row.names = FALSE)
write.csv(df_UKUP, "df_UKUP.csv", row.names = FALSE)
write.csv(df_ChangeUK, "df_ChangeUK.csv", row.names = FALSE)
write.csv(df_TheIndependents, "df_TheIndependents.csv", row.names = FALSE)
write.csv(df_BirkenheadSocialJustice, "df_BirkenheadSocialJustice.csv", row.names = FALSE)
write.csv(df_other, "df_other.csv", row.names = FALSE)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign"                 # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw <- readRDS("data/Corp_HouseOfCommons_V2.rds")
df_HoC_raw <- readRDS(here("data/Corp_HouseOfCommons_V2.rds"))
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw <- readRDS(here("data/Corp_HouseOfCommons_V2.rds"))
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms))
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Speeches by Party
plot_speech_byParty <- df_HoC_2000s %>%
group_by(party) %>%
summarise(n = n()) %>%
filter(n > 1000) %>%       # only speeches above 1000
ggplot(aes(x = party, y = n)) +
geom_bar(stat = "identity") +
labs(x = "Party", y = "Count", title = "Number of Speeches by Party")
plot_speech_byParty
# Create separate Dataframe for each party
df_Lab <- df_HoC_2000s %>% filter(party == "Lab")
df_Con <- df_HoC_2000s %>% filter(party == "Con")
df_LibDem <- df_HoC_2000s %>% filter(party == "LibDem")
df_SNP <- df_HoC_2000s %>% filter(party == "SNP")
df_PlaidCymru <- df_HoC_2000s %>% filter(party == "PlaidCymru")
df_UKIP <- df_HoC_2000s %>% filter(party == "UKIP")
df_GPEW <- df_HoC_2000s %>% filter(party == "GPEW")
df_Independent <- df_HoC_2000s %>% filter(party == "Independent")
df_DUP <- df_HoC_2000s %>% filter(party == "DUP")
df_UUP <- df_HoC_2000s %>% filter(party == "UUP")
df_SDLP <- df_HoC_2000s %>% filter(party == "SDLP")
df_APNI <- df_HoC_2000s %>% filter(party == "APNI")
df_Respect <- df_HoC_2000s %>% filter(party == "Respect")
df_UKUP <- df_HoC_2000s %>% filter(party == "UKUP")
df_ChangeUK <- df_HoC_2000s %>% filter(party == "Change UK")
df_TheIndependents <- df_HoC_2000s %>% filter(party == "The Independents")
df_BirkenheadSocialJustice <- df_HoC_2000s %>% filter(party == "Birkenhead Social Justice")
df_other <- df_HoC_2000s %>% filter(party == "other")
# Save the dataframes into csv.
write.csv(df_Lab, "data/df_Lab.csv", row.names = FALSE)
setwd("C:/Users/Bryan Chan/Documents/Projects/MA_Thesis/data/")
write.csv(df_Lab, "df_Lab.csv", row.names = FALSE)
write.csv(df_Con, "df_Con.csv", row.names = FALSE)
write.csv(df_LibDem, "df_LibDem.csv", row.names = FALSE)
