labs(x = "Party", y = "Speech Length", title = "Speech Length by Party")
# Speech Term Frequency
plot_Term_Frequency <- df_HoC_2000s %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(!word %in% stop_words$word) %>%
head(10) %>%
ggplot(aes(reorder(word, n), n)) +
geom_col() +
coord_flip() +
labs(x = "Word", y = "Count", title = "Most Common Words in Speeches")
# Speech Term Frequency
plot_Term_Frequency <- df_HoC_2000s %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(!word %in% stop_words$word) %>%
head(10) %>%
ggplot(aes(reorder(word, n), n)) +
geom_col() +
coord_flip() +
labs(x = "Word", y = "Count", title = "Most Common Words in Speeches")
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("chattr",
"tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign"                 # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign"                 # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
# Speech Term Frequency
plot_Term_Frequency <- df_HoC_2000s %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(!word %in% stop_words$word) %>%
head(10) %>%
ggplot(aes(reorder(word, n), n)) +
geom_col() +
coord_flip() +
labs(x = "Word", y = "Count", title = "Most Common Words in Speeches")
plot_Term_Frequency
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms),
parliament = as.factor(parliament),
iso3country = as.factor(iso3country))
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms))
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Create separate Dataframe for each party
df_Lab <- df_HoC_2000s %>% filter(party == "Lab")
df_Con <- df_HoC_2000s %>% filter(party == "Con")
df_LibDem <- df_HoC_2000s %>% filter(party == "LibDem")
df_SNP <- df_HoC_2000s %>% filter(party == "SNP")
df_PlaidCymru <- df_HoC_2000s %>% filter(party == "PlaidCymru")
df_UKIP <- df_HoC_2000s %>% filter(party == "UKIP")
df_GPEW <- df_HoC_2000s %>% filter(party == "GPEW")
df_Independent <- df_HoC_2000s %>% filter(party == "Independent")
df_DUP <- df_HoC_2000s %>% filter(party == "DUP")
df_UUP <- df_HoC_2000s %>% filter(party == "UUP")
df_SDLP <- df_HoC_2000s %>% filter(party == "SDLP")
df_APNI <- df_HoC_2000s %>% filter(party == "APNI")
df_Respect <- df_HoC_2000s %>% filter(party == "Respect")
df_UKUP <- df_HoC_2000s %>% filter(party == "UKUP")
df_ChangeUK <- df_HoC_2000s %>% filter(party == "Change UK")
df_TheIndependents <- df_HoC_2000s %>% filter(party == "The Independents")
df_BirkenheadSocialJustice <- df_HoC_2000s %>% filter(party == "Birkenhead Social Justice")
df_other <- df_HoC_2000s %>% filter(party == "other")
# Speech Length
plot_speech_length <- df_HoC_2000s %>%
mutate(speech_length = str_count(text, "\\S+")) %>%
ggplot(aes(x = party, y = speech_length)) +
geom_boxplot() +
labs(x = "Party", y = "Speech Length", title = "Speech Length by Party")
# Speech Over Time
plot_speech_overTime <- df_HoC_2000s %>%
ggplot(aes(x = date)) +
geom_line(stat = "count") +
labs(x = "Date", y = "Count", title = "Distribution of Dates")
# Speeches by Party
plot_speech_byParty <- df_HoC_2000s %>%
group_by(party) %>%
summarise(n = n()) %>%
filter(n > 1000) %>%       # only speeches above 1000
ggplot(aes(x = party, y = n)) +
geom_bar(stat = "identity") +
labs(x = "Party", y = "Count", title = "Number of Speeches by Party")
plot_speech_overTime
plot_Term_Frequency
# Top 10 most frequent speakers
plot_Top10_speakers <- df_HoC_2000s %>%
group_by(speaker) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
head(10) %>%
ggplot(aes(reorder(speaker, n), n)) +
geom_col() +
coord_flip() +
labs(x = "Speaker", y = "Count", title = "Top 10 Most Frequent Speakers")
plot_Top10_speakers
# Save the dataframes into csv.
setwd("C:/Users/Bryan Chan/Documents/Projects/thesis_data/")
# Save the dataframes into csv.
setwd("C:/Users/Bryan Chan/Documents/Projects/thesis_data/")
write.csv(df_Lab, "df_Lab.csv", row.names = FALSE)
write.csv(df_Con, "df_Con.csv", row.names = FALSE)
write.csv(df_LibDem, "df_LibDem.csv", row.names = FALSE)
write.csv(df_SNP, "df_SNP.csv", row.names = FALSE)
write.csv(df_PlaidCymru, "df_PlaidCymru.csv", row.names = FALSE)
write.csv(df_UKIP, "df_UKIP.csv", row.names = FALSE)
write.csv(df_GPEW, "df_GPEW.csv", row.names = FALSE)
write.csv(df_Independent, "df_Independent.csv", row.names = FALSE)
write.csv(df_DUP, "df_DUP.csv", row.names = FALSE)
write.csv(df_UUP, "df_UUP.csv", row.names = FALSE)
write.csv(df_SDLP, "df_SDLP.csv", row.names = FALSE)
write.csv(df_APNI, "df_APNI.csv", row.names = FALSE)
write.csv(df_Respect, "df_Respect.csv", row.names = FALSE)
write.csv(df_UKUP, "df_UKUP.csv", row.names = FALSE)
write.csv(df_ChangeUK, "df_ChangeUK.csv", row.names = FALSE)
write.csv(df_TheIndependents, "df_TheIndependents.csv", row.names = FALSE)
write.csv(df_BirkenheadSocialJustice, "df_BirkenheadSocialJustice.csv", row.names = FALSE)
write.csv(df_other, "df_other.csv", row.names = FALSE)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign"                 # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw <- readRDS("data/Corp_HouseOfCommons_V2.rds")
df_HoC_raw <- readRDS(here("data/Corp_HouseOfCommons_V2.rds"))
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw <- readRDS(here("data/Corp_HouseOfCommons_V2.rds"))
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms))
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Speeches by Party
plot_speech_byParty <- df_HoC_2000s %>%
group_by(party) %>%
summarise(n = n()) %>%
filter(n > 1000) %>%       # only speeches above 1000
ggplot(aes(x = party, y = n)) +
geom_bar(stat = "identity") +
labs(x = "Party", y = "Count", title = "Number of Speeches by Party")
plot_speech_byParty
# Create separate Dataframe for each party
df_Lab <- df_HoC_2000s %>% filter(party == "Lab")
df_Con <- df_HoC_2000s %>% filter(party == "Con")
df_LibDem <- df_HoC_2000s %>% filter(party == "LibDem")
df_SNP <- df_HoC_2000s %>% filter(party == "SNP")
df_PlaidCymru <- df_HoC_2000s %>% filter(party == "PlaidCymru")
df_UKIP <- df_HoC_2000s %>% filter(party == "UKIP")
df_GPEW <- df_HoC_2000s %>% filter(party == "GPEW")
df_Independent <- df_HoC_2000s %>% filter(party == "Independent")
df_DUP <- df_HoC_2000s %>% filter(party == "DUP")
df_UUP <- df_HoC_2000s %>% filter(party == "UUP")
df_SDLP <- df_HoC_2000s %>% filter(party == "SDLP")
df_APNI <- df_HoC_2000s %>% filter(party == "APNI")
df_Respect <- df_HoC_2000s %>% filter(party == "Respect")
df_UKUP <- df_HoC_2000s %>% filter(party == "UKUP")
df_ChangeUK <- df_HoC_2000s %>% filter(party == "Change UK")
df_TheIndependents <- df_HoC_2000s %>% filter(party == "The Independents")
df_BirkenheadSocialJustice <- df_HoC_2000s %>% filter(party == "Birkenhead Social Justice")
df_other <- df_HoC_2000s %>% filter(party == "other")
# Save the dataframes into csv.
write.csv(df_Lab, "data/df_Lab.csv", row.names = FALSE)
setwd("C:/Users/Bryan Chan/Documents/Projects/MA_Thesis/data/")
write.csv(df_Lab, "df_Lab.csv", row.names = FALSE)
write.csv(df_Con, "df_Con.csv", row.names = FALSE)
write.csv(df_LibDem, "df_LibDem.csv", row.names = FALSE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
setwd(H:/MA_Thesis/data/Blumenau_2021/)
setwd(H:MA_Thesis/data/Blumenau_2021/)
setwd("H:/MA_Thesis/data/Blumenau_2021/")
setwd("H:/MA_Thesis/data/Blumenau_2021/")
# read 2016.csv
df_HoC_2016_raw <- read.csv("2016.csv")
# Filter for the top 10 'name' with the most 'count'
df_HoC_2016_raw %>%
group_by(name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(10)
# Count the total number of words 'n_words' for name == 'Boris Johnson'
df_HoC_2016_raw %>%
filter(name == "Boris Johnson") %>%
mutate(n_words = str_count(text, "\\S+")) %>%
summarise(total_words = sum(n_words))
# Sum up the numbers in the 'n_words' column for name == 'Boris Johnson'
df_HoC_2016_raw %>%
filter(name == "Boris Johnson") %>%
summarise(total_words = sum(n_words))
df_Con <- read.csv("df_Con.csv")
setwd("H:/MA_Thesis/data/Blumenau_2021/")
df_Con <- read.csv("df_Con.csv")
df_Con <- read.csv("Rauh_Schwalbach_2020_ParlSpeech/df_Con.csv")
setwd("H:/MA_Thesis/data/")
df_Con <- read.csv("Rauh_Schwalbach_2020_ParlSpeech/df_Con.csv")
# Filter for 'Boris Johnson
df_Con %>% head(3)
# Filter for 'Boris Johnson' in the speaker column
df_Con %>%
filter(speaker == "Boris Johnson") %>%
head(10)
# Filter for 'Boris Johnson' in the speaker column and select only the text column
df_Con %>%
filter(speaker == "Boris Johnson") %>%
select(text)
df_Con %>% head(3)
# Filter for 'Boris Johnson' in the speaker column and see the min and max date
df_Con %>%
filter(speaker == "Boris Johnson") %>%
summarise(min_date = min(date), max_date = max(date))
setwd("H:/MA_Thesis/data/")
write.csv(df_Boris_Johnson, "Rauh_Schwalbach_2020_ParlSpeech/df_Boris_Johnson_2001-19.csv",
row.names = FALSE)
# Filter for 'Boris Johnson' in the speaker column and select only the text column
df_Boris_Johnson <- df_Con %>%
filter(speaker == "Boris Johnson") %>%
select(text)
# Save the text column as a csv file
setwd("H:/MA_Thesis/data/")
write.csv(df_Boris_Johnson, "Rauh_Schwalbach_2020_ParlSpeech/df_Boris_Johnson_2001-19.csv",
row.names = FALSE)
df_Boris_Johnson
View(df_Boris_Johnson)
# count the number of words in the text column
df_Boris_Johnson %>%
mutate(n_words = str_count(text, "\\S+")) %>%
summarise(total_words = sum(n_words))
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
setwd("H:/MA_Thesis/data/")
df_Con <- read.csv("Rauh_Schwalbach_2020_ParlSpeech/df_Con.csv")
df_Boris_Johnson <- df_Con %>%
filter(speaker == "Boris Johnson") %>%
select(text)
#
```
# count the number of words in the text column
df_Boris_Johnson %>%
mutate(n_words = str_count(text, "\\S+")) %>%
summarise(total_words = sum(n_words))
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
setwd("H:/MA_Thesis/data/Blumenau_2021/")
df_HoC_2016_raw <- read.csv("2016.csv")
# Filter for the top 10 'name' with the most 'count'
df_HoC_2016_raw %>%
group_by(name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(10)
View(df_HoC_2016_raw)
df_HoC_2016_raw %>% colnames()
df_HoC %>% df_HoC_2016_raw %>%
select(name, hdate, body, parent, n_words)
df_HoC <- df_HoC_2016_raw %>%
select(name, hdate, body, parent, n_words)
View(df_HoC)
df_HoC_2016 <- df_HoC_2016_raw %>%
select(name, hdate, body, parent, n_words)
View(df_HoC)
View(df_HoC)
View(df_HoC)
#delete df_HoC from memory
rm(df_HoC)
# Histogram showing Distribution of df_HoC_2016 n_words
ggplot(df_HoC_2016, aes(x = n_words)) +
geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Distribution of n_words in df_HoC_2016",
x = "Number of Words",
y = "Frequency") +
theme_minimal()
summary(df_HoC_2016)
summary(df_HoC_2016$n_words)
# Histogram showing Distribution of df_HoC_2016 n_words
ggplot(df_HoC_2016, aes(x = n_words)) +
geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Distribution of n_words in df_HoC_2016",
x = "Number of Words",
y = "Frequency") +
theme_minimal()
summary(df_HoC_2016$n_words)
summary(df_HoC_2016$n_words) %>% as.dataframe()
summary(df_HoC_2016$n_words)
# Top 20 Distribution of 'name' column in df_HoC_2016
df_HoC_2016 %>%
ggplot(aes(x = name)) +
geom_bar(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Top 20 Distribution of 'name' in df_HoC_2016",
x = "Name",
y = "Frequency") +
theme_minimal()
df_HoC_2016 %>%
count(name, sort = TRUE) %>%
head(20)
# Top 20 Most appeared names in the 'name' column of df_HoC_2016
df_HoC_2016 %>%
count(name, sort = TRUE) %>%
head(20) %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(fill = "blue", color = "black", alpha = 0.7) +
coord_flip() +
labs(title = "Top 20 Most appeared names in df_HoC_2016",
x = "Name",
y = "Frequency") +
theme_minimal()
# Top 20 Most appeared names in the 'name' column of df_HoC_2016
df_HoC_2016 %>%
count(name, sort = TRUE) %>%
head(50) %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(fill = "blue", color = "black", alpha = 0.7) +
coord_flip() +
labs(title = "Top 20 Most appeared names in df_HoC_2016",
x = "Name",
y = "Frequency") +
theme_minimal()
df_HoC_2016 %>%
count(name, sort = TRUE) %>%
head(20)
View(df_HoC_2016)
View(df_HoC_2016)
# Investigate if the 'parent' column contains words like 'applaus'
df_HoC_2016 %>%
filter(str_detect(parent, "applaus")) %>%
select(parent, body) %>%
head(10)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw <- readRDS(here("Corp_HouseOfCommons_V2.rds"))
# Load the Rauh_Schwalbach_2020_ParlSpeech
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_raw <- readRDS(here("Corp_HouseOfCommons_V2.rds"))
df_HoC_raw <- readRDS("Corp_HouseOfCommons_V2.rds")
# Load the Rauh_Schwalbach_2020_ParlSpeech
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_raw <- readRDS("Corp_HouseOfCommons_V2.rds")
df_HoC_raw %>% head(10)
df_HoC_raw %>% colnames()
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms))
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Save df_HoC as Rdata. in the data folder
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
#saveRDS(df_HoC, "data/df_HoC.rds")
saveRDS(df_HoC_2000s, "data/df_HoC_2000s.rds")
# save df_HoC_2000s as csv.
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
# Save df_HoC as Rdata. in the data folder
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
# save df_HoC_2000s as csv.
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
View(df_HoC_2000s)
df_HoC_2000s %>% head(20)
df_HoC_2000s %>% head(100)
df_HoC_2000s %>%
group_by(date)
trainingdata_Johnson <- df_HoC_2000s %>%
group_by(date) %>%
mutate(context = lag(text, n = 1, default = ""),   # Previous utterance
context_2 = lag(text, n = 2, default = ""), # Second previous utterance
context_3 = lag(text, n = 3, default = ""), # Third previous utterance
combined_context = paste(context_3, context_2, context, sep = " | ")) %>%
filter(speaker == "Boris Johnson") %>%
select(date, combined_context, text) %>%
rename(input = combined_context, output = text)
trainingdata_Johnson
View(trainingdata_Johnson)
# How may rows in between the subsequent 'Boris Johnson' appear in the 'speaker' column of df_HoC_2000s
df_HoC_2000s %>%
filter(speaker == "Boris Johnson") %>%
mutate(row_number = row_number()) %>%
select(row_number) %>%
mutate(diff = row_number - lag(row_number, n = 1, default = 0)) %>%
filter(diff > 1) %>%
summarise(n = n())
