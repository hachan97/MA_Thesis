p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw <- readRDS(here("data/Corp_HouseOfCommons_V2.rds"))
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms))
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Speeches by Party
plot_speech_byParty <- df_HoC_2000s %>%
group_by(party) %>%
summarise(n = n()) %>%
filter(n > 1000) %>%       # only speeches above 1000
ggplot(aes(x = party, y = n)) +
geom_bar(stat = "identity") +
labs(x = "Party", y = "Count", title = "Number of Speeches by Party")
plot_speech_byParty
# Create separate Dataframe for each party
df_Lab <- df_HoC_2000s %>% filter(party == "Lab")
df_Con <- df_HoC_2000s %>% filter(party == "Con")
df_LibDem <- df_HoC_2000s %>% filter(party == "LibDem")
df_SNP <- df_HoC_2000s %>% filter(party == "SNP")
df_PlaidCymru <- df_HoC_2000s %>% filter(party == "PlaidCymru")
df_UKIP <- df_HoC_2000s %>% filter(party == "UKIP")
df_GPEW <- df_HoC_2000s %>% filter(party == "GPEW")
df_Independent <- df_HoC_2000s %>% filter(party == "Independent")
df_DUP <- df_HoC_2000s %>% filter(party == "DUP")
df_UUP <- df_HoC_2000s %>% filter(party == "UUP")
df_SDLP <- df_HoC_2000s %>% filter(party == "SDLP")
df_APNI <- df_HoC_2000s %>% filter(party == "APNI")
df_Respect <- df_HoC_2000s %>% filter(party == "Respect")
df_UKUP <- df_HoC_2000s %>% filter(party == "UKUP")
df_ChangeUK <- df_HoC_2000s %>% filter(party == "Change UK")
df_TheIndependents <- df_HoC_2000s %>% filter(party == "The Independents")
df_BirkenheadSocialJustice <- df_HoC_2000s %>% filter(party == "Birkenhead Social Justice")
df_other <- df_HoC_2000s %>% filter(party == "other")
# Save the dataframes into csv.
write.csv(df_Lab, "data/df_Lab.csv", row.names = FALSE)
setwd("C:/Users/Bryan Chan/Documents/Projects/MA_Thesis/data/")
write.csv(df_Lab, "df_Lab.csv", row.names = FALSE)
write.csv(df_Con, "df_Con.csv", row.names = FALSE)
write.csv(df_LibDem, "df_LibDem.csv", row.names = FALSE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
setwd(H:/MA_Thesis/data/Blumenau_2021/)
setwd(H:MA_Thesis/data/Blumenau_2021/)
setwd("H:/MA_Thesis/data/Blumenau_2021/")
setwd("H:/MA_Thesis/data/Blumenau_2021/")
# read 2016.csv
df_HoC_2016_raw <- read.csv("2016.csv")
# Filter for the top 10 'name' with the most 'count'
df_HoC_2016_raw %>%
group_by(name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(10)
# Count the total number of words 'n_words' for name == 'Boris Johnson'
df_HoC_2016_raw %>%
filter(name == "Boris Johnson") %>%
mutate(n_words = str_count(text, "\\S+")) %>%
summarise(total_words = sum(n_words))
# Sum up the numbers in the 'n_words' column for name == 'Boris Johnson'
df_HoC_2016_raw %>%
filter(name == "Boris Johnson") %>%
summarise(total_words = sum(n_words))
df_Con <- read.csv("df_Con.csv")
setwd("H:/MA_Thesis/data/Blumenau_2021/")
df_Con <- read.csv("df_Con.csv")
df_Con <- read.csv("Rauh_Schwalbach_2020_ParlSpeech/df_Con.csv")
setwd("H:/MA_Thesis/data/")
df_Con <- read.csv("Rauh_Schwalbach_2020_ParlSpeech/df_Con.csv")
# Filter for 'Boris Johnson
df_Con %>% head(3)
# Filter for 'Boris Johnson' in the speaker column
df_Con %>%
filter(speaker == "Boris Johnson") %>%
head(10)
# Filter for 'Boris Johnson' in the speaker column and select only the text column
df_Con %>%
filter(speaker == "Boris Johnson") %>%
select(text)
df_Con %>% head(3)
# Filter for 'Boris Johnson' in the speaker column and see the min and max date
df_Con %>%
filter(speaker == "Boris Johnson") %>%
summarise(min_date = min(date), max_date = max(date))
setwd("H:/MA_Thesis/data/")
write.csv(df_Boris_Johnson, "Rauh_Schwalbach_2020_ParlSpeech/df_Boris_Johnson_2001-19.csv",
row.names = FALSE)
# Filter for 'Boris Johnson' in the speaker column and select only the text column
df_Boris_Johnson <- df_Con %>%
filter(speaker == "Boris Johnson") %>%
select(text)
# Save the text column as a csv file
setwd("H:/MA_Thesis/data/")
write.csv(df_Boris_Johnson, "Rauh_Schwalbach_2020_ParlSpeech/df_Boris_Johnson_2001-19.csv",
row.names = FALSE)
df_Boris_Johnson
View(df_Boris_Johnson)
# count the number of words in the text column
df_Boris_Johnson %>%
mutate(n_words = str_count(text, "\\S+")) %>%
summarise(total_words = sum(n_words))
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
setwd("H:/MA_Thesis/data/")
df_Con <- read.csv("Rauh_Schwalbach_2020_ParlSpeech/df_Con.csv")
df_Boris_Johnson <- df_Con %>%
filter(speaker == "Boris Johnson") %>%
select(text)
#
```
# count the number of words in the text column
df_Boris_Johnson %>%
mutate(n_words = str_count(text, "\\S+")) %>%
summarise(total_words = sum(n_words))
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
setwd("H:/MA_Thesis/data/Blumenau_2021/")
df_HoC_2016_raw <- read.csv("2016.csv")
# Filter for the top 10 'name' with the most 'count'
df_HoC_2016_raw %>%
group_by(name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(10)
View(df_HoC_2016_raw)
df_HoC_2016_raw %>% colnames()
df_HoC %>% df_HoC_2016_raw %>%
select(name, hdate, body, parent, n_words)
df_HoC <- df_HoC_2016_raw %>%
select(name, hdate, body, parent, n_words)
View(df_HoC)
df_HoC_2016 <- df_HoC_2016_raw %>%
select(name, hdate, body, parent, n_words)
View(df_HoC)
View(df_HoC)
View(df_HoC)
#delete df_HoC from memory
rm(df_HoC)
# Histogram showing Distribution of df_HoC_2016 n_words
ggplot(df_HoC_2016, aes(x = n_words)) +
geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Distribution of n_words in df_HoC_2016",
x = "Number of Words",
y = "Frequency") +
theme_minimal()
summary(df_HoC_2016)
summary(df_HoC_2016$n_words)
# Histogram showing Distribution of df_HoC_2016 n_words
ggplot(df_HoC_2016, aes(x = n_words)) +
geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Distribution of n_words in df_HoC_2016",
x = "Number of Words",
y = "Frequency") +
theme_minimal()
summary(df_HoC_2016$n_words)
summary(df_HoC_2016$n_words) %>% as.dataframe()
summary(df_HoC_2016$n_words)
# Top 20 Distribution of 'name' column in df_HoC_2016
df_HoC_2016 %>%
ggplot(aes(x = name)) +
geom_bar(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Top 20 Distribution of 'name' in df_HoC_2016",
x = "Name",
y = "Frequency") +
theme_minimal()
df_HoC_2016 %>%
count(name, sort = TRUE) %>%
head(20)
# Top 20 Most appeared names in the 'name' column of df_HoC_2016
df_HoC_2016 %>%
count(name, sort = TRUE) %>%
head(20) %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(fill = "blue", color = "black", alpha = 0.7) +
coord_flip() +
labs(title = "Top 20 Most appeared names in df_HoC_2016",
x = "Name",
y = "Frequency") +
theme_minimal()
# Top 20 Most appeared names in the 'name' column of df_HoC_2016
df_HoC_2016 %>%
count(name, sort = TRUE) %>%
head(50) %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(fill = "blue", color = "black", alpha = 0.7) +
coord_flip() +
labs(title = "Top 20 Most appeared names in df_HoC_2016",
x = "Name",
y = "Frequency") +
theme_minimal()
df_HoC_2016 %>%
count(name, sort = TRUE) %>%
head(20)
View(df_HoC_2016)
View(df_HoC_2016)
# Investigate if the 'parent' column contains words like 'applaus'
df_HoC_2016 %>%
filter(str_detect(parent, "applaus")) %>%
select(parent, body) %>%
head(10)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw <- readRDS(here("Corp_HouseOfCommons_V2.rds"))
# Load the Rauh_Schwalbach_2020_ParlSpeech
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_raw <- readRDS(here("Corp_HouseOfCommons_V2.rds"))
df_HoC_raw <- readRDS("Corp_HouseOfCommons_V2.rds")
# Load the Rauh_Schwalbach_2020_ParlSpeech
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_raw <- readRDS("Corp_HouseOfCommons_V2.rds")
df_HoC_raw %>% head(10)
df_HoC_raw %>% colnames()
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms))
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Save df_HoC as Rdata. in the data folder
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
#saveRDS(df_HoC, "data/df_HoC.rds")
saveRDS(df_HoC_2000s, "data/df_HoC_2000s.rds")
# save df_HoC_2000s as csv.
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
# Save df_HoC as Rdata. in the data folder
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
# save df_HoC_2000s as csv.
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
View(df_HoC_2000s)
df_HoC_2000s %>% head(20)
df_HoC_2000s %>% head(100)
df_HoC_2000s %>%
group_by(date)
trainingdata_Johnson <- df_HoC_2000s %>%
group_by(date) %>%
mutate(context = lag(text, n = 1, default = ""),   # Previous utterance
context_2 = lag(text, n = 2, default = ""), # Second previous utterance
context_3 = lag(text, n = 3, default = ""), # Third previous utterance
combined_context = paste(context_3, context_2, context, sep = " | ")) %>%
filter(speaker == "Boris Johnson") %>%
select(date, combined_context, text) %>%
rename(input = combined_context, output = text)
trainingdata_Johnson
View(trainingdata_Johnson)
# How may rows in between the subsequent 'Boris Johnson' appear in the 'speaker' column of df_HoC_2000s
df_HoC_2000s %>%
filter(speaker == "Boris Johnson") %>%
mutate(row_number = row_number()) %>%
select(row_number) %>%
mutate(diff = row_number - lag(row_number, n = 1, default = 0)) %>%
filter(diff > 1) %>%
summarise(n = n())
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
# Load the Rauh_Schwalbach_2020_ParlSpeech
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_raw <- readRDS("Corp_HouseOfCommons_V2.rds")
df_HoC_raw %>% head(10)
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms))
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
indices <- df_HoC_2000s %>%
mutate(row_number = row_number()) %>%
filter(speaker == "Boris Johnson") %>%
pull(row_number)
# Step 2: Calculate differences (spaces between rows)
spaces <- diff(indices)
# Step 3: Plot the distribution
spaces_df <- tibble(spaces = spaces)
spaces_df
# Plotting the distribution
spaces_df %>%
ggplot(aes(x = spaces)) +
geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
labs(
title = "Distribution of Spaces Between 'Boris Johnson' Appearances",
x = "Number of Rows Between",
y = "Frequency"
) +
theme_minimal()
spaces_df
indices
spaces
spaces_df %>%
count(spaces) %>%
ggplot(aes(x = spaces, y = n)) +
geom_col(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Distribution of spaces between 'Boris Johnson' speeches",
x = "Spaces",
y = "Frequency") +
theme_minimal()
spaces_df %>%
count(spaces)
# Summarize and plot the 'spaces_df'
spaces_df %>%
count(spaces)
View(spaces_df)
# Summarize and plot the 'spaces_df'
spaces_df %>%
count(spaces)
# Summarize and plot the 'spaces_df'
spaces_df %>% summarise()
# Summarize and plot the 'spaces_df'
spaces_df %>% summarise(spaces)
# Summarize and plot the 'spaces_df'
spaces_df %>%
count(spaces)
df_HoC_2000s %>% head(10)
df_HoC_2000s %>% colnames
# Display agendas that overlap into the next date
agenda_date_check
agenda_date_check <- df_HoC_2000s %>%
group_by(agenda) %>%
summarize(unique_dates = n_distinct(date)) %>%
filter(unique_dates > 1)
# Display agendas that overlap into the next date
agenda_date_check
distribution <- df_HoC_2000s %>%
group_by(date, agenda) %>%                    # Group by date and agenda
mutate(boris_flag = (speaker == "Boris Johnson")) %>%  # Flag rows where speaker is Boris Johnson
filter(any(boris_flag)) %>%                   # Keep only groups where Boris Johnson spoke
mutate(row_number_within_group = row_number()) %>%  # Assign row numbers within each group
filter(boris_flag) %>%                        # Keep only rows with Boris Johnson
mutate(gap = lead(row_number_within_group) - row_number_within_group - 1) %>%  # Calculate gaps
ungroup() %>%                                 # Remove grouping
filter(!is.na(gap)) %>%                       # Remove NA values (e.g., last Boris Johnson in group)
count(gap)
distribution
df_HoC_2000s %>%
group_by(date, agenda) %>%                    # Group by date and agenda
mutate(boris_flag = (speaker == "Boris Johnson")) %>%  # Flag rows where speaker is Boris Johnson
filter(any(boris_flag)) %>%                   # Keep only groups where Boris Johnson spoke
mutate(row_number_within_group = row_number()) %>%  # Assign row numbers within each group
filter(boris_flag) %>%                        # Keep only rows with Boris Johnson
mutate(gap = lead(row_number_within_group) - row_number_within_group - 1) %>%  # Calculate gaps
ungroup()
df_HoC_2000s %>%
group_by(date, agenda) %>%
mutate(row_number = row_number()) %>%
filter(speaker == "Boris Johnson") %>%
mutate(diff = row_number - lag(row_number) - 1) %>%
filter(!is.na(diff)) %>%
ungroup() %>%
count(diff) %>%
arrange(diff)
distribution
df_HoC_2000s %>%
group_by(date, agenda) %>%
mutate(row_number = row_number()) %>%
filter(speaker == "Boris Johnson") %>%
mutate(diff = row_number - lag(row_number) - 1) %>%
filter(!is.na(diff)) %>%
ungroup() %>%
count(diff) %>%
arrange(diff)
View(df_HoC_2000s)
View(df_HoC_raw)
View(df_HoC)
# Save df_HoC as Rdata. in the data folder
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
# save df_HoC_2000s as csv.
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
# Save df_HoC as Rdata. in the data folder
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
# save df_HoC_2000s as csv.
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
df_HoC_2000s %>%
group_by(date, agenda) %>%
mutate(row_number = row_number()) %>%
filter(speaker == "Boris Johnson") %>%
mutate(diff = row_number - lag(row_number) - 1) %>%
filter(!is.na(diff)) %>%
ungroup() %>%
count(diff) %>%
arrange(diff)
# which year has the most of where speeches by Boris Johnson?
df_HoC_2000s %>%
filter(speaker == "Boris Johnson") %>%
mutate(year = year(date)) %>%
count(year) %>%
ggplot(aes(x = year, y = n)) +
geom_col() +
labs(title = "Number of Speeches by Boris Johnson by Year",
x = "Year",
y = "Count")
# subset for just rows in 2017
df_HoC_2017 <- df_HoC_2000s %>%
filter(year(date) == 2017) %>%
count(speaker) %>%
arrange(desc(n))
View(df_HoC_2017)
# subset for just rows in 2017
df_HoC_2017 <- df_HoC_2000s %>%
filter(year(date) == 2017)
View(df_HoC_2017)
# The number of other speeches between successive appearances by Boris Johnson within the same agenda and date.
df_HoC_2000s %>%
group_by(date, agenda) %>%
mutate(row_number = row_number()) %>%
filter(speaker == "Boris Johnson") %>%
mutate(diff = row_number - lag(row_number) - 1) %>%
filter(!is.na(diff)) %>%
ungroup() %>%
count(diff) %>%
arrange(diff)
# Summarize the distribution of 'terms'
df_HoC_2000s %>%
count(terms) %>%
ggplot(aes(x = terms, y = n)) +
geom_col(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Distribution of 'terms' in df_HoC_2000s",
x = "Terms",
y = "Frequency") +
theme_minimal()
df_HoC_2000s %>%
count(terms)
