mutate(row_number = row_number()) %>%
filter(speaker == "Boris Johnson") %>%
mutate(diff = row_number - lag(row_number) - 1) %>%
filter(!is.na(diff)) %>%
ungroup() %>%
count(diff) %>%
arrange(diff)
View(df_HoC_2000s)
View(df_HoC_raw)
View(df_HoC)
# Save df_HoC as Rdata. in the data folder
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
# save df_HoC_2000s as csv.
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
# Save df_HoC as Rdata. in the data folder
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
# save df_HoC_2000s as csv.
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
df_HoC_2000s %>%
group_by(date, agenda) %>%
mutate(row_number = row_number()) %>%
filter(speaker == "Boris Johnson") %>%
mutate(diff = row_number - lag(row_number) - 1) %>%
filter(!is.na(diff)) %>%
ungroup() %>%
count(diff) %>%
arrange(diff)
# which year has the most of where speeches by Boris Johnson?
df_HoC_2000s %>%
filter(speaker == "Boris Johnson") %>%
mutate(year = year(date)) %>%
count(year) %>%
ggplot(aes(x = year, y = n)) +
geom_col() +
labs(title = "Number of Speeches by Boris Johnson by Year",
x = "Year",
y = "Count")
# subset for just rows in 2017
df_HoC_2017 <- df_HoC_2000s %>%
filter(year(date) == 2017) %>%
count(speaker) %>%
arrange(desc(n))
View(df_HoC_2017)
# subset for just rows in 2017
df_HoC_2017 <- df_HoC_2000s %>%
filter(year(date) == 2017)
View(df_HoC_2017)
# The number of other speeches between successive appearances by Boris Johnson within the same agenda and date.
df_HoC_2000s %>%
group_by(date, agenda) %>%
mutate(row_number = row_number()) %>%
filter(speaker == "Boris Johnson") %>%
mutate(diff = row_number - lag(row_number) - 1) %>%
filter(!is.na(diff)) %>%
ungroup() %>%
count(diff) %>%
arrange(diff)
# Summarize the distribution of 'terms'
df_HoC_2000s %>%
count(terms) %>%
ggplot(aes(x = terms, y = n)) +
geom_col(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Distribution of 'terms' in df_HoC_2000s",
x = "Terms",
y = "Frequency") +
theme_minimal()
df_HoC_2000s %>%
count(terms)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
# Load the Rauh_Schwalbach_2020_ParlSpeech
#setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
# setwd as C:\Users\chanho\Downloads
setwd("C:/Users/Bryan Chan/Downloads/")
df_HoC_raw <- readRDS("C:/Users/Bryan Chan/Downloads/Corp_HouseOfCommons_V2.rds")
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw <- readRDS("C:/Users/Bryan Chan/Downloads/Corp_HouseOfCommons_V2.rds")
# Load up df_HoC_2000s
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_2000s <- read.csv("df_HoC_2000s.csv")
df_HoC_2000s %>% head()
#check if the 'text' column contains "\u00e2\u20ac\u0153" and print out the row
df_HoC_2000s %>%
filter(str_detect(text, "\u00e2\u20ac\u0153")) %>%
select(text)
#check if the 'text' column contains "\u00e2\u20ac\u0153" or "\u00e2\u20ac\u009d", or both and count the number of rows that has them
df_HoC_2000s %>%
filter(str_detect(text, "\u00e2\u20ac\u0153") | str_detect(text, "\u00e2\u20ac\u009d")) %>%
count()
# Remove the just "\u00e2\u20ac\u0153" and "\u00e2\u20ac\u009d" from the 'text' column, not the entire row
df_HoC_2000s_cleaned <- df_HoC_2000s %>%
mutate(text = str_replace_all(text, "\u00e2\u20ac\u0153", "")) %>%
mutate(text = str_replace_all(text, "\u00e2\u20ac\u009d", ""))
df_HoC_2000s_cleaned %>%
filter(str_detect(text, "\u00e2\u20ac\u0153") | str_detect(text, "\u00e2\u20ac\u009d")) %>%
count()
df_HoC_2000s <- df_HoC_2000s_cleaned
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
df_HoC_raw <- readRDS("C:/Users/Bryan Chan/Downloads/Corp_HouseOfCommons_V2.rds")
df_HoC_raw <- readRDS("C:/Users/chanho/Downloads/Corp_HouseOfCommons_V2.rds")
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"stringi",                         # for string manipulation
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
# Process and clean the dataset df_HoC
df_HoC <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms),
# Clean the 'text' column
text = stri_unescape_unicode(text) %>% # Decode Unicode artifacts using the stringi package
str_replace_all("\\s+", " ") %>%           # Normalize whitespace
str_trim()                                 # Trim leading/trailing spaces
)
df_HoC_2000s <- df_HoC %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Count the number of rows with Unicode artifacts in the 'text' column of df_HoC_2000s
df_HoC_2000s %>%
filter(str_detect(text, "\\\\u")) %>%
count()
# Save df_HoC_2000s as a csv file
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
View(df_HoC_2000s)
View(df_HoC_2000s)
gc()
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"stringi",                         # for string manipulation
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw <- readRDS("C:/Users/chanho/Downloads/Corp_HouseOfCommons_V2.rds")
# Process and clean the dataset df_HoC
df_HoC_2000s <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms),
# Clean the 'text' column
text = stri_unescape_unicode(text) %>%   # Decode Unicode artifacts using the stringi package
str_replace_all("\\s+", " ") %>%       # Normalize whitespace
str_trim() %>%                         # Trim leading/trailing spaces
# Replace other Unicode artifacts explicitly
str_replace_all("\\u00c2\\u00a3", "£") %>%  # Example: Replace pound sign
str_replace_all("\\u00e2\\u20ac\\u0153", "€") %>% # Example: Replace euro sign
str_replace_all("\\u00e2\\u20ac\\u009d", "”") %>% # Replace curly quotes
str_replace_all("\\\\\\\"", "\"")  %>%  # Convert escaped quotes (\") to normal quotes
) %>%
# Process and clean the dataset df_HoC
df_HoC_2000s <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms),
# Clean the 'text' column
text = stri_unescape_unicode(text) %>%   # Decode Unicode artifacts using the stringi package
str_replace_all("\\s+", " ") %>%       # Normalize whitespace
str_trim() %>%                         # Trim leading/trailing spaces
# Replace other Unicode artifacts explicitly
str_replace_all("\\u00c2\\u00a3", "£") %>%  # Example: Replace pound sign
str_replace_all("\\u00e2\\u20ac\\u0153", "€") %>% # Example: Replace euro sign
str_replace_all("\\u00e2\\u20ac\\u009d", "”") %>% # Replace curly quotes
str_replace_all("\\\\\\\"", "\"")  # Convert escaped quotes (\") to normal quotes
) %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
rm(df_HoC_raw)
df_HoC_2000s %>%
filter(str_detect(text, "\u00c2\u00a3")) %>%
count()
df_HoC_2000s %>%
filter(str_detect(text, "\u00e2\u20ac\u0153")) %>%
count()
df_HoC_2000s %>%
filter(str_detect(text, "\u00e2\u20ac\u009d")) %>%
count()
# Check for rows that has '\', and print them out
df_HoC_2000s %>%
filter(str_detect(text, "\\\\")) %>%  # Match the backslash character
print()  # Print the rows containing the backslash
# Check for rows that has '\', and print them out
df_HoC_2000s %>%
filter(str_detect(text, "\\\\"))
df_HoC_2000s %>%
filter(str_detect(text, "\\\\")) %>%
count()
filter(str_detect(text, "\")) %>%
df_HoC_2000s %>%
filter(str_detect(text, "\\")) %>%
df_HoC_2000s %>%
filter(str_detect(text, "\\\\")) %>%
count()
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"stringi",                         # for string manipulation
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_raw <- readRDS("Corp_HouseOfCommons_V2.rds")
df_HoC_raw <- readRDS("C:/Users/chanho/Downloads/Corp_HouseOfCommons_V2.rds")
# Process and clean the dataset df_HoC
df_HoC_2000s <- df_HoC_raw %>%
select(-c(parliament,iso3country)) %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms),
# Clean the 'text' column
text = stri_unescape_unicode(text) %>%   # Decode Unicode artifacts using the stringi package
str_replace_all("\\s+", " ") %>%       # Normalize whitespace
str_trim() %>%                         # Trim leading/trailing spaces
# Replace other Unicode artifacts explicitly
str_replace_all("\\u00c2\\u00a3", "£") %>%  # Example: Replace pound sign
str_replace_all("\\u00e2\\u20ac\\u0153", "€") %>% # Example: Replace euro sign
str_replace_all("\\u00e2\\u20ac\\u009d", "”") %>% # Replace curly quotes
str_replace_all("\\\\\\\"", "\"")  # Convert escaped quotes (\") to normal quotes
) %>%
filter(date >= "2000-01-01" & date <= "2020-12-31")
# Check for "\u00e2\u0090\u00a3"
df_HoC_2000s %>%
filter(str_detect(text, "\u00e2\u0090\u00a3")) %>%
count()
df_HoC_2000s %>%
filter(str_detect(text, "\u00e2\u0090\u00a3"))
# Process and clean the dataset df_HoC
df_HoC_2000s <- df_HoC_raw %>%
select(-c(parliament, iso3country)) %>%
mutate(
date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms)
) %>%
filter(date >= "2000-01-01" & date <= "2020-12-31") %>%
# Enhanced text cleaning
mutate(text = stri_unescape_unicode(text) %>%  # Decode Unicode artifacts
str_replace_all("\\s+", " ") %>%       # Normalize whitespace
str_trim() %>%                         # Trim leading/trailing spaces
# Replace specific Unicode artifacts
str_replace_all("\\u00c2\\u00a3", "£") %>%
str_replace_all("\\u00e2\\u20ac\\u0153", "€") %>%
str_replace_all("\\u00e2\\u20ac\\u009d", "”") %>%
str_replace_all("\\u00e2\\u20ac\\u02dc", "'") %>%
str_replace_all("\\u00e2\\u20ac\\u02dcs", "'s") %>%
str_replace_all("\\u00e2\\u20ac\\u201c", "–") %>%
str_replace_all("\\u00e2\\u20ac\\u201d", "—") %>%
str_replace_all("\\u00e2\\u20ac\\u02dc", "‘") %>%
str_replace_all("\\u00e2\\u20ac\\u02dc", "’") %>%
str_replace_all("\\u00e2\\u20ac", "€") %>%
str_replace_all("\\\\\\\"", "\"") %>%  # Convert escaped quotes
str_replace_all("\\\\u00a", " ") %>%   # Remove other artifacts like \u00a
str_replace_all("\\\\u00b", " ") %>%   # Handle \u00b
str_replace_all("\\\\u00c", " ") %>%   # Handle \u00c
# Remove any remaining Unicode sequences
str_replace_all("\\\\u[0-9a-fA-F]{4}", "") %>%
# Optional: Replace common placeholders or fallback text for unmatched Unicode
str_replace_all("\u0090£", "£") %>%
str_replace_all("\u20acOn", "€ On") %>%  # Contextual corrections
str_replace_all("[^[:print:]]", "")     # Remove non-printable characters
)
# Check for Remaining Unicode Artifacts
df_HoC_2000s %>%
filter(str_detect(text, "\u00c2\u00a3")) %>%
count()
# Check for "\u00e2\u0090\u00a3"
df_HoC_2000s %>%
filter(str_detect(text, "\u00e2\u0090\u00a3")) %>%
count()
# Check for "\u00e2\u0090\u00a3"
df_HoC_2000s %>%
filter(str_detect(text, "\u00e2\u20ac\u02dc")) %>%
count()
# Check for "\u00e2\u0090\u00a3"
df_HoC_2000s %>%
filter(str_detect(text, "\u00a")) %>%
count()
df_HoC_2000s %>%
filter(str_detect(text, "\\\\")) %>%
count()
df_HoC_2000s %>%
filter(str_detect(text, "\\")) %>%
count()
df_HoC_2000s %>%
filter(str_detect(text, "\\\\")) %>%
count()
# remove df_HoC_raw from memory
rm(df_HoC_raw)
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
write.csv(df_HoC_2000s, "df_HoC_2000s.csv", row.names = FALSE)
# Codes to install the need packaged and it'll output the package(s) that may have failed to load
knitr::opts_chunk$set(echo = TRUE)
p_needed <-
c("tidyverse",
"tidytext",
"stringi",                         # for string manipulation
"DataExplorer", "skimr",  "VIM",   # for EDA
"modelsummary",                    # Descriptive statistics & Models Summary
"haven", "foreign", "here"         # for STATA data type
)
packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]
if (length(p_to_install) > 0) {
install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)
df_HoC_raw %>% head(10)
setwd("H:/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
setwd("C:/Users/Bryan Chan/Documents/Projects/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
df_HoC_raw <- readRDS("Corp_HouseOfCommons_V2.rds")
df_HoC_raw %>% head(10)
# The range of dates where David Cameron has spoken in the House of Commons
df_HoC_2000s %>%
filter(speaker == "David Cameron") %>%
summarize(min_date = min(date),
max_date = max(date))
# The range of dates where David Cameron has spoken in the House of Commons
df_HoC_raw %>%
filter(speaker == "David Cameron") %>%
summarize(min_date = min(date),
max_date = max(date))
# The range of dates where Theresa May has spoken in the House of Commons
df_HoC_raw %>%
filter(speaker == "Theresa May") %>%
summarize(min_date = min(date),
max_date = max(date))
# Process and clean the dataset df_HoC for 1997-2000
df_HoC_1990s <- df_HoC_raw %>%
select(-c(parliament, iso3country)) %>%
mutate(
date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms)
) %>%
filter(date >= "1997-01-01" & date <= "2000-12-31") %>%
```
df_HoC_raw %>% head(10)
# Process and clean the dataset df_HoC for 1997-2000
df_HoC_1990s <- df_HoC_raw %>%
select(-c(parliament, iso3country)) %>%
mutate(
date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms)
) %>%
filter(date >= "1997-01-01" & date <= "2000-12-31") %>%
# Process and clean the dataset df_HoC for 1997-2000
df_HoC_1990s <- df_HoC_raw %>%
select(-c(parliament, iso3country)) #%>%
# Process and clean the dataset df_HoC for 1997-2000
df_HoC_1990s <- df_HoC_raw %>%
select(-c(parliament, iso3country)) %>%
mutate(
date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms)
) #%>%
# Process and clean the dataset df_HoC for 1997-2000
df_HoC_1990s <- df_HoC_raw %>%
select(-c(parliament, iso3country)) %>%
mutate(
date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms)
) %>%
filter(date < "2000-01-01") %>%
```
# Process and clean the dataset df_HoC for 1997-2000
df_HoC_1990s <- df_HoC_raw %>%
select(-c(parliament, iso3country)) %>%
mutate(
date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms)
) %>%
filter(date < "2000-01-01")
# The range of dates where Theresa May has spoken in the House of Commons
df_HoC_1990s %>%
filter(speaker == "Theresa May") %>%
summarize(min_date = min(date),
max_date = max(date))
# Process and clean the dataset df_HoC for 1997-2000
df_HoC_1990s <- df_HoC_raw %>%
select(-c(parliament, iso3country)) %>%
mutate(
date = as.Date(date, format = "%Y-%m-%d"),
agenda = as.factor(agenda),
speaker = as.factor(speaker),
party = as.factor(party),
chair = as.factor(chair),
terms = as.factor(terms)
) %>%
filter(date < "2000-01-01") %>%
# Enhanced text cleaning
mutate(text = stri_unescape_unicode(text) %>%  # Decode Unicode artifacts
str_replace_all("\\s+", " ") %>%       # Normalize whitespace
str_trim() %>%                         # Trim leading/trailing spaces
# Replace specific Unicode artifacts
str_replace_all("\\u00c2\\u00a3", "£") %>%
str_replace_all("\\u00e2\\u20ac\\u0153", "€") %>%
str_replace_all("\\u00e2\\u20ac\\u009d", "”") %>%
str_replace_all("\\u00e2\\u20ac\\u02dc", "'") %>%
str_replace_all("\\u00e2\\u20ac\\u02dcs", "'s") %>%
str_replace_all("\\u00e2\\u20ac\\u201c", "–") %>%
str_replace_all("\\u00e2\\u20ac\\u201d", "—") %>%
str_replace_all("\\u00e2\\u20ac\\u02dc", "‘") %>%
str_replace_all("\\u00e2\\u20ac\\u02dc", "’") %>%
str_replace_all("\\u00e2\\u20ac", "€") %>%
str_replace_all("\\\\\\\"", "\"") %>%  # Convert escaped quotes
str_replace_all("\\\\u00a", " ") %>%   # Remove other artifacts like \u00a
str_replace_all("\\\\u00b", " ") %>%   # Handle \u00b
str_replace_all("\\\\u00c", " ") %>%   # Handle \u00c
# Remove any remaining Unicode sequences
str_replace_all("\\\\u[0-9a-fA-F]{4}", "") %>%
# Optional: Replace common placeholders or fallback text for unmatched Unicode
str_replace_all("\u0090£", "£") %>%
str_replace_all("\u20acOn", "€ On") %>%  # Contextual corrections
str_replace_all("[^[:print:]]", "")     # Remove non-printable characters
)
setwd("C:/Users/Bryan Chan/Documents/Projects/MA_Thesis/data/Rauh_Schwalbach_2020_ParlSpeech/")
write.csv(df_HoC_1990s, "df_HoC_1990s.csv", row.names = FALSE)
